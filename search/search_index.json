{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>This website documents the courses that I took at ETH in the Computer Science master. Some courses are taken from the bachelors degree. </p>"},{"location":"#mkdocs-and-material-for-mkdocs","title":"Mkdocs and Material for mkdocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>Some parts of this page were written using ChatGPT.</p>"},{"location":"bachelors/","title":"Bachelors in Computer Science","text":""},{"location":"bachelors/ads/","title":"Algorithms and Datastructures","text":"<p>This course discusses a series of well-known algorithms and datastructures that are used throughout the world of  computer science to solve easy and hard problems.</p> <p>The algorithms and datastructures are analysed regarding their complexity (most notably time complexity).</p>"},{"location":"bachelors/ads/#comparing-and-measuring-algorithms","title":"Comparing and measuring algorithms","text":"<p>We always try to find faster algorithms to decrease the computation time (sometimes we also look for algorithms taking up less memory). Most importantly, the algorithms must run correctly. As a developer, we can't influence the hardware or the input given ot an algorithm. The only possibility to make a program faster is by using a better algorithm. </p> <p>The following chapters are mostly not looking on improvements of constant factors (e.g. an algorithm which is twice as fast), but compares algorithms running in \\(O(n!)\\) against \\(O(n)\\) for example. To make such comparisons, we use the asymptotic notation which then leads to the big-O notation.</p>"},{"location":"bachelors/ads/#asymptotic-notation-big-o-notation","title":"Asymptotic notation (Big-O notation)","text":"<p>To measure the complexity of a problem, we often use the asymptotic notation. This notation gives us an idea of how difficult the algorithm is compared to the input size. We have two functions \\(g,f: \\mathbb{N} \\to \\mathbb{R}^+\\). In our purpose, the function computes the number of elementary operations executed in an algorithm, depending on an input size \\(n\\). However, in the simple asymptotic notation, this input can signify anything. </p> <p>The function \\(f\\) grows asymptotically faster than \\(g\\), if \\(\\lim_{n \\to \\infty} \\frac{g(n)}{f(n)} = 0\\). For  such computations, L'H\u00f4pital's rule is often very useful. It states that the limit of the division of two functions is equal to the division of their derivatives: </p> \\[ \\lim_{n \\to \\infty} \\frac{g'(n)}{f'(n)} \\] <p>This also leads to the conclusion that only the term which is growing fastest is important for the asymptotic growth,  the other terms can be neglected. </p> <p>This is where the \\(O\\)-notation comes in. It describes the complexity of an algorithm (the number of elementary  operations) while ignoring constant factors, and states that one function is growing at most as fast as some other function. For example, \\(g \\leq O(f) \\Leftrightarrow g \\in O(f)\\) means that the function \\(g\\) is growing at the same  rate or slower than \\(f\\). </p> \\[ O(f)  := \\{g: \\mathbb{N} \\to \\mathbb{R}^+ \\mid \\exists C &gt; 0 \\; \\forall n \\in \\mathbb{N} \\text{ such that } g(n) \\leq C \\cdot f(n)\\} \\] <p>The \\(\\Theta\\)-notation is used to compare two functions that grow at a same rate. For example \\(g = \\Theta(f)  \\Leftrightarrow g \\in \\Theta(f)\\) means that \\(g\\) and \\(f\\) grow at the same rate. Computing the limit of the division of those two function results in a constant non-zero factor. </p> \\[ \\Theta(f) := \\{g: \\mathbb{N} \\to \\mathbb{R}^+ \\mid g \\leq O(f) \\text{ and } f \\leq O(g)\\} \\] <p>The \\(\\Omega\\)-notation tells us that one function grows at least as fast as some other function. For example, \\(g \\geq  \\Omega(f) \\Leftrightarrow g \\in \\Omega(f)\\) means that \\(g\\) grows at least as fast as \\(f\\). This is the case if  \\(\\lim_{n \\to \\infty} \\frac{g(n)}{f(n)} = \\infty\\). </p> \\[ \\Omega(f) := \\{g: \\mathbb{N} \\to \\mathbb{R}^+ \\mid g \\leq O(f)\\} \\] <p>We can restate the above definitions using the limits: </p> \\[\\begin{align} \\lim_{n \\to \\infty} \\frac{f(n)}{g(n)} &amp;= 0 &amp;\\text{, then } f \\leq O(g)\\\\ \\lim_{n \\to \\infty} \\frac{f(n)}{g(n)} &amp;= C \\in \\mathbb{R}^+ &amp;\\text{, then } f = \\Theta(g)\\\\ \\lim_{n \\to \\infty} \\frac{f(n)}{g(n)} &amp;= \\infty &amp;\\text{, then } f \\geq \\Omega(g) \\end{align}\\]"},{"location":"bachelors/ads/#counting-function-calls","title":"Counting function calls","text":"<p>One thing that comes up often is the counting of some function call in pseudocode. The exercises often state to compute the asymptotic bound, but sometimes also requires the exact number of calls. </p> <p>Here a couple of things to remember. </p> <ul> <li>A loop (almost) always results in a formula, while it sums up the number of function calls in this loop.</li> <li>If an inner loop depends on the counting index of the outer loop, the gaussian sum is used: \\(\\sum_{k=1}^n k =   \\frac{n(n+1)}{2}\\), \\(\\sum_{k=1}^n k^2 = \\frac{n(n+1)(2n+1)}{6}\\), \\(\\sum_{k=1}^n k^3 = \\frac{n^2(n+1)^2}{4}\\).</li> <li>Loops that follow each other are added together.</li> </ul> Examples <p>The following function has a complexity of \\(\\Theta(n)\\) regarding the function calls \\(f\\) with an exact number of calls  of: </p> \\[ \\sum_{i=0}^n 2 + \\sum_{j=0}^{2n} 1 = 2(n+1) + (2n) + 1 = 4n+3 \\] <pre><code>i = 0\nwhile i &lt;= n:\n    f()\n    f()\n    i += 1\n\nj = 0\nwhile j \\leq 2n:\n    f()\n    j += 1\n</code></pre> <p>The following function has a complexity of \\(\\Theta(n^4)\\) regarding the function calls \\(f\\) with an exact number of calls of:</p> \\[ \\sum_{i=1}^n \\sum_{j=1}^{i^3} 1 = \\sum_{i=1}^n i^3 = \\frac{n^2(n+1)^2}{4} \\] <pre><code>i = 1\nwhile i &lt;= n:\n    j = 1\n    while j \\leq i^3:\n        f()\n        j += 1\n    i += 1\n</code></pre>"},{"location":"bachelors/ads/#running-time-of-divide-and-conquer-master-theorem","title":"Running-time of divide-and-conquer (master-theorem)","text":"<p>To compute the running-time of divide-and-conquer algorithms, we use the following theorem. Let \\(a,C &gt; 0\\) and \\(b \\geq 0\\) be constant, and \\(T: \\mathbb{N} \\to \\mathbb{R}^+\\) for all even \\(n \\in \\mathbb{N}\\).</p> \\[ T(n) \\leq aT(n/2)+Cn^b \\] <p>For all \\(n = 2^k, k \\in \\mathbb{N}\\):</p> <ul> <li>If \\(b &gt; log_2(a)\\): \\(T(n) \\leq O(n^b)\\)</li> <li>If \\(b = log_2(a)\\): \\(T(n) \\leq O(n^{log_2(a)} \\cdot log(n))\\)</li> <li>If \\(b &lt; log_2(a)\\): \\(T(n) \\leq O(n^{log_2(a)})\\)</li> </ul> <p>The theorem supposes that the problem size is halved in each iteration. The value of \\(a\\) signifies, how many recursive calls are to be found in the function. \\(b\\) is used to determine the complexity of the work that is done in each call on the input elements. </p>"},{"location":"bachelors/ads/datastructures/","title":"Datastructures","text":""},{"location":"bachelors/ads/datastructures/#abstract-data-type-vs-data-structures","title":"Abstract data type (vs. data structures)","text":"<p>Abstract data types define what we want to do with some data. The following chapter describe a series of abstract data types (ADT) and discuss possible implementations. In general, the objects as well as their operations are described.</p>"},{"location":"bachelors/ads/datastructures/#list","title":"List","text":"<p>A list is defined as an ADT containing objects/keys in a set order and defines (among others) the following operations:</p> <ul> <li><code>insert(K,L)</code>: insert an object <code>K</code> at the end of list <code>L</code></li> <li><code>get(i,L)</code>: get the object at index <code>i</code> from the list <code>L</code></li> <li><code>delete(o,L)</code>: delete the object <code>o</code> from list <code>L</code></li> <li><code>insertAfter(o, K,L)</code>: insert object <code>K</code> after <code>o</code> in list <code>L</code></li> </ul> <p>The following data structures are possible implementations of the list ADT.</p> <ul> <li>Array: requires the maximum length to be known.</li> <li>Linked list: each list entry is an object containing the key and referencing the following object in the list.   The list object is a reference to the first element in the list.</li> <li>Doubly linked list: similar to the linked list, but each object references the following AND preceding object,   and the list object has a reference to the first and last element in the list.</li> </ul> <code>insert</code> <code>get</code> <code>delete</code> <code>insertAfter</code> array \\(O(1)\\) \\(O(1)\\) \\(O(n)\\) \\(O(n)\\) linked list \\(O(n)\\) \\(O(n)\\) \\(O(n)\\) \\(O(1)\\)* doubly linked list \\(O(1)\\) \\(O(n)\\) \\(O(1)\\)* \\(O(1)\\)* <p>*operations require the memory location of the object to be known.</p>"},{"location":"bachelors/ads/datastructures/#dictionary","title":"Dictionary","text":"<p>The dictionary is a collection of unique keys - each key can be found at most one time in the collection. Important operations are:</p> <ul> <li><code>search(x, W)</code>: is <code>x</code> in <code>W</code>?</li> <li><code>insert(x, W)</code>: insert <code>x</code> into <code>W</code>, do nothing if it's already in there</li> <li><code>delete(x, W)</code>: remove <code>x</code> from <code>W</code></li> </ul> <p>This ADT can be implemented using some type of list. However, such dictionaries are not very efficient as most operations would run in \\(O(n)\\). We are looking for something more efficient, namely \\(O(log(n))\\). This is possible using binary trees (with the additional AVL condition) described in the chapter below. It is possible to have more efficient data structures, but these are probabilistic, and were not discussed in this course.</p>"},{"location":"bachelors/ads/datastructures/#binarysearch-tree","title":"Binary/Search Tree","text":"<p>A binary tree is a structure where every node links to (at most) two child nodes. At the top we have the root node that has no parent node. Each binary tree has a search-tree condition that defines how the child keys compare to the parent key. A typical condition is: all node's keys in the left subtree are smaller than the parent node's key, and all node's keys in the right subtree are greater.</p> <p></p> <p>We are talking about a complete binary tree, if all levels are completely filled (except for the last level).</p> <p>The search and insert operations are trivial: search goes through the tree height once. By using the search-tree condition, the algorithm always knows in which subtree to continue searching. insert is quite similar, as it is just using the search algorithm. If the key does not yet exist, a new leaf is created where search ended up.</p> <p>The delete operation is somewhat more complicated, as the tree might have to be restructured. We make a case distinction. The element <code>x</code> is to be deleted.</p> <ol> <li><code>x</code> is a leaf: trivial, just remove the node from its parent</li> <li><code>x</code> has only one child: trivial, x's child becomes its parent's child.</li> <li><code>x</code> has two children: x must be replaced with the next-biggest element of the tree. This element can be found by    going into the right subtree of x, and then following the left subtrees until no left subtree exists. This    element becomes the new x. Now, the delete operation can be used on the element replacing x.</li> </ol> <p>Such a binary tree has, however, a problem in some cases. If a sorted array is converted into a binary tree, the tree depth will be equal to the array length - all operations are inefficient. We require thus a slightly modified search-tree condition.</p>"},{"location":"bachelors/ads/datastructures/#avl-tree","title":"AVL Tree","text":"<p>The AVL tree is built on a binary search-tree but with an additional AVL-condition: the height of the left and right subtree must have a difference of at most 1. This must be valid for every node in the tree. In case the condition is no longer met, the tree must be restructured. This condition leads to trees where the number of nodes is equal to \\(\\text{Fib}(h + 2) -1\\) where \\(h\\) is the tree's height.</p> <p>After the operations insert and delete, the tree might have to be rebalanced. All predecessors of the affected node must be checked (in some cases, the check must not be followed all the way up to the root). In case the AVL-condition of some node <code>u</code> is no longer met, the following operation is to be done:</p> <p>In this case the left subtree of <code>u</code> has grown too large. As the left subtree of <code>v</code> has grown, a single rotation has to be carried out, as shown in the below picture.</p> <p></p> <p>Again the left subtree of <code>u</code> has become too large. But this time, the right subtree of <code>v</code> has grown. A double rotation as shown in the following picture is to be done.</p> <p></p>"},{"location":"bachelors/ads/datastructures/#stack","title":"Stack","text":"<p>The stack is a LIFO (last in first out) data structure, storing object in the order they were added to the structure. This ADT describes the following operations:</p> <ul> <li><code>push(x, S)</code>: add the element <code>x</code> to the top of the stack <code>S</code></li> <li><code>pop(S)</code>: remove and return the top element of <code>S</code></li> </ul> <p>This data can be implemented using a linked list.</p>"},{"location":"bachelors/ads/datastructures/#queue","title":"Queue","text":"<p>The queue is a FIFO (first in first out) data structure, storing object in the order they were added. It is thus quite similar to the stack, but the order of object retrieval is different.</p> <ul> <li><code>enqueue(x, Q)</code>: add the element <code>x</code> to the end of the queue <code>Q</code></li> <li> <p><code>dequeue(Q)</code>: remove and return the first element in the queue</p> </li> <li> <p>This data can be implemented using a doubly linked list.</p> </li> </ul>"},{"location":"bachelors/ads/datastructures/#max-heap","title":"(Max)-Heap","text":"<p>The ADT Max-Heap has a clever way to sort its data allowing access to the maximum element in constant time. It is for example used in the sorting algorithm HeapSort and consists of the two main operations:</p> <ul> <li><code>insert(x, H)</code>: insert the value <code>x</code> into the heap</li> <li><code>extractMax(H)</code>: remove and return the maximum value from the heap</li> </ul> <p>A possible implementation uses a binary tree with a Heap condition that specifies how the tree must be constructed to be valid: it specifies that the key of an element must be greater or equal to all keys of its descendants.</p>"},{"location":"bachelors/ads/datastructures/#in-memory-representation","title":"In-memory representation","text":"<p>The heap is stored as an array. The indexes can be used to determine an element's position in the binary tree underlying the heap: the direct children of the element \\(i\\) are to be found at index \\(2i\\) and \\(2i + 1\\) (requires indexing to start at \\(1\\)).</p>"},{"location":"bachelors/ads/datastructures/#operations","title":"Operations","text":"<p>Both operations shown below always require the heap-condition to be met before the operation is started. As the tree has a depth of \\(log(n)\\), and the elements are only moved vertically, a maximum of \\(log(n)\\) swaps can be done in both cases. It follows, that their time complexity is \\(O(log(n))\\).</p> <p>Insert</p> <ol> <li>Put element at the end of binary tree (in memory: the end of the array)</li> <li>Compare the element with its parent. If the parent is smaller, swap the keys.</li> <li>Repeat step 2 until heap-condition is met.</li> </ol> <p>ExtractMax</p> <ol> <li>Get the heap's maximum from the root.</li> <li>Replace the root's key with the key of the last leaf in the binary tree.</li> <li>Swap the new root with the biggest of its two children.</li> <li>Repeat step 3 until both children are smaller or equal to itself in which case the heap-condition is met again.</li> </ol> <p>CreateHeap is another possible operation. It can be done by using the Insert operation on all elements of the array. Another possibility is to reuse the given array and use it as the heap. At the beginning, the heap-condition is (most certainly) not met. Next, we start looking at the last complete level of the binary tree and let all keys sink. This means, the elements are compared to its children, and if necessary, swapped with the bigger of the two. This is then repeated for all levels up to the root of the heap, resulting in a heap meeting its heap-condition. The sinking process must be done all the way to the bottom of the tree.</p>"},{"location":"bachelors/ads/datastructures/#union-find","title":"Union-Find","text":"<p>The Union-Find ADT provides the means to efficiently keep track of sets, check if elements belong to the same set, and to create unions of the owner-sets of two entries. The following operations are define.</p> <ul> <li><code>make(E)</code>: create the data structures. Each entry in <code>E</code> is in a set of size \\(1\\). Runs in \\(O(|E|)\\)</li> <li><code>same(u,v)</code>: check if \\(u\\) and \\(v\\) are in the same set. Runs in \\(O(1)\\)</li> <li><code>union(u,v)</code>: create a union of the sets containing \\(u\\) and \\(v\\). Runs in \\(O(\\text{min}\\{|\\text{SetOf}(u)|,   |\\text{SetOf}(v)|\\})\\) </li> </ul> Example implementation <p>A possible implementation of this data structure keeps two arrays in memory: </p> <ul> <li><code>rep[u]</code>: identification of the set that \\(u\\) is in</li> <li><code>members[u]</code>: list of members of \\(u\\)'s set, if \\(u\\) is the set's representative</li> </ul> <pre><code>type UnionFind struct {\n    rep     int[]\n    members int[][]\n}\n\nfunc NewUnionFind(E int[]) *UnionFind {\n    U := UnionFind {make(int[], len(E)), make(int[][], len(E))}\n    for e := range E {\n        U.rep[e] = e\n        U.members[e] = make(int[], 0)\n    }\n}\n\nfunc (U *UnionFind) Same(u, v int) bool {\n    return U.rep[u] == U.rep[v]\n}\n\nfunc (U *UnionFind) Union(u, v int) {\n    for x := range U.members[U.rep[u]] { // improve by iterating over the smaller member list \n        U.rep[x] = U.rep[v]\n        U.members[U.rep[v]] = append(U.members[U.rep[v]], x)\n    }\n}\n</code></pre>"},{"location":"bachelors/ads/dynamic-programming/","title":"Dynamic Programming (DP)","text":"<p>Dynamic programming is an approach to solving problems where results of previous computations are reused. Such results are stored inside the DP-table. If applied correctly, the running time of an algorithm can be greatly reduced, and  often even the code gets simpler. </p> <p>To find such algorithms, a suitable sub-problem is defined - it generally describes the meaning of an entry in  the DP-table. Using the sub-problem, we can then define the recursion describing how such han entry can be  computed from previously established values. </p>"},{"location":"bachelors/ads/dynamic-programming/#approaches","title":"Approaches","text":"<p>To solve a sub-problem, we have seen two general approaches:</p> <p>Top-down (memoization): this approach is often used with recursive algorithms. Essentially, before returning the  result, such an algorithm stores the computed value inside a memoization table such that later function calls for  the same value can simply return the value of a table lookup.  </p> FIB using a top-down approach <p>Please note that the <code>memo</code> array is a global array whose values is not stored in the function. </p> <pre><code>memo[1] = 1 // base case 1\nmemo[2] = 1 // base case 2\nfunc fib(n) {\n    if n &gt; 2 &amp;&amp; memo[n] == 0 {\n        memo[n] = fib(n-1) + fib(n-2)\n    }\n\n    return memo[n]\n}\n</code></pre> <p>Bottom-up: such algorithms use an iterative approach by starting with the base case. The value of this base case  is stored in a table. The computation of the subsequent values are based on the previously computed values. In the  case of fibonacci, we have the base cases <code>fib(1)=1</code> and <code>fib(2)=1</code> which are then used to compute <code>fib(3)</code>. </p> FIB using a bottom-up approach <pre><code>func fib(n) {\n    dp := make(int[], n)\n    dp[0], dp[1] = 1, 1\n\n    for i := range 2..n {\n        dp[i] = dp[i-1] + dp[i-2]\n    }\n    return dp[n]\n}\n</code></pre> Naive approach to computing the fibonacci number <p>The following algorithm runs in \\(\\Omega(2^{\\frac{n}{2}})\\).</p> <pre><code>func fib(n) {\n    if n &lt;= 2 {\n        return 1\n    }\n    return fib(n-1) + fib(n-2)\n}\n</code></pre> <p>Running time: </p> \\[\\begin{align} T(n) &amp;= T(n-1) + T(n-2) + c\\\\ &amp; \\geq 2 \\cdot T(n-2)\\\\ &amp; \\geq 4 \\cdot T(n-4)\\\\ &amp; ...\\\\ &amp; \\geq \\Omega(2^{\\frac{n}{2}}) \\end{align}\\]"},{"location":"bachelors/ads/dynamic-programming/#solution-description","title":"Solution description","text":"<p>A solution to a DP-problem can be described using the following six points. </p> <ol> <li>Dimensions of the DP table: What are the dimensions of the DP table?</li> <li>Sub-problems: What is the meaning of each entry?</li> <li>Recursion: How can an entry of the table be computed from previous entries? Justify why your recurrence     relation is correct. Specify the base cases of the recursion, i.e., the cases that do not depend on others.</li> <li>Calculation order: In which order can entries be computed so that values needed for each entry have been     determined in previous steps?</li> <li>Extracting the solution: How can the solution be extracted once the table has been filled?</li> <li>Running time: What is the running time of your solution</li> </ol>"},{"location":"bachelors/ads/dynamic-programming/#examples-by-problem-definitions","title":"Examples by problem definitions","text":"<p>We are now looking at seven problem examples that can be solved through a DP approach.</p>"},{"location":"bachelors/ads/dynamic-programming/#maximum-subarray-sum","title":"Maximum subarray sum","text":"<p>Given an array \\(A\\) of length \\(n\\), we are looking for the biggest sum built from consecutive cells.</p> Solution description <ol> <li>Dimensions of the DP table: \\(n\\)</li> <li>Sub-problems: \\(DP[j]\\) max subarray sum using the first \\(j\\) cells of the input array. </li> <li>Recursion: <ul> <li>BC: \\(DP[1] = max\\{0, A[1]\\}\\)</li> <li>\\(DP[j] = max\\{A[j], A[j] + DP[j-1]\\}\\)</li> </ul> </li> <li>Calculation order: bottom-up</li> <li>Extracting the solution: \\(max\\{DP\\}\\)</li> <li>Running time: \\(O(n)\\)</li> </ol>"},{"location":"bachelors/ads/dynamic-programming/#jump-game","title":"Jump Game","text":"<p>Given an array of positive integers \\(A\\). We start on position \\(1\\) and try to reach the end of the array with as few  jumps as possible. The number at the current position defines how far we can jump in the array. </p> Solution description <ol> <li>Dimensions of the DP table: \\(n\\)</li> <li>Sub-problems: \\(DP[i]\\) max index reachible in \\(i\\) jumps</li> <li>Recursion: <ul> <li>BC: \\(DP[1] = A[1]\\)</li> <li>\\(DP[i] = max\\{j + A[j] \\mid DP[i-2] \\leq i \\leq DP[i-1]\\}\\)</li> </ul> </li> <li>Calculation order: bottom-up</li> <li>Extracting the solution: \\(min\\{i \\mid DP[i] \\geq n\\}\\)</li> <li>Running time: \\(O(n)\\)</li> </ol>"},{"location":"bachelors/ads/dynamic-programming/#longest-common-subsequence","title":"Longest common subsequence","text":"<p>Given two strings \\(A\\) with length \\(n\\) and \\(B\\) with length \\(m\\), we are searching for the length of the longest common  sequence. The letters must be in the correct order, but between the letters we allow for whitespaces. </p> Solution description <p>In this solution, we start indexing the DP-table at 0.</p> <ol> <li>Dimensions of the DP table: \\((n+1) \\times (m+1)\\)</li> <li>Sub-problems: \\(DP[i][j]\\) longest common subsequence using the first \\(i\\) letters from \\(A\\) and the first     \\(j\\) letters of \\(B\\)</li> <li>Recursion: <ul> <li>BC: \\(DP[0][j]=DP[i][0]=0\\)</li> <li>\\(A[i] = B[j] \\Rightarrow DP[i][j] = DP[i-1][j-1] + 1\\)</li> <li>\\(A[i] \\neq B[j] \\Rightarrow DP[i][j] = max\\{DP[i-1][j], DP[i][j-1]\\}\\)</li> </ul> </li> <li>Calculation order: bottom-up</li> <li>Extracting the solution: \\(DP[n][m]\\)</li> <li>Running time: \\(O(n \\cdot m)\\)</li> </ol> <p>The clue here in the recursion is to define what we do with the letters from the strings A and B. For an index  \\(i\\) and \\(j\\), there are essentially three possibilities.</p> <ol> <li>Use both \\(A[i]\\) and \\(B[j]\\). This is only possible if both letters are identical.</li> <li>Don't use \\(A[i]\\): \\(DP[i][j] = max\\{DP[i-1][j], DP[i][j-1]\\}\\)</li> <li>Don't use \\(B[j]\\): \\(DP[i][j] = max\\{DP[i-1][j], DP[i][j-1]\\}\\)</li> </ol>"},{"location":"bachelors/ads/dynamic-programming/#edit-distance","title":"Edit distance","text":"<p>Given two strings \\(A\\) with length \\(n\\) and \\(B\\) with length \\(m\\), what's the minimum of operations required to convert  the string \\(A\\) into the string \\(B\\)? The allowed operations are: insert a new letter, delete a letter, change a letter.</p> Solution description <ol> <li>Dimensions of the DP table: \\((n+1) \\times (m+1)\\)</li> <li>Sub-problems: \\(DP[i][j]\\) the number of operations required to convert the string \\(A[1..i]\\) to \\(B[1..j]\\)</li> <li>Recursion: <ul> <li>BC: \\(DP[i][0] = i, DP[0][j] = j\\) (converting the string \\(A\\) into the empty string requires the deletion of    \\(i\\) letters)</li> <li>\\(A[i] = B[j] \\Rightarrow DP[i][j] = DP[i-1][j-i]\\)</li> <li>\\(A[i] \\neq B[j] \\Rightarrow DP[i][j] = min\\{DP[i-1][j]+1, DP[i][j-1]+1, DP[i-1][j-1]+1\\}\\)</li> </ul> </li> <li>Calculation order: bottom-up</li> <li>Extracting the solution: \\(DP[n][m]\\)</li> <li>Running time: \\(O(n^2)\\)</li> </ol> <p>We are again making a case distinction:</p> <ol> <li>Letter A[j] is used as is in B[j]: only possible if the letters are identical. \\(DP[i][j] = DP[i-1][j-i]\\)</li> <li>Letter A[i] is converted into B[j]: \\(DP[i][j] = DP[i-1][j-1]+1\\)</li> <li>Letter A[i] is deleted: \\(DP[i][j] = DP[i-1][j]+1\\)</li> <li>Letter B[j] is inserted: \\(DP[i][j] = DP[i][j-1]+1\\)</li> </ol>"},{"location":"bachelors/ads/dynamic-programming/#subset-sum","title":"Subset sum","text":"<p>Given an array of \\(n\\) integers \\(A\\) and an integer \\(b\\) we are looking for the subset of integers in \\(A\\) whose sum is  equal to \\(b\\) (if one exists). </p> Solution description <p>The approach first completely ignores what elements are used to reach the sub. We are simly computing if it is  possible at all to reach the sum. To get one possible subset, we use backtracking.</p> <ol> <li>Dimensions of the DP table: \\((n+1) \\times (b+1)\\)</li> <li>Sub-problems: \\(DP[i][j]\\) is it possible to reach the sum \\(j\\) using a subset from the first \\(i\\) entries of     \\(A\\) </li> <li>Recursion:<ul> <li>BC: \\(DP[i][0] = True\\) it is always possible to have a sum of \\(0\\)</li> <li>\\(DP[i][j] = DP[i-1][j] \\vee DP[i-1][j-A[i]]\\)</li> </ul> </li> <li>Calculation order: bottom-up</li> <li>Extracting the solution: \\(DP[n][b]\\)</li> <li>Running time: \\(O(nb)\\) this is also called pseudo-polynomial because the running time now also depends     on the size of an input number.  </li> </ol>"},{"location":"bachelors/ads/dynamic-programming/#knapsack","title":"Knapsack","text":"<p>Given a rucksack with a weight limit \\(W\\) and \\(n\\) objects all having a weight \\(w_i \\in \\mathbb{N}\\) and a value \\(v_i  \\in \\mathbb{N}\\), we are looking for the subset of objects such that the sum of the values is maximal while staying  below the weight limit of the rucksack.</p> Solution description <ol> <li>Dimensions of the DP table: \\(n \\times W\\)</li> <li>Sub-problems: \\(DP[i][j]\\) the maximum achievable value with the first \\(i\\) items while not surpassing a weight     limit of \\(j\\). </li> <li>Recursion: \\(DP[i][j] = max\\{DP[i-1][j], v_i + DP[i-1][j-w_i]\\}\\)</li> <li>Calculation order: bottom-up</li> <li>Extracting the solution: \\(DP[n][W]\\)</li> <li>Running time: \\(O(n \\cdot W)\\), again this is a pseudo-polynomial algorithm.</li> </ol> <p>The above approach tries to maximize the value for a certain weight. A slightly modified version of the problem  searches for the minimum weight required to reach a combined value of \\(V\\). This problem's recursion is defined as  \\(DP[i][j] = min\\{DP[i-1][j], w_i + DP[i-1][j-v_i]\\}\\) and the running time is \\(O(n \\cdot V)\\).</p> <p>Currently, there is no known algorithm improving the running time. However, by slightly modifying the problem, we  are able to improve the running time (here, we take the modified version \"minimum weight to  reach a combined value  of \\(V\\)\"): Instead of knowing the exact values, are underestimating the values through an approximation. The values  \\(v_i\\) are replaced with \\(\\tilde{v_i} = K \\lfloor \\frac{v_i}{K} \\rfloor, K \\in \\mathbb{N}\\). All values are rounded  down to the next closest multiple of \\(K\\). The algorithm essentially stays identical, but now we are only required to  fill out k-th column.</p> <p>This approximated solution has a running time of \\(O(\\frac{n \\tilde{V}}{K}) \\leq O(\\frac{n^2 v_{max}}{K})\\) and a  precision of \\(V_{\\tilde{opd}} \\geq V_{opd} \\cdot (1 - \\frac{nK}{v_{max}})\\).</p> <p>By defining \\(K = \\frac{\\epsilon v_{max}}{n}\\) where \\(\\epsilon &gt; 0\\) is small, we can define the value of our  approximated solution also as \\(V_{\\tilde{opd}} \\geq V_{opt} (1 - \\epsilon)\\) and the running time as \\(O(\\frac{n^3} {\\epsilon})\\)</p>"},{"location":"bachelors/ads/dynamic-programming/#longest-ascending-subsequence","title":"Longest ascending subsequence","text":"<p>Given an array of \\(n\\) (supposedly unique) integers \\(A\\) we search for the longest ascending subsequence (LAS). The  integers in the subsequence must always grow, and the subsequence is not necessarily chained together in the given  array - we allow for values in between that are not used in the subsequence. </p> Solution description <ol> <li>Dimensions of the DP table: \\(n \\times n\\)</li> <li>Sub-problems: \\(DP[i][j]\\) the smallest ending possible for a sequence of length \\(j\\) using the first \\(i\\) values     of \\(A\\).</li> <li>Recursion:<ul> <li>BC: \\(DP[1][1] = A[1]\\), \\(DP[1][j&gt;1] = \\infty\\)</li> <li>\\(DP[i-1][j-1] &lt; A[i] &lt; DP[i-1][j]\\) (\\(A[i]\\) can be used, and it is better than the previous minimum for this    length): \\(DP[i][j] = A[i]\\)</li> <li>Otherwise: \\(DP[i][j] = DP[i-1][j]\\)</li> </ul> </li> <li>Calculation order: bottom-up</li> <li>Extracting the solution: \\(DP[n][j]\\) where \\(j\\) is the largest value for which \\(DP[n][j] \\neq \\infty\\)</li> <li>Running time: \\(O(n^2)\\)</li> </ol> <p>The exact subset can be found through backtracking. </p> <p>The same approach can be modified slightly by reusing the first column in every iteration to receive a running time  of \\(O(n \\cdot log(n))\\): the numbers in the DP table are always sorted from smallest to largest, and in every iteration,  exactly one entry is modified. If the next value in the input array is \\(x\\), we can use the binary search algorithm  to find the next smallest value in the DP table, and then replace the value to its right with \\(x\\).   </p>"},{"location":"bachelors/ads/dynamic-programming/#backtracking","title":"Backtracking","text":"<p>A DP-table often contains only number values. For example, in the \"Longest common subsequence\", the DP-table stores  the length of the subsequence. However, the table still allows to extract the subsequence itself through strategic  backtracking through the table. </p> <p>We start by looking at the value of the final result and search our way back through the array to the starting  position. </p>"},{"location":"bachelors/ads/graph-theory/","title":"Graph theory","text":"<p>A graph \\(G\\) is a set of vertices \\(V\\) and edges \\(E\\) where an edge is defined as an unordered pair of vertices \\(e = uv\\) with \\(u \\neq v\\). Directed graphs are quite similar, but edges are defined as ordered pairs.</p> Variable names <p>The following chapters will use a series o variable names that, if not signaled otherwise, have the following  meaning.</p> <ul> <li>\\(V\\): set of vertices</li> <li>\\(E\\): set of edges</li> <li>\\(e\\): one specific edge</li> <li>\\(n = |V|\\): number of vertices in the graph</li> <li>\\(m = |E|\\): number of edges in the graph</li> <li>\\(d(u, v)\\): distance function between vertices \\(u\\), \\(v\\)</li> <li>\\(c(e)\\): cost/weight of the edge \\(e\\)</li> </ul>"},{"location":"bachelors/ads/graph-theory/#definitions","title":"Definitions","text":"<p>Vertices:</p> <ul> <li>Vertex degree \\(\\text{deg}(u)\\): Number of adjacent vertices. In a directed graph, this is further split into   \\(\\text{deg}_{in}\\) (number of incoming edges) and \\(\\text{deg}_{out}\\) (outgoing edges)</li> <li>Source (Quelle): Vertex with \\(\\text{deg}_{in} = 0\\)</li> <li>Sink (Senke): Vertex with \\(\\text{deg}_{out} = 0\\) (exists, if the graph is acyclic)</li> <li>Leaf: Vertex with \\(\\text{deg}(u) = 1\\)</li> <li>Adjacent (Adjazent, benachbart): two vertices directly connected through an edge</li> <li>Incident (Inzident, angliegen): edges connected to a vertex</li> <li>\\(u\\) reaches \\(v\\): There exists a path from \\(u\\) to \\(v\\)</li> <li>Strongly connected (in directed graphs): both edges \\(uv\\) and \\(vu\\) exist</li> <li>Loop: an edge \\(uu\\)</li> </ul> <p>Graphs:</p> <ul> <li>Complete graph: all vertices are pairwise adjacent</li> <li>Transitive graph: for any two edges \\(uv\\) and \\(vw\\), the edge \\(uw\\) also exists</li> <li>Connected component (Zusammenhangskomponente ZHK): biggest possible subgraph where there exists a walk between   every pair of vertices.</li> <li>Connected graph (zusammenh\u00e4ngend): Graph with exactly one connected component</li> <li>Tree: connected graph without cycles. A tree with \\(n\\) vertices has \\(n-1\\) edges</li> <li>Multi-graph: edges are allowed to be duplicated</li> </ul> <p>Walks:</p> <ul> <li>Walk (Weg): sequence of adjacent vertices with two endpoints where the length is defined as the number of   vertices on the walk</li> <li>Closed Walk (Zyklus): walk with identical first and last vertex</li> <li>Path (Pfad): walk without repeating vertex</li> <li>Cycle (Kreis): path with identical first and last vertex</li> </ul> <p>Special walks:</p> <ul> <li>Eulerian walk: walk using every edge exactly once. Exists if at most two vertices have an odd degree.</li> <li>Eulerian closed walk: closed walk using every edge exactly once. Exists if all edges have an even degree, and   only one ZHK exists.</li> <li>Hamiltonian path: path visiting every vertex exactly once. A graph with a Hamiltonian path also has an   Eulerian walk.</li> <li>Hamiltonian cycle: cycle visiting every vertex exactly once.</li> </ul>"},{"location":"bachelors/ads/graph-theory/#finding-eulerian-walk","title":"Finding Eulerian walk","text":"<p>We define the algorithm <code>Walk(u)</code> that finds a walk in a graph with starting vertex \\(u\\) where each edge is used at most once, and all edges incident to the final node were used.</p> <pre><code>Walk(u):\n    if u has adjacent vertex v, and edge uv is not marked:\n        mark uv\n        Walk(v)\n</code></pre> <p>This algorithm has the invariant: number of unmarked edges incident to \\(v\\) is even. If the invariant is valid before the execution of \\(Walk(v)\\), it is also valid afterward. Actually, if it is valid before the execution, the algorithm will find a closed walk.</p> <p>By slightly modifying this algorithm, we are able to use it to find an Eulerian walk. We put every vertex into a global list <code>z</code> after it has been fully processed (has no more unmarked incident edges). The marking is also global.</p> <pre><code>EulerianWalk(u):\n    for every adjacent vertex v of u, with uv not marked:\n        mark uv\n        EulerianWalk(v)\n    z &lt;- (z, u)\n</code></pre> <p>By executing the above algorithm on any node in the graph, we can find an Eulerian cycle in \\(z\\) IFF the graph is connected, and all vertex degrees are even. See the following example.</p> <p></p>"},{"location":"bachelors/ads/graph-theory/#storing-a-graph-in-memory","title":"Storing a graph in memory","text":"<p>An adjacency matrix stores the edges in a square matrix of size \\(|V|^2\\). Due to its size, it is often considered inefficient, as most of the cells will be empty (set to \\(0\\)), except if \\(|E| \\geq \\Omega(|V|^2)\\).</p> <p>The adjacency list is a list of vertices, where for each vertex a linked list of nodes is stored. This linked list represents all the adjacent vertices.</p> <p>The improved adjacency list stores some additional data: for each vertex, we know the vertex degree, and identical edges in the adjacency list are linked together.</p>"},{"location":"bachelors/ads/graph-theory/#topological-order","title":"Topological order","text":"<p>The topological order is a special order of the vertices of a directed acyclic graph (DAG, a directed graph without cycles). Such an order is not necessarily unique.</p>"},{"location":"bachelors/ads/graph-theory/#search-algorithms","title":"Search algorithms","text":"<p>To find a topological order, we follow the steps below:</p> <ol> <li>Find a sink \\(v\\)</li> <li>\\(v\\) is the last element in the topological order</li> <li>Remove \\(v\\) and call this algorithm recursively</li> </ol> <p>To find a sink in the graph, we use the following algorithm on an arbitrary vertex. The last vertex in the path is a sink.</p> <pre><code>Path(u):\n    mark u\n    if u has unmarked descendant:\n        Path(u)\n</code></pre>"},{"location":"bachelors/ads/graph-theory/#depth-first-search-dfs","title":"Depth first search (DFS)","text":"<p>To find a complete topological order of a graph, we can use a so-called depth first search. The algorithm is called on any vertex of the graph, giving us a pre- and post-numper. It is called depth first, because the algorithm first explores a final vertex in the path and then goes up one level to continue searching.</p> <pre><code>DFS(G):\n    for unmarked v:\n        Visit(v)\n\nVisit(u):\n    pre[u] &lt;- T;  T++\n    for unmarked descendant v of u:\n        Visit(v)\n    post[u] &lt;- T; T++\n</code></pre> <p>If this algorithm is called on the root of the topological order, this results in a DFS-tree, otherwise in a DFS-forest. The reverse post-order results in the topological order (if we have a DAG).</p> <p>In the following example, the algorithm is executed on a graph with cycles. In red, we have the pre- and post-number.</p> <p></p> <p>The pre- and post-number of a vertex \\(u\\) creates the interval \\(I_u\\)</p> <p>The edges are colored as follows:</p> <ul> <li>Green: tree edge - edge building up the DFS-tree</li> <li>Yellow: backward edge - remaining edges \\(uv\\) where \\(I_v\\) completely contains \\(I_u\\)</li> <li>Blue: forward edge - remaining edges \\(uv\\) where \\(I_u\\) completely contains \\(I_v\\)</li> <li>Red: cross edge: - remaining edges \\(uv\\) where \\(I_u\\) is entirely in front of \\(I_v\\)</li> </ul> <p>This allows us to build a recursion tree/DFS-tree:</p> <p></p> <p>If a graph has a backward edge, it follows that the graph has a cycle. And thus no topological order exists.</p> <p>DFS can also be executed on undirected graphs, with the following properties:</p> <ul> <li>forward edge = backward edge</li> <li>cross edges do not exist.</li> </ul>"},{"location":"bachelors/ads/graph-theory/#shortest-path","title":"Shortest path","text":"<p>In graphs, we are searching for shortest paths between two vertices. This must always be a path, as visiting a vertex twice would unnecessarily add more edges to cross. Each edge is weighted, and these weights can also be negative.</p> <ul> <li>Path cost (Wegkosten) \\(c(W)\\): sum of the edge weights</li> <li>Distance \\(d(u,v) = \\text{min}\\{c(W) \\mid \\text{W is walk from } u \\text{ to } v\\}\\)</li> <li>\\(d(u,v) \\leq d(u, w) + d(w,v)\\)</li> </ul> <p>Once the shortest paths towards all vertices was found, the shortest-path-tree can be constructed, spanning up a tree where a path from the starting vertex to all other vertices exists.</p> <p>The following chapters will look at five algorithms that can be used in different use cases to find shortest paths.</p> 1-to-allall-to-all Edge costs Algorith Running time \\(c(e)=1\\) BFS \\(O(m+n)\\) \\(c(e)\\geq 0\\) Dijkstra \\(O((m+n) log(n))\\)<sup>1</sup> \\(c(e) \\in \\mathbb{R}\\) Bellman-Ford<sup>2</sup> \\(O(m \\cdot n)\\) Edge costs Algorith Running time \\(c(e)=1\\) \\(n \\times\\) BFS \\(O((m+n) \\cdot n)\\) \\(c(e)\\geq 0\\) \\(n \\times\\) Dijkstra \\(O((m+n) log(n) \\cdot n)\\)<sup>1</sup> \\(c(e) \\in \\mathbb{R}\\) \\(n \\times\\) Bellman-Ford<sup>2</sup> \\(O(m \\cdot n^2)\\) \\(c(e) \\in \\mathbb{R}\\) Floyd-Warhsall \\(O(n^3)\\) \\(c(e) \\in \\mathbb{R}\\) Johnson \\(O(n (m + n) log(n))\\)"},{"location":"bachelors/ads/graph-theory/#breadth-first-search-bfs","title":"Breadth first search (BFS)","text":"<p>The breadth first search algorithm can be used to find the shortest path in an unweighted graph, where only the number of crossed vertices are counted. It is called breadth first, as each vertex is fully processed, before going a level further. This is achieved using a queue. Actually, this algorithm not only computes the distance between two vertices, but between a starting vertex and all other connected vertices.</p> <pre><code>BFS(s):\n    queue = {s}\n    dist[s] = 0\n    enter[s] = 0\n    T = 1\n\n    while !queue.empty:\n        u = queue.deq()\n        leave[u] = T; T++\n        for (u,v) in E &amp;&amp; enter[v] empty:\n            queue.enq(v)\n            dist[v] = dist[u] + 1\n            enter[v] = T; T++\n</code></pre> <p>The algorithm keeps track on what steps a vertex is started to being processed, and when it is finished. Additionally, it computes the distances to each vertex, and adds adjacent vertices to the list of vertices to process. Executed on the vertex A in the graph below, the shown enter and leave numbers result.</p> <p></p>"},{"location":"bachelors/ads/graph-theory/#dijkstra-non-negative-edges","title":"Dijkstra (non-negative edges)","text":"<p>To find the shortest paths in graphs without negative weighted edges, the Dijkstra algorithm can be applied. In general, this algorithm sorts the vertices by distance to the starting vertex \\(s\\). We use the following recursion:</p> \\[ d(s, v_k) = \\text{min}_{v_i \\to v_k} \\{d(s, v_i) + c(v_i,v_k)\\} \\] <p>The algorithm keeps track of upper bounds distances to the starting vertex, until all vertices were processed at which point we have the shortest path distances in the array \\(d\\).</p> <pre><code>Dijkstra(s):\n    d[s] = 0 \n    for v in V &amp;&amp; v != s: d[v] = infinity\n    priorityQ = {(s, 0)}\n    S = {}\n\n    while S != V:\n        v = priorityQ.enq()\n        S.add(v)\n        for w in v.adjacent() &amp;&amp; w notin S:\n            if d[v] + c(w,v) &lt;= d[w]:\n                d[w] = d[v] + c(w,v)\n                priorityQ.enq(w, d[w])\n</code></pre> <p>In the following figure, the algorithm is run on a given graph. In red, we see the evolution of the costs, and in green the order of processing.</p> <p></p>"},{"location":"bachelors/ads/graph-theory/#bellman-ford-negative-edges","title":"Bellman-Ford (negative edges)","text":"<p>The Bellman-Ford algorithm finds shortest paths in a graph without negative cycles. The principle of this algorithm is to have \\(l\\)-precise bounds - bounds that are only exact for the first \\(l\\) vertices in the shortest-path-tree. These bounds are iteratively improved, until the costs do no longer change, which is after \\((n-1)\\) runs at the latest. The recursion of this algorithm is defined as:</p> \\[\\begin{align} \\forall v &amp;\\in S_{\\leq l} \\; \\backslash \\; \\{s\\}\\\\ d(s,v) &amp;= min\\{d(s,u) + c(u,v) \\mid u \\to v,\\; u \\in S_{\\leq l-1}\\} \\end{align}\\] <pre><code>BellmanFord(s):\n    d[s] = 0 \n    for v in V &amp;&amp; v != s: d[v] = infinity\n\n    while d changed:\n        for v in V:\n            for u in v.adj():\n                d[u] = min(d[u], d[v] + c(v, u) \n</code></pre> <p>This algorithm can be seen in below graph where the red values show how the costs evolve.</p> <p></p> A B C D E F G 0 \\(\\infty\\) \\(\\infty\\) \\(\\infty\\) \\(\\infty\\) \\(\\infty\\) \\(\\infty\\) 0 3 1 5 6 9 12 0 3 -2 5 3 9 9"},{"location":"bachelors/ads/graph-theory/#finding-negative-cycles","title":"Finding negative cycles","text":"<p>As soon as a graph has negative edge costs, there is the potential to have negative cycles. To find if such a cycle exists, we simply execute the Bellman-Ford algorithm. If a negative cycle exists, the algorithm will never terminate as the weights become smaller in each iteration.</p>"},{"location":"bachelors/ads/graph-theory/#floyd-warshall","title":"Floyd-Warshall","text":"<p>The Floyd-Warshall algorithm applies a solution using the dynamic-programming technique. We define the sub-problem as \\(d_{u,v}^{i}\\): shortest path from \\(u\\) to \\(v\\) using the intermediate nodes \\(\\{1,...,i\\}\\). The recursion gives us the following case distinction.</p> <ol> <li>\\(i\\) is not an intermediate node: \\(d_{u,v}^{i} = d_{u,v}^{i-1}\\)</li> <li>\\(i\\) is an intermediate node exactly once: \\(d_{u,v}^{i} = d_{u,i}^{i-1} + d_{i,v}^{i-1}\\)</li> <li>\\(i\\) is an intermediate node multiple times: ignore this case if no negative cycles exist</li> </ol> <p>This can be translated into pseudocode as follows. This algorithm has a running time and memory usage of \\(O(n^3)\\)</p> <pre><code>FloydWarshall(V, E):\n    d = int[n][n][n] // weights on diagonal are left at 0\n    for u in V:\n        for v in V:\n            if u != v &amp;&amp; E.contains(u,v):\n                d[0][u][v] = E.contains(u,v) ? c(u,v) : infinity\n\n    for i in 1..len(V): \n        for u in 0..len(V):\n            for v in 0..len(V):\n                d[i][u][v] = min(d[i-1][u][v], d[i-1][u][i] + d[i-1][i][v])\n\n    return d[len(v)-1]\n</code></pre>"},{"location":"bachelors/ads/graph-theory/#finding-negative-cycles_1","title":"Finding negative cycles","text":"<p>After the algorithm has been executed, we can look at the diagonal of the DP table. If any value on this diagonal is negative, there exists a walk from some \\(u\\) to itself having a negative distance. In this case we can conclude that at least one negative cycle exists.</p> <p>In our algorithm, we can now conclude that: if for any \\(u \\to v\\) walk, there exists a walk (not necessarily the shortest one) through some vertex \\(w\\) with \\(d[n][w][w] &lt; 0\\), the walk \\(u \\to v\\) has a shortest distance of \\(-\\infty\\). Otherwise, its distance is defined by \\(d[n][u][v]\\).</p>"},{"location":"bachelors/ads/graph-theory/#johnson","title":"Johnson","text":"<p>The algorithm of Johnson applies the Dijkstra algorithm \\(n\\)-times, which is faster than using Floyd-Warshall. However, as we have discussed before, Dijkstra only works for graphs without negative edge costs. Now, Johnson modifies the edge costs in a clever way such that they are all positive but without changing the outcome of the algorithm.</p> <p>This is for example a problem if we simply add the minimum weight in the graph to all edges. While this eliminates negative weights, the outcome might change: say we have a shortest path crossing \\(n\\) edges. The minimum weight is added \\(n\\)-times to the path. There might exist some more direct path with fewer edge crossings and thus the minimum weight is added fewer times. This path might now become the shortest path.</p> <p>This problem is overcome by using a telescoping sum to modify the cost function. We chose some height \\(h(u) \\in \\mathbb{R}\\) for each vertex such that for any edge in the graph, the modified cost function defined below remains positive.</p> \\[ \\hat{c}(u,v) = c(u,v) + h(u) - h(v) \\] <p>Due to the nature of the telescoping sum, the distance of any path between \\(s\\) and \\(t\\) is defined as follows. As we can see, the final distance contains only the height of the starting and ending vertex - all other heights have canceled out.</p> \\[\\begin{align} \\hat{d}(s, t) &amp;= \\sum_{i=0}^{K-1} \\hat{c}(v_i,v_{i+1})\\\\ &amp;= \\sum_{i=0}^{K-1} \\Bigg(c(v_i,v_{i+1}) + h(v_i) - h(v_{i+1})\\Bigg)\\\\ &amp;= \\Bigg(\\sum_{i=0}^{K-1} c(v_i,v_{i+1})\\Bigg) + h(v_0) - h(v_k)\\\\ &amp;= \\Bigg(\\sum_{i=0}^{K-1} c(v_i,v_{i+1})\\Bigg) + h(s) - h(t) \\end{align}\\] <p>To compute the height function, we add a vertex \\(z\\) and connected it to all other vertices in the graph with \\(c(z,v)=0\\). The height of some vertex \\(u\\) is then defined as the shortest path from \\(z\\) to \\(u\\). Due to the construction of the graph, \\(h(u) \\leq 0 \\forall u \\in V\\). Further, the following holds for any \\((uv) \\in E\\):</p> \\[\\begin{align} h(v) &amp;\\leq h(u) + c(u,v)\\\\ 0 &amp;\\leq c(u,v) +h(u) - h(v) \\end{align}\\] <p>The height computation requires the graph to have no negative cycles.</p>"},{"location":"bachelors/ads/graph-theory/#minimum-spanning-tree-mst","title":"Minimum spanning tree (MST)","text":"<p>A Spanning tree is a connected subgraph with minimum weights. To find such a tree we can look for the minimum edge incident to each vertex and add it to the MST. This, however, most certainly leaves us with a forest instead of a tree - we now have a series of connected components. To connect the forest into a single tree, we repeatedly add the minimum weight edge on each ZHK to the MST.</p> <p>While the MST results in the minimum graph weight, it should not be confused with an alternative to find the shortest paths.</p>"},{"location":"bachelors/ads/graph-theory/#uniqueness","title":"Uniqueness","text":"<p>In graphs with unique weights, the MST is always unique.</p>"},{"location":"bachelors/ads/graph-theory/#algorithms","title":"Algorithms","text":"<p>The following chapters describe three algorithms that search for the MST.</p> Algorithm Running tim Boruvka \\(O((n + m) \\cdot log(n))\\) Prim \\(O((n + m) \\cdot log(n))\\)"},{"location":"bachelors/ads/graph-theory/#boruvka","title":"Boruvka","text":"<p>This first algorithm was already described in the introduction to the MSTs. The following pseudocode describes it in more details. In the first iteration, every vertex is its own ZHK. One iteration of the loop has a duration of \\(O (n+m)\\), and it is executed \\(log(n)\\)-times, as after each iteration, the number of ZHKs is halved.</p> <pre><code>Boruvka(V,E)\n    F = {} // edge set of the spanning-tree\n    while F not spanning-tree:\n        S1,...,Sk = ZHK(V, F)\n        e1,...,ek = minEdges(V,E)\n\n        F.append(e1,...,ek)\n</code></pre>"},{"location":"bachelors/ads/graph-theory/#prim","title":"Prim","text":"<p>Prim's algorithm is quite similar but here we look at one vertex after the other. Some starting vertex represents the first ZHK, which is getting extended after each iteration until the spanning-tree is complete. In each iteration, the minimum weighted edge incident to the ZHK is added.</p> <pre><code>Prim(V,E,s):\n    prioQ = queue(V, infinity)\n    S = {}\n    d[s] = 0\n    for v in V &amp;&amp; v != s: d[v] = infinity\n\n    prioQ.decrease_key(s, 0)\n    while prioQ.notempty():\n        v = prioQ.deq()\n        S.append(v)\n\n        for w in v.adj():\n            if !S.contains(w):\n                d[v] = min(d[v], c(v,w))\n                decrease_key(v, d[v])\n</code></pre>"},{"location":"bachelors/ads/graph-theory/#kruskal","title":"Kruskal","text":"<p>This algorithm sorts the edges by their weights (in ascending order), and then iteratively evaluates each edge. If it connects two independent ZHKs, the edge is added to the MST. To start, each vertex is one ZHK. Implemented like this, the algorithm will run in \\(O(n \\cdot m)\\) (\\(m\\) iterations, and each iteration requires \\(n\\) comparisons to check if the vertices are in the same ZHK). The running time can be improved to \\(O((n+m) \\cdot log(n))\\) by using the data structure union-find to keep track of the ZHKs.</p> <pre><code>func Kruskal(V Vertex[], E Edge[]) Edge[] {\n  F := make(Edge[], 0)\n  ZHK := new UnionFind(V)\n  E = E.sort()\n\n  for e := range E {\n    if !ZHK.same(e.u, e.v) {\n      ZHK.union(e.u, e.v)\n      F.add(e)\n    }\n  }\n  return F\n}\n</code></pre> A note on the running time <p>If analysed like this, the running time of the algorithm would \\(O(n \\cdot m)\\). However, due to how the UnionFind algorithm is designed, an amortised analysis provides us with a better running time. </p> <p>The worst case running time of a union is said to be </p> \\[ \\Theta(\\text{min}\\{\\text{ZHK}(u), \\text{ZHK}(v)\\}) = \\Theta(n/2) = \\Theta(n) \\] <p>This worst case, however, is only the case in a few cases as with every iteration the sets are at least being  doubled in size. This leads to a mean running time of \\(O(log(n))\\).</p>"},{"location":"bachelors/ads/graph-theory/#layered-graphs","title":"Layered graphs","text":"<p>Sometimes, it is beneficial to modify a given graph for an improved algorithm performance. An approach that is often taken is to create multiple layers of the same graph, where the layers serve as a sort of memory. An example for such a problem is finding the shortest path in a graph where \\(k\\) cheats are allowed. A cheat is defined as essentially setting the weight of an edge to \\(0\\).</p> <p>To solve this problem, our modified graph \\(G'\\) contains \\(k+1\\) copies of the original graph (including all edges). Next, we add the edges such that for every edge \\(uv \\in E\\), we add the edge \\(u_iu_{i+1}\\) with a weight of \\(c(u_i,u_{i+1}) = 0\\). Now, as long as we are in the first layer, we have cheated on \\(0\\) edges. Once we pass a layer down, we have cheated on one additional layer.</p> <p>The problem in this modified graph \\(G'\\) is now to find the shortest path between \\(s_0\\) and \\(d_k\\).</p>"},{"location":"bachelors/ads/graph-theory/#graphs-and-matrices","title":"Graphs and matrices","text":"<p>Matrices are actually quite close to graphs. In this chapter, we will see three possible applications on graphs. We consider \\(i\\)-\\(j\\)-walks of length \\(K\\) (here, we refer to the length as the number of crossed edges). We always start with a matrix of size \\(n \\times n\\). Additionally, we know that any \\(i\\)-\\(j\\)-walk has a before-last vertex \\(s\\).</p> <p>\\(L_{ij}^{(K)}\\): does an \\(i\\)-\\(j\\)-walk of length \\(k\\) exist? \\(L^{(1)}\\) is the adjacency list.</p> \\[ L_{ij}^{(K)} = \\bigvee_{s=1}^n \\big(L_{is}^{(K-1)} \\land L_{sj}^{(1)}\\big) \\] <p>\\(M_{ij}^{(K)}\\): what's the minimum cost for an \\(i\\)-\\(j\\)-walk of length \\(K\\)? \\(M^{(1)}\\) is the adjacency list but instead of storing \\(1\\) and \\(0\\), we store the costs of edges connecting two vertices.</p> \\[ M_{ij}^{(K)} = \\text{min}_{s=1..n}\\big\\{M_{is}^{(K-1)} + M_{sj}^{(1)}\\big\\} \\] <p>\\(N_{ij}^{(K)}\\): how many \\(i\\)-\\(j\\)-walk of length \\(K\\) exist? \\(N^{(1)}\\) is the adjacency list.</p> \\[ N_{ij}^{(K)} = \\sum_{s=1}^n N_{is}^{(K-1)} \\cdot N_{sj}^{(1)} \\] <p>This last formula is actually a simple matrix multiplication: \\(N^{(K)}\\) is equal to the \\(K\\)-th power of the adjacency matrix.</p>"},{"location":"bachelors/ads/graph-theory/#use-cases","title":"Use cases","text":"<p>Counting the number of triangles (in a graph without loops):  A triangle is defined as a \\(u\\)-\\(u\\)-walk of length \\(3\\). To compute the number of such triangles, we simply take the third power of the adjacency list \\(A_G\\), and take the sum over the diagonal: \\(tr(A_G^3)/3\\). The division by \\(3\\) is necessary because each triangle is found three times (once for each of the three vertices).</p> <p>Is every vertex reachable from every other vertex (in directed graphs): For this use case, the graph must be slightly modified. A loop is added on each vertex, allowing us to find walks of length \\(\\leq K\\). Any two vertices, are connected by a walk of length \\(\\leq n-1\\), if a walk exists. We can thus compute \\(A_G^{n-1}\\) and check that all entries  are \\(&gt; 0\\). </p> <ul> <li>Naive algorithm (multiplying \\(n-1\\)-times): $O(n^4)</li> <li>Iterative squaring (\\(A^n = A^\\frac{n}{2} \\cdot A^\\frac{n}{2}\\)): \\(O(n^3 \\cdot log(n))\\)</li> <li>Strassen (dividing an \\(n \\times n\\) matrix into four \\(\\frac{n}{2}\\times \\frac{n}{2}\\) matrices): \\(\\Theta(n^{2.807})\\),   useful once \\(n &gt; 1000\\), otherwise the constant factor is too big</li> <li>Best algorithm: \\(O(n^{2.3715})\\), in reality not applicable due to the constant factor being too big</li> </ul> <ol> <li> <p>Using a priority queue (e.g. MinHeap)\u00a0\u21a9\u21a9</p> </li> <li> <p>Requires the graph to have no negative cycles\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"bachelors/ads/search-sort/","title":"Search and Sort","text":""},{"location":"bachelors/ads/search-sort/#search-algorithms","title":"Search algorithms","text":"<p>We have seen two search algorithms: one working on un-sorted arrays, and one working on sorted arrays.</p>"},{"location":"bachelors/ads/search-sort/#unsorted-array-linear-search","title":"Unsorted array (Linear search)","text":"<p>The linear search algorithm is pretty simple: we iterate through all elements in the array and stop once we found the element we were looking for. This operation has \\(O(n)\\), and it's the best we can do on unsorted arrays. Because, in case we are looking for an element that does not exist in the array, we must look at every element to be sure of it.</p>"},{"location":"bachelors/ads/search-sort/#sorted-array-binary-search","title":"Sorted array (Binary search)","text":"<p>The binary search algorithm requires the array to be sorted, such that \\(A[i-1] \\leq A[i] \\leq A[i+1] \\forall i \\in [1,n-2]\\).</p> <p>The algorithm always compares the value \\(b\\) its looking for with the central element of the array \\(A[n/2]\\). If this value is bigger than \\(b\\), the algorithm recursively calls itself by passing the remaining array to the left of the central element. If it is smaller than \\(b\\), the recursion is run on the right part, and if \\(A[n/2] = b\\), we already found the solution.</p> <p>Binary search runs in \\(O(log_2(n))\\), and this is the best we can do. The proof for this is based on the fact that a decision tree of any search algorithm has \\(n+1\\) leafs (one for each value in the array, and one additional element signaling that the value is not present in the array). The depth of such a binary decision tree is \\(log_2(n)\\) and thus any algorithm must make at least that many comparisons.</p>"},{"location":"bachelors/ads/search-sort/#sorting-algorithms","title":"Sorting algorithms","text":"<p>In this chapter we will be looking at a series of sorting algorithms. The below table lists all algorithms and notes their complexity in terms of number of compare and copy operations, as well as the additional memory being required.</p> Algorithm Compare Copy Extra memory Bubble sort \\(O(n^2)\\) \\(O(n^2)\\) \\(O(1)\\) Selection sort \\(O(n^2)\\) \\(O(n)\\) \\(O(1)\\) Insertion sort \\(O(n \\cdot log(n))\\) \\(O(n^2)\\) \\(O(1)\\) Merge sort \\(O(n \\cdot log(n))\\) \\(O(n \\cdot log(n))\\) \\(O(n)\\) Quick sort \\(O(n \\cdot log(n))\\) \\(O(n \\cdot log(n))\\) \\(O(1)\\) Heap sort \\(O(n \\cdot log(n))\\) \\(O(n \\cdot log(n))\\) \\(O(1)\\) <p>We have proven in the lecture that the best possible complexity for (comparison-based) sorting algorithms is \\(O(n log(n))\\). The proof is similar to the one for sorting algorithms. The number of nodes in the decision tree is greater or equal the number of possible outputs, which is \\(n!\\) (there are \\(n!\\) many different permutations of an array). The depth of such a decision tree is \\(log(2!)-1 \\geq \\Omega(n log(n))\\), and it requires thus that many comparisons.</p>"},{"location":"bachelors/ads/search-sort/#bubble-sort","title":"Bubble sort","text":"<p>Invariant \\(I(k)\\): the \\(k\\) biggest elements are at the correct (and final) position.</p> <p>This algorithm iterates many times (at most \\(n\\) to be exact) through the entire array. In one iteration, it always compares neighbouring entries. If they are in the wrong order, the elements are swapped. This is done until in one iteration, no swap was made, or at most \\(n\\)-times.</p> <p>Complexity: Compare: \\(\\Theta(n^2)\\), Swap: \\(O(n^2)\\)</p> Pseudocode <pre><code>func BubbleSort(A int[], n int){\n    for _ := range n {\n        for i := range n-1 {\n            if(A[i] &gt; A[i+1]) A[i+1], A[i] = A[i], A[i+1]\n        }\n    }\n}\n</code></pre>"},{"location":"bachelors/ads/search-sort/#selection-sort","title":"Selection sort","text":"<p>Invariant \\(I(k)\\): the \\(k\\) biggest elements are at the correct (and final) position.</p> <p>Selection sort searches the biggest element in the array, and swaps it with the last element. In the next iteration, it searches for the next largest element, and puts it right in front of the largest element. This process is repeated \\(n\\) times, at which point the array is sorted.</p> <p>Complexity: Compare: \\(\\Theta(n^2)\\), Swap: \\(O(n)\\)</p> Pseudocode <pre><code>func SelectionSort(A int[], n int){\n    arg_max := 0\n\n    for i := range n{\n        for j := range (1,n-i) {\n            if (A[arg_max] &lt; A[j]) arg_max = j\n        }\n        A[arg_max], A[n-i-1] = A[n-i-1], A[arg_max] \n    }\n}\n</code></pre>"},{"location":"bachelors/ads/search-sort/#insertion-sort","title":"Insertion sort","text":"<p>Invariant \\(I(k)\\): the first \\(k\\) elements are correctly sorted.</p> <p>In iteration \\(k\\), the algorithm takes the element \\(A[k]\\) and places it in \\(A[0:k]\\) such that the ordering in this subarray is correct. Let \\(j\\) the index in the subarray where the element \\(A[k]\\) will be placed. All elements \\(A[j:k-1]\\) are required to move one position to their right. The correct position in the subarray can be found using the binary search algorithm, as it is known to be sorted.</p> <p>Complexity: Compare: \\(O(n \\cdot log(n))\\), Swap: \\(O(n^2)\\)</p> Pseudocode <pre><code>func InsertionSort(A int[], n int){\n    for k := range A {\n        k_val := A[k]\n        j := bin_search(A[0:k])\n\n        for i := k; i &gt; j; k-- {\n            A[i] = A[i-1]\n        }\n        A[j] = k_val\n    }\n}\n</code></pre>"},{"location":"bachelors/ads/search-sort/#merge-sort","title":"Merge sort","text":"<p>Recursion: Both halves of the array are correctly sorted.</p> <p>Merge sort is the only algorithm taking a significant additional amount of space, as it must temporarily store an array of size \\(n\\) in addition to the original array. It uses the divide and conquer approach: the array is halved and recursively sorted. Both halves are than merged together which can be done in \\(O(n)\\) because both halves are already sorted.</p> <p>Complexity: Compare: \\(O(n \\cdot log(n))\\), Swap: \\(O(n \\cdot log(n))\\) (one level is \\(O(n)\\), and there are \\(log(n)\\) recursion levels)</p> Pseudocode <pre><code>func MergeSort(A int[], l int, r int) {\n    if l &lt; r {\n        mid = (l + r)  / 2\n        MergeSort(A, l, mid)        // sort left halve\n        MergeSort(A, mid + 1, r)    // sort right halve\n        Merge(A, l, mid, r)         // merge sorted halves\n    }\n}\n\nfunc Merge(A int[], l int, mid int, r int) {\n    B := int[r - l + 1]\n    i, j, k := l, mid + 1, 1\n\n    while i &lt;= mid &amp;&amp; j &lt;= r {\n        if A[i] &lt; A[j] {\n            B[k] = A[i]\n            k++; i++;\n        } else {\n            B[k] = A[j]\n            k++; j++;\n        }\n    }\n    A[l:r] = B\n}\n</code></pre>"},{"location":"bachelors/ads/search-sort/#quick-sort","title":"Quick sort","text":"<p>Recursion: All elements left to the pivot are smaller, all elements to the right are bigger.</p> <p>The QuickSort algorithm is a randomized and recursive algorithm. In every recursion step, a random pivot element is chosen. Next, the algorithm iterates through the array, making sure that the pivot element is put at a position where all elements to its left are smaller, and all elements to its right are bigger. This will also be the final position of the pivot. This procedure is then recursively applied on both sides of the array.</p> <p>Due to its probabilistic nature, the algorithm has a worst case complexity of \\(O(n^2)\\). However, this is only the case if the chosen pivot is always the biggest or smallest element of the array. As this is very unlikely, the mean complexity is \\(O(n \\cdot log(n))\\).</p> <p>Complexity: Compare: \\(O(n \\cdot log(n))\\), Swap: \\(O(n \\cdot log(n))\\)</p> Pseudocode <pre><code>func QuickSort(A int[], l int, r int) {\n    if l &lt; r {\n        pivot_index = MoveAroundPivot(A, l, r)\n        QuickSort(A, l, pivot_index-1)\n        QuickSort(A, pivot_index+1, r)\n    }\n}\n\nfunc MoveAroundPivot(A int[], l int, r int) {\n    // use the last element in the curernt array section as pivot. \n    // can also be any random element\n    pivot = A[r]         \n    il, ir := l, r-1\n\n    while(il &lt; ir) {\n        // search for next pair of elements that can be swaped\n        while(A[il] &lt;= pivot &amp;&amp; il &lt; r) il++\n        while(A[ir] &gt; pivot &amp;&amp; ir &gt; l) ir--\n        if(il &lt; ir) {\n            A[il], A[ir] = A[ir], A[il]\n        }\n    }\n    // put pivot element in the middle\n    A[il], A[r] = A[r], A[il]\n\n    return il\n}\n</code></pre> Running QuickSort deterministically in \\(0(n \\cdot log(n))\\) <p>It is possible to have a deterministic running time of \\(0(n \\cdot log(n))\\), if we are able to find the median (thus   the pivot element) in \\(O(n)\\). In reality this is not one for the QuickSort algorithm.</p> <p>The QuickSelect algorithm finds the median recursively in \\(O(n)\\). Actually, it is able to find the \\(i\\)-th smallest   element, and the median is then a special case of this algorithm.</p> <p>We need to find a pivot that is not too close to the ends of the given array. In fact, it must not be under the first   \\(\\epsilon n\\) elements. In the worst case, the recursion runs on \\((1-\\epsilon)n\\) elements. Using the master-theorem,   we can compute a running time of \\(O(n)\\):</p> <ul> <li>\\(T(n) \\leq T((1-\\epsilon)n) + cn\\)</li> <li>\\(\\leq T((1-\\epsilon)^2n) + c(1-\\epsilon)n + cn\\)</li> <li>\\(\\leq T((1-\\epsilon)^3n) + c(1-\\epsilon)^2n + c(1-\\epsilon)n + cn\\)</li> <li>\\(...\\)</li> <li>\\(\\leq T(1) + cn \\sum_{i=0}^{...}(1-\\epsilon)^i \\leq O(n)\\)</li> </ul> <p>To achieve this, the algorithm splits the input into groups of five elements, and then finds the median of these   elements in a linear time factor.</p> <p>\\(\\text{QuickSelect}(A,i)\\)</p> <ol> <li>Select pivot \\(p\\):<ol> <li>Split \\(A\\) into groups of five</li> <li>Find the median of each group, and put them into \\(A'\\) of length \\(\\lceil \\frac{n}{5} \\rceil\\)</li> <li>\\(p = \\text{QuickSelect}(A',\\frac{1+ \\lceil n/5 \\rceil}{2})\\)</li> </ol> </li> <li>\\(k = \\text{Split}(A[1..n],p)\\), split on pivot where \\(k\\) is the pivot index</li> <li>Recursion:<ul> <li>\\(i=k\\): return \\(k\\)</li> <li>\\(i&lt;k\\): \\(\\text{QuickSelect}(A[1..k-1],i)\\)</li> <li>\\(i&gt;k\\): \\(\\text{QuickSelect}(A[k+1..n],i-k)\\)</li> </ul> </li> </ol> <p>With this algorithm we find a pivot where at least \\(3n/10\\) elements are smaller and \\(3n/10\\) elements are bigger than   \\(p\\). Our recursion finds the pivot in \\(A'\\) to be in the middle, and thus \\(n/10\\) elements are smaller than \\(p\\) (half of   \\(A'\\)s size). Additionally, we know that for each element in \\(A'\\), there are two elements that were left out that were    smaller than those other medians to the left of \\(p\\).</p> <p>To find the running time, we use the master-theorem. We have a double recursion. The recursion in 1c is \\(T(n/5)\\), the   recursion in 3 is \\(T(7n/10)\\), giving us \\(T(n) \\leq T(n/5) + T(7n/10) + cn\\). We state that \\(T(n) \\leq 10cn\\), which we    prove through induction: </p> <ul> <li>\\(T(n) \\leq T(n/5) + T(7n/10) + cn\\)</li> <li>\\(\\leq 10c \\frac{n}{5} + 10cn\\frac{7}{10} + cn\\)</li> <li>\\(=10c(\\frac{9}{10}n) + cn\\)</li> <li>\\(= 10cn \\leq O(n)\\)</li> </ul>"},{"location":"bachelors/ads/search-sort/#heap-sort","title":"Heap sort","text":"<p>Recursion: The root of the heap is the biggest element of the array.</p> <p>Unlike all other sorting algorithms, this one makes use of an alternative data structure. In fact, the sorting algorithm only uses the basic operations of the data structure to sort an array. The data structure at stake is the Max-heap. This is a complete binary tree where the keys are the values of the array. The key of each vertex must be greater or equal to all keys of its descendants. More on this data structure is to be found in the respective chapter.</p> <p>As mentioned, the algorithm is fairly simple. The max-heap is created using the array, and then the maximum is extracted until the hea is empty. The order of these maximums is the reverse order of the array. Due to the max-heaps structure, the sorting algorithm has memory accesses that are jumping all over the memory, which somewhat reduces the speed.</p> <p>As shown in the chapter about the max-heap data structure, the operations <code>Insert</code> and <code>ExtractMax</code> both have a time complexity of \\(log(n)\\). The complete time complexity comes from the fact that both operations are executed \\(n\\)-times to get the sorted array. Although the algorithm below would let you think that additional memory is required, some clever thinking allows the array to be sorted in place by using it to store the heap.</p> <p>Complexity: Compare: \\(O(n \\cdot log(n))\\), Swap: \\(O(n \\cdot log(n))\\)</p> Pseudocode <pre><code>func HeapSort(A int[], n int){\n    H := new Heap()\n    for v := range A {\n        H.Insert(v)\n    }\n    for i := range n-1..0 {\n        A[i] = H.ExtractMax()\n    }\n}\n</code></pre>"},{"location":"bachelors/la/","title":"Linear Algebra","text":""},{"location":"bachelors/tcs/","title":"Theoretical Computer Science","text":""},{"location":"bachelors/tcs/complexity/","title":"Complexity","text":"<p>Problems are divided into different complexity classes. The most used complexity types are time-complexity and space-complexity. These complexity classes can also help to stop infinite calculations: if we know the complexity of a certain problem, but the algorithm runs longer than expected on working out the solution, the calculation can be stopped, and we know that no solution exists.</p> <p>The time-complexity of a turing-machine is defined as the complexity of the longest calculation on some input with length \\(n\\). More formally: \\(\\text{Time}_M(n) = max \\{\\text{Time}_M(x) \\mid x \\in \\Sigma^n\\}\\).</p> <p>To compute the memory-complexity of a k-tape turing-machine \\(M\\), we define multiple instances of the space function. Let \\(C\\) be a configuration of the TM, and \\(\\alpha_i\\) the content of tape \\(i\\). The memory-complexity is defined as</p> \\[\\begin{align} \\text{Space}_M(C) &amp;= max\\{|\\alpha_i| \\mid i = 1, ..., k\\}\\\\ \\text{Space}_M(x) &amp;= max\\{\\text{Space}_M(C_i) \\mid i = 1,...,l\\}\\\\ \\text{Space}_M(n) &amp;= max\\{\\text{Space}_M(x) \\mid x \\in \\Sigma^n\\} \\end{align}\\]"},{"location":"bachelors/tcs/complexity/#complexity-classes","title":"Complexity classes","text":"<p>Problems are generally separated into problems that are solvable using a deterministic TM, and solvable using a non- deterministic TM.</p> <p>The most important classes are:</p> <ul> <li>P: the class of practically decidable problems. A problem is practically solvable if a polynomial algorithm   exists.</li> <li>NP: the class of practically decidable problems with the use of a non-deterministic turing-machine.</li> </ul>"},{"location":"bachelors/tcs/complexity/#deterministic-classes","title":"Deterministic classes","text":"<p>We now look at a couple of classes for deterministic problems.</p> \\[\\begin{align} TIME(f) &amp;= \\{L(B) \\mid B \\text{ is an MTM with Time}_B(n) \\in O(f(n))\\}\\\\ SPACE(g) &amp;= \\{L(A) \\mid A \\text{ is an MTM with Space}_B(n) \\in O(g(n))\\}\\\\ DLOG &amp;= SPACE(log_2n)\\\\ P &amp;= \\bigcup_{c \\in \\mathbb{N}}TIME(n^c)\\\\ PSPACE &amp;= \\bigcup_{c \\in \\mathbb{N}}SPACE(n^c)\\\\ EXPTIME &amp;= \\bigcup_{n \\in \\mathbb{N}}TIME(n^{n^d}) \\end{align}\\] <p>To continue, we are talking about constructable functions:</p> <ul> <li>Platzkonstruierbar: \\(s: \\mathbb{N} \\to \\mathbb{N}\\). A function called platzkonstruierbar is, if there exists   a single-tape turing-machine \\(M\\) such that \\(\\text{Space}_M(n) \\leq s(n)\\) for all \\(n \\in \\mathbb{N}\\) and generates   for any input \\(0^n, n \\in \\mathbb{N}\\) the word \\(0^{s(n)}\\) on its working-tape, and stops on its accepting state.</li> <li>Zeitkonstruierbar: \\(t: \\mathbb{N} \\to \\mathbb{N}\\). A function is called zeitkonstruierbar if there exists a   multi-tape turing-machine \\(M\\) such that \\(\\text{Time}_A(n) \\in O(t(n))\\) and for every input \\(0^n, n \\in \\mathbb{N}\\),   the word \\(0^{t(n)}\\) is generated on its working-tape, and \\(M\\) stops on its accepting state.</li> </ul> <p>We can define the following relations between above classes:</p> <ul> <li>\\(TIME(t(n)) \\subseteq SPACE(t(n))\\): every TM working in time \\(n\\) cannot write on more than \\(n\\) cells on the tapes,   as the TM can move its head by only one cell on every instruction. Thus: \\(P \\subseteq PSPACE\\)</li> <li>\\(SPACE(s(n) \\subseteq \\bigcup_{c\\in \\mathbb{N}} TIME(c^{s(n)})\\). The TM cannot run longer than it takes to check every   possible configuration. Otherwise, there is a duplicate configuration, and the TM runs indefinitely (the function \\(s\\)   must be platzkonstruierbar). Thus: \\(DLOG \\subseteq P\\), \\(PSPACE \\subseteq EXPTIME\\).</li> </ul> <p>From above relations, we can find the following fundamental hierarchy of deterministic complexity classes:</p> \\[ DLOG \\subseteq P \\subseteq PSPACE \\subseteq EXPTIME \\]"},{"location":"bachelors/tcs/complexity/#non-deterministic-classes","title":"Non-deterministic classes","text":"<p>The non-deterministic classes contain problems that can be solved using a non-deterministic turing-machine. The NTM is capable of choosing the \"best\" input, meaning, it chooses the input leading to the correct result that is most efficient.</p> <p>In such a computation, the time-complexity for a TM \\(M\\) on an input \\(x\\) ($\\text{Time}_M(x)) is defined as the shortest path to an accepting state (inside an NTM tree of states). For some input of length \\(n\\), this generalizes to</p> <p>$\\text{Time}_M(n) = max{\\text{Time}_M(x) \\mid x \\in L(M) \\cap \\Sigma^n}</p> <p>The space-complexity is related to the time complexity, as it is defined as the longest configuration in above described computation.</p> <p>We define the following complexity classes</p> \\[\\begin{align} NTIME(f) &amp;= \\{L(B) \\mid B \\text{ is an N-MTM with Time}_B(n) \\in O(f(n))\\}\\\\ NSPACE(g) &amp;= \\{L(A) \\mid A \\text{ is an N-MTM with Space}_B(n) \\in O(g(n))\\}\\\\ NLOG &amp;= NSPACE(log_2n)\\\\ NP &amp;= \\bigcup_{c \\in \\mathbb{N}}NTIME(n^c)\\\\ NPSPACE &amp;= \\bigcup_{c \\in \\mathbb{N}}NSPACE(n^c)\\\\ \\end{align}\\] <p>We can put those classes into relations, that are valid for all functions \\(t\\) and \\(s\\) with \\(s(n) \\geq log_2n\\):</p> <ul> <li>\\(NTIME(t) \\subseteq NSPACE(t)\\)</li> <li>\\(NSPACE(s) \\subseteq \\bigcup_{c \\in \\mathbb{N}}(c^{s(n)})\\)</li> </ul> <p>Further, we can also put those functions in relation with the deterministic complexity classes:</p> <ul> <li>\\(TIME(t) \\subseteq NTIME(t)\\)</li> <li>\\(SPACE(t) \\subseteq NSPACE(t)\\)</li> <li>\\(NTIME(s(n)) \\subseteq SPACE(s(n)) \\subseteq \\bigcup_{c \\in \\mathbb{N}} TIME(c^{s(n)})\\)</li> </ul>"},{"location":"bachelors/tcs/complexity/#np-hard-and-np-complete","title":"NP-hard and NP-complete","text":"<p>The two classes NP-hard and NP-complete define sets of problems.</p> <ul> <li>A language \\(L\\) is called NP-hard if any language \\(L' \\in NP\\) can be reduced to \\(L\\): \\(L' \\leq L\\).</li> <li>A language \\(L\\) is called NP-complete if it is NP-hard, and \\(L \\in NP\\).</li> </ul> <p>If some NP-hard language \\(L\\) is in \\(P\\), then \\(P=NP\\), meaning that all practically solvable problems using a non- deterministic turing-machine are also practically solvable using a deterministic turing-machine. Our current  understanding is, however, that \\(P \\neq NP\\). </p>"},{"location":"bachelors/tcs/complexity/#problems","title":"Problems","text":"<p>The first problem we look at called \\(SAT\\) (satisfiability) is NP-complete, thus all other problems can be reduced to a SAT problem in polynomial time. A KNF is defined by variables \\(x_i\\) and their literals \\(x_i,\\overline{x_i}\\). These literals create a set of clauses, where the literals are combined in a disjunction \\(\\lor\\). These clauses are then combined in a conjunction \\(\\land\\). See the following example of a KNF:</p> \\[ \\Phi = (x_1 \\lor x_2) \\land (x_1 \\lor \\overline{x_2} \\lor \\overline{x_3}) \\land (\\overline{x_1} \\lor x_3) \\land ( \\overline{x_2}) \\] <p>The SAT problem tries to find out if the KNF has an input that evaluates the output to true. One input can be checked in polynomial time, as the KNF can simply be evaluated. However, finding one that evaluates to true, requires a non- deterministic TM to have result in polynomial time. It is simple to create a tree containing all possible input configurations (each variable evaluating to 0 or 1).</p> \\[ SAT = \\{ x \\in \\Sigma_{logic}^* \\mid x \\text{ encodes a satisfiable KNF} \\} \\] <p>A special case of the \\(SAT\\) problem is the \\(3SAT\\) problem, where each clause in the KNF can only contain three literals. The input KNF can be recoded to a conjunction of multiple KNF with three literals. See the following transformation.</p> \\[\\begin{align} \\Phi &amp;= (x_1 \\lor \\overline{x_2} \\lor x_5 \\lor \\overline{x_7} \\lor x_4 \\lor \\overline{x_6})\\\\ \\Phi' &amp;= (x_1 \\lor \\overline{x_2} \\lor y_1) \\land (\\overline{y_1} \\lor x_5 \\lor y_2) \\land (\\overline{y_2} \\lor \\overline{x_7} \\lor y_3) \\land (\\overline{y_3} \\lor x_4 \\lor \\overline{x_6}) \\end{align}\\] <p>The \\(CLIQUE\\) problem is defined on a graph. We search for sub-graphs of size \\(k\\) (or \\(y\\) depending on how the input is defined) that is completely connected.</p> \\[ CLIQUE = \\{ x\\#y \\mid x,y \\in \\Sigma_{bool}^*, x \\text{ encodes a graph } G_x \\text{ containing a y-clique} \\} \\] <p>The \\(IND-SET\\) problem is somewhat the opposite of above problem. It looks for sub-graphs in \\(G\\) of size \\(k\\), where all vertices are pairwise not connected.</p> \\[ IND-SET = \\{(G,k) \\mid G \\text{ has } k\\text{-independent-sets} \\} \\] <p>The last problem we looked at during the lectures is the vertex-cover problem, where we search for a set of \\(k\\) vertices, such that every edge of the graph is connected to one of the selected vertices.</p> \\[ VC = \\{ (G,k) \\mid G \\text{ has a vertex-cover of size } k\\} \\]"},{"location":"bachelors/tcs/complexity/#p-reduction","title":"P-reduction","text":"<p>We have seen earlier, that a subset of problems from NP called NP-complete is at least as hard as all other problems in NP. If any of these problems turns out to be in P, all other NP problems can be solved in polynomial time. This is because we can create a P-reduction that translate one problem into a different problem. It is similar to an EE- reduction, but the TM transforming the input must run in polynomial time.</p> <p>A reduction helps us find out the complexity of a problem. If \\(L_1 \\leq_P L_2\\), and \\(L_1\\) is NP-hard, \\(L_2\\) is NP-hard as well. More formally, we define the reduction as follows.</p> <p>Let \\(L_1 \\subseteq \\Sigma_1^*\\) and \\(L_2 \\subseteq \\Sigma_2^*\\), where \\(L_1\\) can be reduced on \\(L_2\\) in polynomial time: \\(L_1 \\leq_P L_2\\) if \\(\\exists\\) a polynomial TM \\(A\\), computing \\(\\forall x \\in \\Sigma_1^*\\) a word \\(A(x) \\in \\Sigma_2^*\\) such that \\(x \\in L_1 \\Leftrightarrow A(x) \\in L_2\\).</p> <p></p> <p>To illustrate this, let's have a couple of examples.</p> <p>\\(SAT \\leq_P CLIQUE\\): The TM \\(A\\) converts the KNF into a graph problem, where each literal becomes a vertex. Vertices of one clause are logically regrouped into groups \\(F\\). The edges are constructed as follows: each literal is connected to all other vertices outside its group \\(F\\) except for the negated literal (\\(x_i\\) has no edge towards \\(\\overline{x_i}\\)). This graph can now be passed to a TM \\(B\\) with \\(L(B) = CLIQUE\\), and \\(k\\) is set to the number of clauses. If the KNF is satisfiable, the graph will contain a clique of size \\(k\\). We have thus converted a problem \\(SAT(\\Phi)\\) to \\(CLIQUE(G,k)\\)</p> <p>\\(CLIQUE \\leq_P IND-SET\\): The TM \\(A\\) simply takes the input graph \\(G\\) and converts it to \\(G^C\\), which means that existing edges are removed, and replaced with the set of all possible edges between vertices that were not present in \\(G\\). The value of \\(k\\) is kept the same. If the original graph contained a clique of size \\(k\\), the graph complement now contains \\(k\\) pairwise independent vertices (as before the complement, they were fully connected). We have thus converted a problem \\(CLIQUE(G,k)\\) to \\(IND-SET(G^C,k)\\).</p> <p>\\(CLIQUE \\leq_P VC\\): The TM \\(A\\) again computes the graph complement $G^C. However, \\(k'\\) is set to \\(|V| - k\\). The  complement of a graph having a clique of size \\(k\\) thus has a vertex cover of \\(|V| - k\\). </p> <p>Proof template</p> <p>We want to show \\(L_1 \\leq_P L_2\\).</p> <p>To show this, we build a TM \\(A\\) running in polynomial time that converts a problem instance of \\(L_1\\) into an  instsance of \\(L_2\\). </p> <p>[insert the work of the TM here, typically somthing in the form of what was shown in above examples]</p> <p>This TM obviously runs in polynomial time. [short description why that is]</p> <p>Proof for \\(\\Rightarrow\\): Suppose we have an input \\((...) \\in L_1\\). [show why \\(A(...) \\in L_2\\). if deemed necessary, also show proof for an input \\((...) \\notin L_1 \\Rightarrow A(...) \\notin L_2\\)]</p> <p>Proof for \\(\\Leftarrow\\): Suppose we have an input \\((...) \\in L_2\\). [identical to above proof]</p>"},{"location":"bachelors/tcs/computability/","title":"Computability","text":"<p>Computability is one of the first theories described in computer science. It is used to classify problems into algorithmically solvable and non-solvable problems.</p>"},{"location":"bachelors/tcs/computability/#infinities","title":"Infinities","text":"<p>At first, we must realize that there are different types of infinity. For example, there are more languages than there are turing-machines: \\(|KodTM| &lt; |Pot(\\Sigma^*)|\\). We know however, that an infinite amount of TMs and an infinite amount of words in the power product exist. Let's start with the following definition. We have the sets \\(A\\) and \\(B\\).</p> <ul> <li>\\(|A| \\leq |B|\\), if an injective function \\(f: A \\to B\\) exists.</li> <li>\\(|A| = |B|\\), if \\(|A| \\leq |B|\\) and \\(|B| \\leq |A|\\) (thus a bijective function exists).</li> <li>\\(|A| &lt; |B|\\), if \\(|A| \\leq |B|\\) and no injective function \\(f: B \\to A\\) exists.</li> </ul> <p>We can make a first observation with the two sets \\(|\\mathbb{N}| = |\\mathbb{N}_{even}|\\). One would think that the first set would be bigger, as the second only contains every second number. However, by the above definitions, we find that they are equivalent as the bijective function \\(f(i)=2i\\) exists.</p> <p>A set is defined as countable if \\(|A|\\) is finite, or if \\(|A| = |\\mathbb{N}|\\).</p>"},{"location":"bachelors/tcs/computability/#hilbert-hotel","title":"Hilbert Hotel","text":"<p>The hilbert hotel is an intuition to compare finite sets. We assume an infinite hotel where the rooms are enumerated as \\(1,2,...\\). Now, a new guest arrives, and we want to find a room for this guest. We tell all the current guests that they should move into the room next to theirs (\\(i \\to i+1\\)). Room 1 gets empty, and the new guest can move into this room.</p> <p>Now, if a bus with an infinite amount of guests arrives, we can now tell all the guests in to the room with double the room number of their current room (\\(i \\to 2i\\)).</p>"},{"location":"bachelors/tcs/computability/#examples-of-infinities","title":"Examples of infinities","text":"<p>We have seen that \\(\\mathbb{N}\\) is countable. We can also show that \\((\\mathbb{N} - \\{0\\}) \\times (\\mathbb{N} - \\{0\\})\\) is countable as well. We do this by setting up a matrix where the rows and the columns contain the two sets that are multiplied. We then define a canonical order according to the red arrows. With this order, we can enumerate all values present in said set.</p> <p></p> <p>The same way we can also show that \\(\\mathbb{Q}\\) is countable. The rows contain the enumerators, and the columns the dividers.</p>"},{"location":"bachelors/tcs/computability/#diagonalisation","title":"Diagonalisation","text":"<p>A set that is not countable is the real numbers in the interval \\([0,1] = \\{x \\in \\mathbb{R} \\mid 0 \\leq x \\leq x\\}\\). To prove this, we first define the following table where we enumerate real numbers in said interval.</p> <p></p> <p>We define a new entry to the set \\(C\\) as \\(C=0.C_1C_2C_3...\\) with \\(C_i \\neq a_{ii}, c_i \\notin \\{0,9\\}\\) for all \\(i\\). The new entry, however, is not part of the table as it differs on the diagonal \\(a_{ii}\\) from all other entries (as we defined that \\(C_i \\neq a_{ii}\\)).</p> <p>Similarly, we define a new table that combines \\(w_i \\in \\Sigma^*_{bool}\\) and \\(M \\in KodTM\\). \\(d_ij = 1\\) if \\(M_i\\) accepts the word \\(w_j\\).</p> <p></p> <p>We now construct the diagonal language denoted as \\(L_{diag} \\notin \\mathcal{L}_{RE}\\) (the set of recursively enumerable languages). The constructed language does not yet exist in the set \\(L(M_i)\\).</p> \\[ L_{diag} = \\{w \\in (\\Sigma_{bool})^* \\mid w = w_i \\text{ for some } i \\in \\mathbb{N} - \\{0\\} \\text{ and } d_{ii} = 0\\} \\]"},{"location":"bachelors/tcs/computability/#reduction","title":"Reduction","text":"<p>Reductions allow us to compare different languages regarding their difficulty. Using the reduction we can say that a certain language is at least as or at most as difficult as some other language. We have discussed two types of reduction: EE (Eingabe zu Eingabe) and R (recursive) reduction. These reductions are related:</p> \\[ L_1 \\leq_{EE} L_2 \\Rightarrow L_1 \\leq_R L_2 \\] <p>Further, \\(L \\leq_R L^C \\Leftrightarrow L^C \\leq_R L\\). And, if \\(L \\in \\mathcal{L}_{RE}\\) and \\(L^C \\in \\mathcal{L}_{RE}\\), it follows that \\(L \\in \\mathcal{L}_{R}\\).</p>"},{"location":"bachelors/tcs/computability/#r-reduction","title":"R-Reduction","text":"<p>The less strong reduction of the two takes and input and moves it through a first turing-machine transforming the input on the alphabet from the first language \\(x \\in \\sum_1^*\\). This input is then given to a turing-machine \\(A\\) that decides on \\(L_2\\). The output can then either be given to another TM doing some transformation and giving it back to the first TM (recursion), or give it to an (optional) output TM that then outputs the final answer \\(x \\in L_1\\) or \\(x \\notin L_1\\).</p> <p>The complete turing-machine processes the language \\(L_1\\) by internally using a turing-machine processing the language \\(L_2\\).</p> <p></p>"},{"location":"bachelors/tcs/computability/#ee-reduction","title":"EE-Reduction","text":"<p>An EE-reduction is similar to an R-reduction, but is more restrictive. The output of the TM \\(A\\) must not be processed, the output of \\(A\\) must be the output of \\(B\\). In this reduction, we are only allowed to modify the input given to \\(B\\) before giving it to the TM \\(A\\)</p> <p></p>"},{"location":"bachelors/tcs/computability/#languages-and-their-properties","title":"Languages and their properties","text":"<p>In general, we talk about two groups of languages. They define the behaviour of turing-machines that detect the respective language.</p> <ul> <li>Recursive: The turing-machine will halt on any input and can thus always decide if a certain input is in   the language or not.</li> <li>Recursive enumerable: The turing-machine is not guaranteed to halt. It will detect all inputs that are part of   the language. But the TM might run indefinitely on inputs that do not belong to the language.</li> </ul> <p>Regarding these language classes, we can also say: \\(L \\in L_{RE}, L^C \\in L_{RE} \\Leftrightarrow L \\in L_R\\).</p> <p>The universal language is defined as the set of encoded-turing machines with an input, where the turing-machine accepts the given input. \\(L_U \\notin \\mathcal{L}_{R}\\), \\(L_U \\in \\mathcal{L}_{RE}\\)</p> \\[ L_U = \\{\\text{Kod}(M)\\#w \\mid w \\in \\Sigma_{bool}^* \\text{ and } M \\text{ accepts } w\\} \\] <p>The halting problem is similar to the universal language. However, this time we accept all inputs where the turing-machine halts (thus accepts or rejects) \\(x\\). \\(L_H \\notin \\mathcal{L}_R\\), \\(L_H \\in \\mathcal{L}_{RE}\\)</p> \\[ L_H = \\{\\text{Kod}(M)\\#x \\mid x \\in \\Sigma_{bool}^*, M \\text{ holds on } x\\} \\] <p>The empty language is defined as the set of encoded turing-machines that accept no input. \\((L_{empty})^C \\in \\mathcal{L}_{RE}\\), \\((L_{empty})^C \\notin \\mathcal{L}_R\\)</p> \\[ L_{empty} = \\{\\text{Kod}(M) \\mid L(M) = \\emptyset\\} \\] <p>The complement of the diagonal language. \\((L_{diag})^C \\in \\mathcal{L}_{RE}\\), \\((L_{diag})^C \\notin \\mathcal{L}_{R}\\)</p> \\[ (L_{diag})^C = \\{x \\in \\Sigma_{bool}^* \\mid \\text{if } x = w_i \\text{ for some } i \\in \\mathbb{N} - \\{0\\}, M_i \\text{ accepts the word } w_i\\} \\]"},{"location":"bachelors/tcs/computability/#the-postsche-korrespondenzproblem-pkp","title":"The \"Post'sche Korrespondenzproblem\" (PKP)","text":"<p>The PKP is defined as a pair \\((A,B)\\) where \\(A=w_1,w_2,...\\) and \\(B=v_1,v_2,...\\) with \\(A=B\\). The problem has a set of building blocks \\(w_i\\), \\(v_i\\). By concatenating these blocks, we want to create a pair of string \\(A\\) and \\(B\\). The PKP has a solution if there exists \\(i_1,i_2,i_3,...\\) such that \\(w_{i_1}w_{i_2}w_{i_3}... = v_{i_1}v_{i_2}v_{i_3}...\\).</p> <p>Once we found one solution to the PKP, we know that there are an infinite amount of solution, as the same series of blocks can simply be concatenated.</p> <p>The Modified PKP (MKPK) is quite similar, to the regular PKP, but with a fixed starting word. If a PKP can be decided, a MPKP with the same building blocks can also be decided.</p> <p>Let's have an example. Our building blocks are: \\(((1,1110111,101),(111,1110,01))\\). A possible solution to this instance is:</p> \\[ A=1110111,1,1,101 \\] \\[ B=1110,111,111,01 \\]"},{"location":"bachelors/tcs/computability/#rices-theorem","title":"Rice's Theorem","text":"<p>Before we get to rice's theorem, we must define the languages called \"semanticaly non-trivial decision problems on turing-machines\". Such a language must fulfill the following conditions:</p> <ul> <li>\\(\\exists \\text{ TM } M_1 \\text{ with Kod}(M_1) \\in L\\)</li> <li>\\(\\exists \\text{ TM } M_2 \\text{ with Kod}(M_2) \\notin L\\)</li> <li>For two turing-machines \\(A\\) and \\(B\\), \\(L(A)=L(B)\\) implies \\(\\text{KodTM}(A) \\in L \\Leftrightarrow \\text{KodTM}(B) \\in L\\)</li> </ul> <p>The first two conditions make sure that the language \\(L\\) is non-trivial (it does not contain all TMs, but is not empty either).</p> <p>Rice's theorem tells us that \"all semanticaly non-trivial decision problems on turing-machines cannot be decided\" and thus any such decision problem \\(\\text{Kod}_L \\notin \\mathcal{L}_R\\).</p>"},{"location":"bachelors/tcs/computability/#kolmogorov-complexity","title":"Kolmogorov-Complexity","text":"<p>It is impossible to algorithmically compute the Kolmogorov-complexity \\(K\\) for any \\(x \\in \\{0,1\\}^*\\). This can be further extended: in case the output of the \\(K\\) function is in binary form (\\(\\{0,1\\}^*\\)), we can say that \\(K\\) is not completely recursive.</p> <p>A completely recursive function \\(f: \\Sigma_1^* \\to \\Sigma_2^*\\) requires a turing-machine that halts on any input and computes the function \\(f\\).</p> <p>This is proven indirectly through a proof by contradiction. Suppose an algorithm \\(A\\) exists, computing the Kolmogorov- complexity \\(K(x)\\). Let \\(x_n\\) be the first word in canonical order with \\(K(n) \\geq n\\). We have a second algorithm \\(B_n\\) computing the word \\(x_n\\). \\(B_n\\) is used by \\(A\\), and receives \\(\\lambda\\) as an input. Our algorithm looks as follows:</p> <pre><code>x := lambda\nkn = A(x)\nwhile kn &lt; n:\n  x &lt;= nextWordInCanOrder(x)\n  kn = A(x)\nreturn x\n</code></pre> <p>The above described algorithm \\(B_n\\) has a Kolmogorov-complexity of</p> \\[ |B_n| \\leq \\lceil log_2n \\rceil + c \\Rightarrow K(x_n) \\leq \\lceil log_2n \\rceil + c \\] <p>Here we have a contradiction, because we originally set \\(K(x) \\geq n\\).</p>"},{"location":"bachelors/tcs/fsm/","title":"Finite-State machines","text":"<p>A finite-state machine (Endlicher Automat EA) is a state-machine capable of identifying words of a specific regular language. Before getting started, we again need some notions.</p> <p>An EA is defined as a five-tuple \\(M=(Q,\\Sigma,q_0,F,\\delta)\\).</p> <ul> <li>\\(Q\\): finite set of states</li> <li>\\(\\Sigma\\): input alphabet (symbols that are processed by the EA)</li> <li>\\(q_0 \\in Q\\): starting state</li> <li>\\(F \\subseteq Q\\): set of accepting states</li> <li>\\(\\delta: Q \\times \\Sigma \\to Q\\): the set of all possible state-transitions. The set essentially describes what state   the machine will land in for every possible state combined with every possible symbol of the alphabet.   \\(\\delta(q_i,aw)\\) outputs the state after the machine, which is currently in \\(q_i\\), read the symbol \\(a\\). The function   \\(\\hat{\\delta}\\) is quite similar but outputs the state after reading the entire word</li> <li>\\(Kl[q_i]\\): class of the state \\(q_i\\), describing the form of the words landing in said state</li> </ul> <p>The following additional terms are important.</p> <ul> <li>Configuration: everything that is important for the future - \\((q, aw) \\in Q \\times \\Sigma^*\\) denoting the current   state and the remaining input.</li> <li>Start-configuration: \\((q_0, w) \\in \\{q_0\\} \\times \\Sigma^*\\) denoting the starting state and the full input.</li> <li>End-configuration: every configuration \\(\\in Q \\times \\{\\lambda\\}\\), the configuration after having read the full   input.</li> <li>Step: expresses the relation \\(|_{\\!\\overline{\\;M\\;}}\\) between two configuration such as   \\((q,w) |_{\\!\\overline{\\;M\\;}} (p,x)\\) with \\(w \\in \\Sigma^*\\), \\(w = ax\\), \\(\\delta(q,a)=p\\).</li> <li>Computation C: describes a sequence \\(C = C_0,C_1,...,C_n\\) of configurations such that \\(C_i |_{\\!\\overline{\\;M\\;}}   C_{i+1}\\). If \\(C_0\\) is the start configuration and \\(C_n\\) the end configuration, \\(C\\) is the computation of \\(M\\) on input   \\(x\\).   \\(C\\) can be accepting or rejecting, depending on the final state \\(q_n\\). If \\(q_n \\in F\\), \\(C\\) is accepting.</li> </ul> <p>Now, let's see a couple of above definition using an example state machine. The following EA accepts the language \\(L=\\{w\\in\\Sigma_{bool}^* \\big|\\, |w|_0 \\: mod\\: 3 = 0\\}\\).</p> <p></p> \\[ \\begin{align*} M &amp;= \\big(Q,\\Sigma,q_0,F,\\delta\\big)\\\\ Q &amp;= \\{q_0,q_1,q_2\\}\\\\ \\Sigma &amp;= \\{0,1\\}\\\\ q_0 &amp;= q_0\\\\ F &amp;= \\{q_0\\} \\end{align*} \\] <p>The following table describes the \\(\\delta\\) function.</p> \\(\\delta\\) 0 1 \\(q_0\\) \\(q_1\\) \\(q_0\\) \\(q_1\\) \\(q_2\\) \\(q_1\\) \\(q_2\\) \\(q_0\\) \\(q_2\\) <p>Now, assume we have input \\(x=01101\\), the following computation is made.</p> \\[ (q_0,01101) \\; |_{\\!\\overline{\\;M\\;}} \\; (q_1,1101) \\; |_{\\!\\overline{\\;M\\;}} \\; (q_1,101) \\; |_{\\!\\overline{\\;M\\;}} \\; (q_1,01) \\; |_{\\!\\overline{\\;M\\;}} \\; (q_2,1) \\; |_{\\!\\overline{\\;M\\;}} \\; (q_2,\\lambda) \\] <p>This is equivalent to \\(\\hat{\\delta}(q_0,x)=q_2\\)</p> <p>The classes of above EA can be written as one generalized description with \\(i\\in\\{0,1,2\\}\\):</p> \\[ Kl[q_i] = \\big\\{w \\in \\Sigma^* \\big| \\, |w|_0 \\; mod \\; 3 = i \\big\\} \\]"},{"location":"bachelors/tcs/fsm/#modularity","title":"Modularity","text":"<p>Big state machines for more complicated languages can be expressed as a cartesian product of multiple smaller state-machines. In below picture, we see three machines with the following definitions:</p> \\[ \\begin{align*} L_{top} &amp;= \\{|w|_a \\; mod \\; 3 = 1\\}\\\\ L_{left} &amp;= \\{ubbv \\; \\mid \\; u,v \\in \\{a,b\\}\\}\\\\ L_{comb} &amp;= \\{|w|_a \\; mod \\; 3 = 1\\ \\land ubbv \\; \\mid \\; u,v \\in \\{a,b\\} \\} \\end{align*} \\] <p></p> <p>The formal definition of the above machine:</p> \\[ \\begin{align*} M &amp;= \\{Q, \\Sigma, \\delta, q_0, F\\}\\\\ Q &amp;= Q_{top} \\times Q_{left}\\\\ q_0 &amp;= (p_0, q_0)\\\\ \\delta &amp;= (\\delta_{top}(q,a),\\delta_{left}(p,a))\\\\ F &amp;= L(M_{top}) \\cap L(M_{left}) \\end{align*} \\]"},{"location":"bachelors/tcs/fsm/#proof-of-non-existence-of-a-shorter-machine","title":"Proof of non-existence of a shorter machine","text":"<p>To prove the non-existence of a smaller machine, we first start by constructing a possible suspected shortest machine. For each state, we then provide a word with which the machine will land in that state after having processed the word.</p> <p>Then, all the provided words must be compared pairwise, and for all pairs, a suffix must be found with which one of the words will be part of the langauge while the other won't.</p> <p>Let's look at an example. Below machine is suspected to be the shortest possible machine detecting the language \\(L = \\{w \\in \\{0,1\\}^* \\; \\mid \\; a11b, \\; with \\; a,b \\in \\{a,b\\}^* \\in \\}\\)</p> <p></p> <p>We start by constructing three words that land in a different state. See the words \\(\\lambda,1,11\\). Now, the following table compares the words pairwise and provides a suffix \\(z\\) that brings only one of the words into the language.</p> \\(z\\) \\(\\lambda\\) 1 11 \\(\\lambda\\) - 1 \\(\\lambda\\) 1 1 - \\(\\lambda\\) 11 \\(\\lambda\\) \\(\\lambda\\) -"},{"location":"bachelors/tcs/fsm/#proof-of-non-regularity","title":"Proof of non-regularity","text":"<p>Some languages are non-regular. This means that no finite-state machine exists that detects said language. We now discuss three approaches to prove a non-regularity.</p>"},{"location":"bachelors/tcs/fsm/#lemma-33","title":"Lemma 3.3","text":"<p>In case that two words \\(x,y\\) with \\(x \\neq y\\) land in the same state when being processed by an FSM \\(A\\) (\\(\\hat{\\delta}(q_o,x) = \\hat{\\delta}(q_o,y))\\), the following statement is true: \\(xz \\in L(A) \\Leftrightarrow yz \\in L (A)\\). We observe that the machine does not store the past of the word - it always only looks at the current and the future state.</p> <p>We then construct an infinite set of words \\(x_1,x_2,...\\) such that \\(x_iz \\in L\\) but \\(x_jz \\notin L\\).</p> <p>We first constructed an infinite set of words. By definition, there cannot exist a machine that can distinguish all of those words, and there must therefore exist two words (here \\(x_i\\) and \\(x_j\\)) which will arrive in the same state. This, however, was disproven by above statement.</p> <p>Let's look for example at the language \\(L = \\{0^{n^2} \\; \\mid \\; n \\in \\mathbb{N}\\}\\). We construct the following infinite set of words:</p> <ul> <li>\\(0\\)</li> <li>\\(0^4\\)</li> <li>\\(...\\)</li> <li>\\(0^{n_i^2} \\cdot 0^{2i+1} = 0^{(n_i+1)^2} \\in L\\)</li> <li>\\(0^{n_j^2} \\cdot 0^{2i+1} = 0^{(n_i+1)^2} \\notin L\\)</li> </ul>"},{"location":"bachelors/tcs/fsm/#pumping-lemma","title":"Pumping Lemma","text":"<p>To prove the non-regularity through the pumping lemma, we search for one specific split of a \\(w \\in L\\) with \\(|w| \\geq n_0\\): \\(w =yxz\\). We are free to choose any arbitrary word \\(w\\), but the split must be generalised through below properties.</p> <p>For a regular language, this split must have the following properties:</p> <ul> <li>\\(|yx| \\leq n_0\\)</li> <li>\\(|x| \\geq 1\\)</li> <li>Either all \\(yx^kz (k\\in \\mathbb{N})\\) are in \\(L\\) or none.</li> </ul> <p>Let's look for example at the language \\(L = \\{w \\in \\{a,b,c\\}^* \\; \\mid \\; |w|_{ab} = |w|_{ba}\\}\\). We define our word \\(w = (abc)^{n_0}(bac)^{n_0} \\in L\\). Due to above properties, we know that \\(x\\) must be in the first part of the word, and we can prove the non-regularity by looking at the following two cases:</p> <ul> <li>Case \\(x=c\\): \\(yx^0z = ...abcababc...\\), we now have an additional \\(ba\\) in the word, and thus \\(yx^0z \\notin L\\).</li> <li>Case \\(x\\neq c\\): \\(x\\) contains at least one \\(a\\) or \\(b\\). \\(yx^0z\\) is thus missing at least one \\(ab\\).</li> </ul> <p>Now, because the original word \\(w\\) is in the language \\(L\\) and for any possible split the word will not be in \\(L\\), we have contradiction to the three properties defined above.</p>"},{"location":"bachelors/tcs/fsm/#kolmogorov-complexity","title":"Kolmogorov-Complexity","text":"<p>The non-regularity proof through Kolmogorov-Complexity uses a contradiction. With the information received from the course, we only consider languages over the binary alphabet. It would be possible to extend the proof on other alphabets, but we have not proven this possibility in the course.</p> <p>We first assume that a given language \\(L\\) is regular. We construct a second language \\(L' = \\{y \\in \\{0,1\\} ^* \\mid xy \\in L\\}\\). Then, we look at a word \\(z\\) (not necessarily in \\(L\\)), which is defined with some \\(n \\in \\mathbb {N}\\). \\(z\\) is considered to be the \\(m\\)-th word in \\(L'\\) (is constant for one proof, but can change for different proofs).</p> <p>If we can show that \\(z\\) is always the \\(m\\)-th word in \\(L'\\), we can conclude that \\(z\\) is not depending on \\(n\\) but on the language \\(L\\). The Kolmogorov-Complexity can, in this case, be written as a constant: \\(K(z) \\leq \\lceil log_2(m+1) \\rceil +c=c'\\).</p> <p>As there are only infinitely many programs of said constant length, but there are infinitely many words in \\(L\\), we have a contradiction and thus \\(L\\) cannot be regular.</p> <p>Let's have an example. We want to prove that the language \\(L_1 = \\{0^{F_n} \\mid n \\in \\mathbb{N}\\}\\) where \\(F_n\\) is the \\(n\\)-th fibonacci number is not regular. \\(F_0 = 0, F_1 = 1, F_{n+1} = F_n + F_{n-1}\\) for \\(n\\geq 1\\).</p> <p>We first assume that \\(L_1\\) is regular (as we will prove the non-regularity by contradiction). We consider the word \\(z = 0^{F_{n+1}-F_n-1}\\), which can be simplified to \\(z = 0^{F_{n-1}-1}, n \\geq 2, n \\in \\mathbb{N}\\). Now, we claim that z is the first word in canonical order in the following language:</p> \\[ L' = \\{y \\in \\{0,1\\}^* \\mid 0^{F_n+1}y \\in L_1\\} \\] <p>We find this first word as \\(0^{F_n+1}z = 0^{F_n+1}0^{F_{n+1}-F_n-1}=F^F_{n+1} \\in L_1\\). There is no shorter word possible, as we know that the fibonacci sequence is growing monotonically. This shows us that \\(c\\) depends on \\(L_1\\), but not on \\(n\\) and we arrive at the following formula.</p> \\[ K(z)=K(0^F_{n-1}-1) \\leq \\lceil log_2(1+1) \\rceil c = 1 + c \\] <p>We arrive at the conclusion that the Kolmogorov constant is \\(1 + c\\). This is telling us that only a finite amount of programs egxists. However, as there are infinitely many words \\(z\\), we have a contradiction.</p>"},{"location":"bachelors/tcs/fsm/#non-deterministic-finite-state-machine","title":"Non-deterministic finite-state machine","text":"<p>The Non-deterministic finite-state machines (NEA) are quite similar to the EAs, but with the difference that it can be in multiple states at once; a state can have multiple outgoing transitions for the same symbol. Its formal definition is almost identical: \\(M = (Q, \\Sigma, \\delta, q_0, F)\\) where \\(\\delta\\) has the new definition \\(\\delta: Q \\times \\Sigma \\to Pot(Q)\\).</p> <p>If, after having processed the entire word, at least one final state is an accepting state, the word is in the language. Actually, the sole difference between the NEA and the EA is that some languages have simpler representations as NEAs. Everything else is identical as all NEAs can be converted to an EA.</p> <p>Let's convert the following NEA into an EA.</p> <p></p> <p>We first start constructing a transition table. In the first row we see that there are two possible states after having read the symbol 1. We construct thus a new state that consists of the two possible states, and, in a next step, look at the possible transitions from those states.</p> Q 0 1 \\(q_0\\) \\(q_0\\) \\(\\{q_0,q_1\\}\\) \\(\\{q_0,q_1\\}\\) \\(q_0\\) \\(\\{q_0,q_1,q_2\\}\\) \\(\\{q_0,q_1,q_2\\}\\) \\(\\{q_0,q_2\\}\\) \\(\\{q_0,q_1,q_2\\}\\) \\(\\{q_0,q_2\\}\\) \\(\\{q_0,q_2\\}\\) \\(\\{q_0,q_1,q_2\\}\\) <p>Once all states in the second and third column have been added to the column Q, we can start constructing the EA, which looks as follows. Notice that all states containing the accepting state \\(q_2\\) are accepting states in the EA.</p> <p></p>"},{"location":"bachelors/tcs/languages/","title":"Languages","text":"<p>Before starting to learn about alphabets, words and languages, we require a couple of definitions.</p> <ul> <li>Alphabet \\(\\Sigma\\): Non-empty set containing symbols, letters, numbers, etc.<ul> <li>\\(| \\Sigma |\\): Cardinality, number of elements in alphabet</li> <li>\\(\\mathcal{P}(\\Sigma)\\): Every possible combination of the elements. Note that the empty set must be counted as well</li> </ul> </li> <li>Word \\(w\\): finite string of symbols from \\(\\Sigma\\)<ul> <li>\\(\\lambda\\): empty word, has length 0</li> <li>\\(|w|\\): length of word \\(w\\)</li> <li>\\(|w|_a\\): number of symbol \\(a\\) in word \\(w\\)</li> <li>\\(\\Sigma^*\\): set of all words that can be created using the alphabet \\(\\Sigma\\)</li> </ul> </li> <li>Subword \\(v\\): part of a word. \\(\\exists x,y \\in \\Sigma^* : w = xvy\\) where \\(x\\) is a prefix and \\(y\\) a suffix to \\(v\\)</li> <li>Language \\(L\\): set of words from \\(\\Sigma^*\\) with \\(L \\subseteq \\Sigma^*\\)<ul> <li>\\(L^c\\): complement, all words but the ones from \\(L\\). \\(L^c=\\Sigma^* - L\\)</li> <li>\\(L_\\emptyset\\): the empty language</li> <li>\\(L_\\lambda\\): the language only containing the empty word</li> <li>\\(L_1 \\cdot L_2\\): multiplication of two languages. Multiplying two words means concatenating them. Here, every word   from \\(L_1\\) is combined with those from \\(L_2\\). Example: \\(\\{a,ab\\}\\cdot\\{\\lambda,bc\\}=\\{a,abc,ab,abbc\\}\\)</li> <li>\\(|L|\\): cardinality, number of words in \\(L\\). Note that \\(|L_1\\cdot L_2| \\leq k \\cdot m\\) with \\(k=|L_1|,m=|L_2|\\)</li> <li>\\(L^n\\): exponentiation, multiplication of \\(L\\) with itself \\(n\\)-times. \\(L^{n+1}=L^n\\cdot L\\). Two additional special   cases: \\(L^* = \\bigcup_{i\\in\\mathbb{N}}L^i\\) and \\(L^+ = \\bigcup_{i\\in\\mathbb{N}-\\{0\\}}L^i\\)</li> </ul> </li> </ul>"},{"location":"bachelors/tcs/languages/#language-properties","title":"Language properties","text":"<p>The following chapters discuss some properties and operations for languages and words.</p>"},{"location":"bachelors/tcs/languages/#concatenation","title":"Concatenation","text":"<p>Words can be concatenated. \\(\\Sigma^* \\cdot \\Sigma^* = \\Sigma^*\\). A concrete example is \\(abb\\cdot bbc = abbbbc\\). This operation is associative (\\((a\\cdot b) \\cdot c = a \\cdot (b \\cdot c)\\) )  but not commutative (\\(a \\cdot b \\neq b \\cdot a\\)).</p> <p>\\(a^R\\) is the word \\(a\\) but its letters are in reverse order; \\(a=a_1a_2a_3, a^R=a_3a_2a_1\\).</p>"},{"location":"bachelors/tcs/languages/#cardinal-order","title":"Cardinal order","text":"<p>To get the cardinal order of a language, its words are first sorted by length. Words of the same length are then sorted lexicographically. In mathematical terms, the word \\(u\\) is in front of \\(v\\) if:</p> \\[ |u| &lt; |v| \\lor (|u|=|v| \\land u=xs_iu'\\land v=xs_jv'\\land s_i&lt;s_j) \\] <p>The last two equalities and the last inequality look for the first letter that is different.</p>"},{"location":"bachelors/tcs/languages/#arithmetics-with-languages","title":"Arithmetics with languages","text":"<p>Set operations can be applied on languages such as the subtraction, union, intersection, etc. The same rules apply as to sets, eg.</p> \\[ L_1L_2\\cup L_1L_3 = L_1(L_2\\cdot L_3) \\] <p>An additional definition defines the homomorphism between two languages \\(\\Sigma_1^*,\\Sigma_2^*\\) as every function \\(h: \\Sigma_1^* \\to \\Sigma_2^*\\) with the following properties:</p> <ol> <li>\\(h(\\lambda)=\\lambda\\)</li> <li>\\(h(uv) = h(u) \\cdot h(v)\\) for all \\(u,v\\in \\Sigma_2^*\\).</li> </ol>"},{"location":"bachelors/tcs/languages/#kolmogorov-complexity","title":"Kolmogorov-Complexity","text":"<p>The Kolmogorov-Complexity \\(K\\) is defined as the length of the shortest (Pascal)-program which is able to generate a binary word \\(x\\).</p> <p>The \\(K\\) of the language \\(L_1 = \\{0^n\\}^\\infty_{n=1}\\) for example is defined as \\(K(0^n) \\leq \\lceil log_2(n+1) \\rceil + 1\\) where \\(c\\) is the constant part of the program that is not linked to \\(n\\), and \\(\\lceil log_2(n+1) \\rceil\\) the size of the binary representation of \\(n\\).</p> <p>Let's compare two possible programs for the language \\(L_2 = \\{0^{n^3}\\}^\\infty_{n=1}\\) and their resulting complexity.</p> AB <p>First we define the program A in pseudocode. </p> <pre><code>begin\n  for I = 1 to n^3: write(0)\n end\n</code></pre> <p>In above code, the value of \\(n^3\\) is directly used as an input to the program. Consequently, the Kolmogorov-Complexity is computed as \\(K(A) = \\lceil log(n^3+1) \\rceil + c\\). </p> <p>Our second program B takes advantage of the fact that we do not care about the memory usage of our program. </p> <pre><code>begin\n  J := n\n  J := J * J * J\n  for I = 1 to J: write(0)\nend\n</code></pre> <p>The program above has as an input the value \\(n\\). This is better than seen in program A. This fact is also being reflected in the Kolmogorov-Complexity \\(K(B) = \\lceil log(n+1) \\rceil + d\\).</p>"},{"location":"bachelors/tcs/languages/#non-compressible-words","title":"Non-compressible words","text":"<p>Not all words can be compressed regarding the Kolmogorov-Complexity - this means that for all \\(n \\in \\mathbb{N}-\\{0\\}\\) there exists a word \\(w_n \\in (\\Sigma_{bool})^n\\) such that \\(K(w_n) \\geq |w_n| = n\\). In other words, a word of length \\(n\\) exists for every \\(n\\) that is non-compressible.</p> <p>The language \\(\\{0,1\\}^n\\) containing only words of length \\(n\\) for example has at least two words that are not compressible. The language contains \\(2^n\\) words, but there exist not enough distinct non-empty programs with length strictly smaller than \\(n\\). To be precise, only \\(2^n-2\\) such programs exist.</p> <p>For the language \\(\\{0,1\\}^{\\leq n}\\) this gets even worse as now \\(n^{2+1}-2\\) distinct words exist but there are still only \\(2^n-2\\) distinct programs. Thus, at least half of the words have \\(K(x) \\geq |x|\\).</p> <p>Such words are called random. The same can be said for numbers. A number \\(n\\) is called random if \\(K(n) = K(Bin(n)) \\geq \\lceil log_2(n) \\rceil -1\\).</p>"},{"location":"bachelors/tcs/turingmachine/","title":"Turing-machine","text":"<p>The turing-machine (TM) is a concept of a machine that can detect (almost) all languages. The  Church-Turing-Thesis states that TMs are suitable formalisations of the term \"Algorithm\".</p> <p>It is based on an infinite work tape (which can be seen as an infinite amount of storage) and a finite control (or unformally a \"program\"). The following diagram describes a turing-machine with all its basic components.</p> <p></p>"},{"location":"bachelors/tcs/turingmachine/#definitions","title":"Definitions","text":"<p>The formal definition of a TM is a seven-tuple \\(M=(Q, \\Sigma, \\Gamma, \\delta, q_0, q_{accept}, q_{reject})\\) with the following symbol definitions.</p> <ul> <li>\\(Q\\): finite state set</li> <li>\\(\\Sigma\\): input alphabet</li> <li>\\(\\Gamma\\): working alphabet, \\(\\Sigma \\in \\Gamma, (\u00a2, \\_\\_) \\in \\Gamma - \\Sigma, \\Gamma \\cap Q = \\emptyset\\)</li> <li>\\(\\delta\\): \\(Q- \\{q_{acc}, q_{rej}\\} \\times \\Gamma \\to Q \\times \\Gamma \\times \\{L,R,N\\}\\) where \\(L,R,N\\) are the movements   that the R/W-head is able to do (move left 1, move right 1, neutral)</li> <li>\\(q_0\\): start state</li> <li>\\(q_{accept}\\): accepting state, also \\(q_{acc}\\)</li> <li>\\(q_{reject}\\): rejecting state, also \\(q_{rej}\\)</li> </ul>"},{"location":"bachelors/tcs/turingmachine/#processing-definitions","title":"Processing definitions","text":"<p>A configuration is an element from \\(Konf(M)=\\{\u00a2\\}\\cdot \\Gamma^* \\cdot Q \\cdot \\Gamma^+ \\cup Q\\{\u00a2\\}\\Gamma^+\\). \\(\\Gamma^*\\) describes the tape content to the left of the R/W-head, \\(Q\\) the current head position, and \\(\\Gamma^+\\) everything to the right of the head. The second element of the union describes the special case when the head is on the end mark (where the head should not be able to go further to the left).</p> <p>The start configuration for some input \\(x\\) is \\(q_0\u00a2x = Q_0\\). Further configurations can then be denoted as \\(\u00a2q_1qaw_2\\), where \\(q\\) is the head position, and \\(a\\) is the symbol at said position.</p> <p>Let's consider a step where the head is currently on \\(x_i\\)and will replace said symbol with \\(y\\). There are three possible steps to be taken. Here, we transition from one config \\(Q_j\\) to the next configuration \\(Q_{j+1}\\):</p> <ul> <li>No movement: \\(\u00a2x_1x_2...x_{i-1}qx_ix_{i+1} \\; |_{\\!\\overline{\\;M\\;}} \\; \u00a2x_1x_2...x_{i-1}pyx_{i+1}\\) which is identical   to \\(\\delta(q,x_i)=(p,y,N)\\)</li> <li>Movement left: \\(\u00a2x_1x_2...x_{i-1}qx_ix_{i+1} \\; |_{\\!\\overline{\\;M\\;}} \\; \u00a2x_1x_2...x_{i-2}px_{i-1}yx_{i+1}\\) which is   identical to \\(\\delta(q,x_i)=(p,y,L)\\)</li> <li>Movement right:\\(\u00a2x_1x_2...x_{i-1}qx_ix_{i+1} \\; |_{\\!\\overline{\\;M\\;}} \\; \u00a2x_1x_2...x_{i-1}ypx_{i+1}\\) which is   identical to \\(\\delta(q,x_i)=(p,y,R)\\)</li> </ul> <p>A computation is a sequence of configurations \\(Q_1,Q_2,...\\) with \\(Q_i \\; |_{\\!\\overline{\\;M\\;}} \\; Q_{i+1}\\). A TM can run indefinitely, or stop on \\(w_1qw_2\\) with \\(q \\in \\{q_{acc},q_{rej}\\}\\). The TM can then be accepting if it stops on the accepted state, or rejecting if it stops on a rejecting state or if it is running indefinitely.</p> <p>The accepted language is denoted as \\(L(M) = \\{w \\in \\Sigma^* \\mid q_0 \\notin w\\; |_{\\!\\overline{\\;M\\;}}^* \\; w_1 q_{acc}w_2, \\: w1,w2 \\in \\Gamma^*\\}\\). A language is recursively enumerable (rekursiv aufz\u00e4hlbar, (\\(\\mathcal{L}_ {RE}\\))) if M is able to tell if a word \\(x\\) is in the language, but might run indefinitely if \\(l \\notin L\\). If M can  also always tell if \\(x \\notin L\\), the language is said to be recursively (decidable) (\\(\\mathcal{L}_{R}\\)).</p>"},{"location":"bachelors/tcs/turingmachine/#tm-example","title":"TM example","text":"<p>Let's look at the following example. We have seen previously that the language \\(L = \\{0^{2^n} \\mid n \\geq 1\\}\\) is not regular. With a turing-machine, we are able to detect the language. The following process is a possible solution.</p> <ul> <li>Mark every second \\(0\\)</li> <li>Repeat the above step until only a single \\(0\\) remains.</li> <li>The word is part of \\(L\\) in case above condition applies.</li> </ul>"},{"location":"bachelors/tcs/turingmachine/#multi-tape-turing-machine","title":"Multi-tape turing-machine","text":"<p>The multi-tape turing-machine (MTM) is similar to the TM, but possesses a constant (but arbitrary) number of tapes. One of those tapes is a read-only input tape, while the others are working tapes that are empty at the beginning. See the following visualisation of an MTM.</p> <p></p> <p>The start configuration consists of three parts:</p> <ul> <li>\\(\u00a2w\\$\\) on input tape for an input \\(w\\). The read-head is on \\(\u00a2\\).</li> <li>Empty working tapes, where the R/W-heads are on \\(\u00a2\\)</li> <li>Starting state \\(q_0\\)</li> </ul> <p>The configuration itself is denoted as \\((q,w,i,u_1,i_1,...,u_k,i_k)\\) with the following definitions:</p> <ul> <li>\\(q\\): current state</li> <li>\\(w\\): input</li> <li>\\(i\\): head-position on input</li> <li>\\(u_k\\): content of working band \\(k\\)</li> <li>\\(i_k\\): R/W-head-position on working band \\(k\\)</li> </ul> <p>The transition-function is now defined as:</p> \\[ \\delta: Q \\times (\\Sigma \\cup \\{\u00a2,\\$\\}) \\times \\Gamma^k \\to Q \\times \\{L,R,N\\} \\times (\\Gamma \\times \\{L,R,N\\})^k \\]"},{"location":"bachelors/tcs/turingmachine/#mtm-vs-tm","title":"MTM vs TM","text":"<p>Actually, an MTM is not more powerful than a TM, because we can show that for all MTM, an equivalent TM exists. The TM will be way more complicated, and for one step in an MTM, a series of steps are usually required in a TM. The sole tape of the TM must additionally contain the stored words as well as the position of the heads.</p> <p>A machine \\(A\\) (MTM) is equivalent to a machine \\(B\\) (TM), if for all \\(x \\in \\Sigma^*\\) all the following conditions apply.</p> <ul> <li>\\(A\\) accepts \\(x \\Leftrightarrow B\\) accepts \\(x\\)</li> <li>\\(A\\) rejects \\(x \\Leftrightarrow B\\) rejects \\(x\\)</li> <li>\\(A\\) runs indefinitely on \\(x \\Leftrightarrow B\\) runs indefinitely on \\(x\\)</li> </ul> <p>If above apply, we can say that \\(A\\) and \\(B\\) are equivalent \\(\\Rightarrow L(A) = L(B)\\). However, the other way around \\(A\\) and \\(B\\) are equivalent \\(\\Leftarrow L(A) = L(B)\\) does not apply!</p>"},{"location":"bachelors/tcs/turingmachine/#non-deterministic-turing-machine","title":"Non-deterministic turing-machine","text":"<p>The non-deterministic turing-machine (NTM) is an extension to the TM. It's formally defined as the seven-tuple \\(M = (Q,\\Sigma,\\Gamma,\\delta,q_0,q_{acc},q_{rej})\\) where \\(\\delta\\) has been redefined as  \\(\\delta: (Q-\\{q_{acc},q_{rej}\\}) \\times \\Gamma \\to Pot(Q \\times \\Gamma \\times \\{L,R,N\\})\\). Additionally, delta must make  sure that the tapes are not left. </p> <p>The non-determinism is similar to the one described for the finite-state machines; it is possible for the NTM to  transition into multiple states on the same input, head position and current state. </p> <p>Let M be a NTM, and \\(x \\in \\Sigma^*\\). The NTM can be described as a computational tree \\(T_{M,x}\\) with a root such that: </p> <ul> <li>(i): Nodes are labeled with configurations</li> <li>(ii): root as the input degree 0, labeled with the starting configuration \\(q_0\u00a2x\\)</li> <li>(iii): nodes with label C has children which are all possible following configurations of C.</li> </ul> <p>Analog to the EA, it is also possible to express every NTM as a TM. </p>"},{"location":"bachelors/tcs/turingmachine/#turing-machine-encoding","title":"Turing-machine encoding","text":"<p>All turing-machines can be encoded as binary strings. The following is an arbitrary definition that was seen in the  lectures. Other encodings are possible. </p> \\[ \\begin{align*} M&amp;=(Q,\\Sigma,\\Gamma,\\delta,q_o,q_{acc},q_{rej})\\\\ Q&amp;=\\{q_0,q_1,...,q_{acc},q_{rej}\\} \\;\\; \\Gamma = \\{A_1,...,A_m\\}\\\\ Code(q_1) &amp;= 10^{i+1}1, \\; Code(q_{acc})=10^{m+2}1, \\; Code(q_{rej})=10^{m+3}1\\\\ Code(A_j) &amp;= 110^j11\\\\ Code(N)&amp;=1110111, \\; Code(R)=11100111, \\; Code(L) = 111000111\\\\ Code(\\delta(p,A)=(q,A_n,d))&amp;=\\#Code(p)Code(A)Code(q)Code(A_n)Code(d)\\#\\\\ Code(M) &amp;= \\#0^{m+3}\\#0^\\Gamma\\#\\#Code(Transition1)\\#Code(Transition2)\\#... \\end{align*} \\] <p>We observe that the above encoding is not a binary encoding as the alphabet used is \\(\\{0,1,\\#\\}\\). We therefore  define the function h converting the ternary encoding into a binary encoding and is defined as follows.</p> \\[ \\begin{align*} h&amp;: \\; \\{0,1,\\#\\}^* \\to \\{0,1\\}^*\\\\ Kod(M) &amp;= h(Code(M)) \\end{align*} \\]"},{"location":"data/rtai/","title":"Reliable and Trustworthy Artificial Intelligence","text":""},{"location":"data/rtai/#general-notions","title":"General notions","text":""},{"location":"data/rtai/#l_p-norm","title":"\\(l_p\\)-norm","text":"<p>The similarity of two vectors \\(x\\) and \\(x'\\) is usually captured through an \\(l_p\\) norm. In the following formula, \\(\\epsilon\\) is a threshold of similarity that can be arbitrary.</p> \\[ x \\sim x' \\; \\mathrm{iff} \\; ||x-x'||_p &lt; \\epsilon \\] <p>Now, \\(||x-x'||_p\\) specifies the distance between the two vectors, which is computed follows, where \\(x_i\\) is the \\(i\\)-th component of the vector \\(x\\).</p> \\[ ||x-x'||_p = \\Bigg(\\sum_{i=1}^n |x_i-x_i'|^p\\Bigg)^{\\frac{1}{p}} \\] <p>Some of the \\(l_p\\) norms are used more often than others. The following list contains important norms.</p> <ul> <li>\\(l_0\\): adds up all changes. Counts, for example, the number of changed pixels in an image</li> <li>\\(l_2\\): Euclidean distance between \\(x\\) and \\(x'\\)</li> <li>\\(l_\\infty\\): maximum noise (change) added to any component of the vectors. The formula can be simplified as</li> </ul> \\[ ||x-x'||_\\infty = max(|x_1-x_1'|, ..., |x_n-x_n'|) \\] <p>The \\(l_2\\)-norm is often used for attacks, but rarely for certification of models due to the difficulties that come with the quadratic nature of said norm. \\(l_\\infty\\) can be imagined as a box around the center point. It is also said to most naturally capture the human vision, and it is simpler to certify.</p>"},{"location":"data/rtai/#logic-in-deep-learning","title":"Logic in Deep Learning","text":"<p>Logic can be translated such that it can be \"understood\" by neural nets. While querying, we can set some parameters that the output should satisfy. In fact, searching for adversarial examples is a special case of such a query with  logical constraints. Furthermore, it is possible to include logic already in the training process. If applied correctly,  this can improve accuracy. </p>"},{"location":"data/rtai/#querying","title":"Querying","text":"<p>In this case, we start with a trained network, and we look for inputs that satisfy specific properties. The following standard logic can be used: </p> <ul> <li>Logical operators \\(\\not, \\neq, \\land, \\lor, \\leq, \\geq, &lt;, &gt;, \\Rightarrow\\)</li> <li>Functions f: \\(\\mathbb{R}^m \\to \\mathbb{R}^n\\)</li> <li>Variables, constants</li> <li>Arithmetic expressions</li> </ul>"},{"location":"data/rtai/#training","title":"Training","text":""},{"location":"data/rtai/#regulations","title":"Regulations","text":"<p>In the past couple of years, first regulations were introduced aiming to preserve a citizen's privacy regarding data collection done by many companies. In the coming years, bills will be introduced to add further regularization regarding AI and its use. Already, huge fines have been imposed regarding privacy.</p> <p>A huge part of the AI regulations require the system to have fairness. Discriminating systems are already in use. This is mostly due to biased data, or data missing out on minorities. Regulations define sensitive attributes, some even define fairness metrics making sure that systems do not discriminate.</p> <p>Further, explainability is required - the provider must be able to explain how a certain decision was reached. This is one point that gets often criticised: even human decisions are not always explainable, and the output of neural networks cannot be explained, although it is an open field in research.</p>"},{"location":"data/rtai/#gdpr","title":"GDPR","text":"<p>GDPR (EU's bill for privacy) was not created for AI, but it applies to automated decision-making, thus it has also power over AI systems. It tries to minimize the data collected, and prevent it from being shared whilst AI systems always require more data. GDPR defines three data types:</p> <ul> <li>Personal data: data related to an identified or identifiable natural person</li> <li>Pseudo-anonymized data: personal data no longer related directly to a data subject. Additional information is required   to get to the data subject (e.g. through values replaced by references)</li> <li>Anonymized data: personal data that can no longer be related to the data subject. This is the only type of information   not subject to GDPR</li> </ul> <p>Further, it identifies the following privacy risks.</p> <ul> <li>Singling out: identifying a person by comparing known information about them with attributes in a different dataset</li> <li>Linkability: linking information form different data sets through some attribute (e.g. a person's address)</li> <li>Inference: estimating personal data from other attributes</li> </ul> <p>Possible counter measurements to the above risks include federated learning, trusted execution environment, homomorphic encryption, and synthetic data.</p> <p>Further, the following principles are required by the GDPR.</p> <ul> <li>Unlearning: a user has the right to be forgotten. We must thus be able to \"remove\" a training sample from a model.</li> <li>Data minimization: the training process must only use the data that is strictly necessary. The formalization of this   requirement is an open problem.</li> </ul>"},{"location":"data/rtai/#eu-ai-act","title":"EU AI act","text":"<p>The EU AI act assesses risks of AI application, dividing the systems into four risk levels. Based on the risk level, different requirements are to be met.</p> <ul> <li>Unacceptable risk: social scoring, distorting human behavior, real-time biometric data for law enforcement (face   recognition)</li> <li>High risk: critical infrastructure, education access, employment, migration, justice</li> <li>Limited risk: chatbots, video games, spam filters</li> <li>Minimal or no risk: most other systems</li> </ul> <p>High risk systems require a risk management system, data governance, technical doc, record-keeping, transparency, human oversight, and good accuracy and robustness.</p>"},{"location":"data/rtai/#other-ai-acts","title":"Other AI acts","text":"<p>AI Bill of rights (US): this foundation for upcoming regulations (e.g. Algorithmic Accountability Act) requires  people to be protected from safe and inefficient systems, they should not be discriminated, be protected from abusive data practices, know about automated systems in use, and have the option to opt out and have access to a human  alternative. </p> <p>Digital Services Act (EU): not explicit about AI, but AI is also affected. Aimed at large platforms, they are  required to be assessed by an independent third party regarding societal risks, they must have transparency reports on automated systems, and limit manipulative advertising platforms. </p> <p>Recommendation Algorithms Regulation (CN): regarding recommendation algorithms, users should have the right for  explanation, must be able to edit tags used for recommendation by themselves, addictive behavior should not be  encouraged, and preferences should not influence a different treatment. </p>"},{"location":"data/rtai/#emerging-issues","title":"Emerging issues","text":"<ul> <li>Copyright: if copyrighted data is used for training, the output might be subject to a copyright infringement</li> <li>AI generators trained on sensitive data: models are trained on everything. They can then be used to generate sensitive   content.</li> <li>Large scale fake content</li> </ul>"},{"location":"data/rtai/fairness-bias/","title":"Fairness","text":""},{"location":"data/rtai/fairness-bias/#individual-fairness","title":"Individual Fairness","text":""},{"location":"data/rtai/fairness-bias/#group-fairness","title":"Group Fairness","text":""},{"location":"data/rtai/fairness-bias/#counterfactual-fairness","title":"Counterfactual Fairness","text":""},{"location":"data/rtai/privacy/","title":"Privacy","text":"<p>With the rize of AI in the recent years, a new problem came apparent. If one does not pay attention on how models are created, they might be leaking training data. This training data is often very personal and should not be available to anyone using the model. This chapter focuses on techniques for improving a model's privacy.</p>"},{"location":"data/rtai/privacy/#privacy-attacks","title":"Privacy attacks","text":""},{"location":"data/rtai/privacy/#model-stealing","title":"Model stealing","text":"<p>Models are expensive to train, are trained with large datasets that might also be expensive to create. A provider wants to sell access permissions to the model. The question to be asked: is it possible to steal the model through the provided access?</p> <p>White-box: A malicious client could for example buy a model. Of course the provider would prohibit the client from reselling it. But by fine tuning the model, he can then resell it as it is often almost impossible to prove that the model is being used without permission.</p> <p>Black-box: A malicious client could use the model not at it was intended by the provider. If done correctly, the client can steal the provider's competitive advantage.</p>"},{"location":"data/rtai/privacy/#model-inversion-and-data-extraction","title":"Model inversion and data extraction","text":"<p>In model inversion, the attacker queries the model to find some representative training input. Say for example we have a facial recognition model that outputs based on an image, a person's name. Malicious clients could search for images that classify to the same name. This image is a representative image for the given name.</p> <p>Data extraction is even worse, as the attacker finds an exact data point from the training set. This is especially dangerous if the training data is private. Especially large neural networks are prone to such issues, as they tent to memorize some training samples. Preventing the memorization hurts the accuracy.</p>"},{"location":"data/rtai/privacy/#membership-inference","title":"Membership inference","text":"<p>In this attack, the attacker uses the model to infer if a known datapoint is part of the training set. Supposing that we know the rough data distribution, the attacker can train shadow models - some with and some without said data point. Then, a classifier is trained on the outputs of the shadow models. This classifier tries to guess if the datapoint is or is not part of the dataset. The real model output can then be put through this classifier.</p>"},{"location":"data/rtai/privacy/#federated-learning","title":"Federated learning","text":"<p>(Model inversion/data extraction)</p> <p>In federated learning, we try to train a model on data comming from third parties clients that do not want to share their data. Insetad, the clients shair a training update without sending the data itself. These updates are collected on a central server and result in a global model. Even though the data never leaves the client, the updates still contain information regarding the data. A malicious server might be able to reconstruct the data based on the update.</p>"},{"location":"data/rtai/privacy/#fedsgd","title":"FedSGD","text":"<p>In FedSGD, each client \\(k\\) computes a gradient update \\(g_k\\) based on a minibatch of their data \\(\\mathcal{D}_k\\) and sends \\(g_k\\) to the server. This guarantees convergence to some local minima but takes many communication rounds to converge.</p> <p>This technique has multiple attack vectors:</p> <ul> <li>Poisoning: a client sends bad updates, degrading the global model</li> <li>Non-cooperative: the client usess the model but does not share updates</li> <li>Gradient inversion: the server sends weights that expose information in the client update</li> <li>Closed-form reconstruction: it is possible to reconstruct the exact input from the gradient (batch size 1, and linear NN)</li> </ul> <p>The latter is also approximately possibel for bigger batch sizes using the following formula. In essence, the server is somewhat curious and tries to reconstruct the data that was used to compute the gradient update. He does this through a random initialization, and then finding data that leads to the closest gradient updates.</p> \\[ \\text{argmin}_{x^*} \\; d(\\nabla_\\Theta\\mathcal{L}(f_\\Theta(x^*), y^*), g_k) + \\alpha_{reg} \\cdot \\mathcal{R}(x^*) \\] <p>Where \\(d\\) computes the distance between the reconstructed gradient and the true gradient, and \\(\\mathcal{R}\\) the  domain-specific knowledge (what do we know about the data we try to uncover).</p> <p>Such attacks are fairly straight forward on images (continuous data), but are also possible on tabular data by using one-hot encodings on categorical features. The difficulty then lies in distinguishing good and bad reconstructions. To get some notion of reconstruction quality, a possibility is to have a series of random initializations, and create normalized histograms for each tabular cell. By measuring the entropy of the histograms, we can see if our reconstruction was probably correct. Low entropy means that the reconstruction is good.</p>"},{"location":"data/rtai/privacy/#fedavg-federated-averaging","title":"FedAvg (federated averaging)","text":"<p>A more common setup includes an averaging process on the server. The client computes its weights over multiple epochs. The server then averages the weight updates over all clients. The client could even add some randomness that should be canceled out in the global model. This method has the advantage of reducing the number of require communication rounds.</p> <p>The question now is if the weight updates do preserve privacy. The challenge for the attacker is that he is unable to observe the intermediate weights, and only gets the final update. Even the order of how data points are fed to the network change the outputs.</p> <p>A possible attack simulates the process and uses differentiation. The simulation produces intermediate weights based on some guessed input samples. The distance between the final simulated weight and the weight update is then fed to automatic differentiation which is used to optiize the reconstruction of the data points.</p> <p>An Order-invariant prior is used to enforce that the set of reconstructed images in different epochs are identical. This is done by adding a weak prior \\(\\mathcal{R}\\) that averages the input per epoch across epochs.</p> \\[ \\text{argmin}_{\\tilde{x}^k} d(\\tilde{\\Theta}^k, \\Theta^k) + \\alpha_{reg} \\cdot \\frac{1}{E^2}\\sum_{e_1,e_2} \\mathcal{R}(g(\\{\\tilde{x}^k_{e1,b}\\}), g(\\{\\tilde{x}^k_{e_2,b}\\})) \\] <p>In above formula we compute the distance between the simulated weights \\(\\tilde{\\Theta}^k\\) and the true weights \\(\\Theta^k\\) for some client \\(k\\). The prior computes the average distance between the average images at every pair of epochs \\(e_1\\) and \\(e_2\\) with \\(E\\) numer of epochs.</p>"},{"location":"data/rtai/privacy/#differential-privacy","title":"Differential privacy","text":"<p>In differential privacy we try to protect models against Membership inference. A mechanism \\(M\\) is called \\(\\varepsilon\\) differential private if the following holds:</p> \\[ Pr[M(a) \\in S] \\leq e^\\varepsilon Pr[M(a') \\in S] \\] <p>\\(\\varepsilon\\) defines how far appart those two mechanisms are. Here, we are saying that for all neighboring datasets \\(a,a'\\) and an attack \\(S\\), the attacker is equally likely to succede in the attack regardless which datasets is in use. A neighboring dataset is defined as (adding/removing one person) or (changing features of one person).</p> <p>Laplacian noise with mean 0 can be added: \\(f(a) + Lap(0, \\Delta_1/\\varepsilon)\\) is \\(\\varepsilon\\)-DP, where \\(\\Delta_1\\) is the sensitifity (largest possible effect of changing input on output in L1 norm.</p> <p>Adding gaussian noise \\(f(a)+ \\mathcal{N}(0 \\sigma^2I)\\) leads to (\\(\\varepsilon, \\delta\\))-DP. \\(\\sigma\\) is defined as</p> \\[ \\sigma = \\frac{\\sqrt{2log(1.25)/\\delta} \\cdot \\Delta_2}{\\varepsilon} \\] <p>with \\(\\Delta_2\\) the effect of changing the input as an L2 norm. We add a small \\(\\delta\\) to counter cases where the probability is tiny.</p> \\[ Pr[M(a) \\in S] \\leq e^\\varepsilon Pr[M(a') \\in S] + \\delta \\] <p>A common pattern to applying such mechanism is splitting an algorithm into two parts, that are now executed in sequence. Between the two sub-algorithms, we then add noise.</p>"},{"location":"data/rtai/privacy/#benefits","title":"Benefits","text":"<ul> <li>We make no assumtions on attackers</li> <li>Post-processing: a mechanism that is (\\(\\varepsilon, \\delta\\))-DP, is also (\\(\\varepsilon, \\delta\\))-DP if it is post-processesd</li> <li>Composition: given two (\\(\\varepsilon, \\delta\\))-DP mechanisms, the combination adds up to (\\(\\varepsilon_1 + \\varepsilon_2, \\delta_1 + \\delta_2\\))-DP.</li> </ul>"},{"location":"data/rtai/privacy/#applications","title":"Applications","text":"<p>DP-SGD: Noise is introduced in training. This makes it impossible to retrieve data from the model, and one can publish it without a problem. If noise is added durring inference, we might run into issues where the model is queried many times. In this case, the data might get leaked as the noise averages out. This technique adds the noise to the gradient. The amount of noise added is defined as</p> \\[ \\sigma = \\frac{\\sqrt{2log(1.25)/\\delta} \\cdot (C/L)}{\\varepsilon} \\] <p>with \\(L\\) the batch size, and \\(C\\) the maximum sensitivity of the gradient.</p> <ul> <li>One iteration without subsampling: (\\(\\varepsilon, \\delta\\))-DP.</li> <li>One iteration with subsampling of size q: (\\(\\tilde{q}\\varepsilon, q\\delta\\))-DP</li> <li>\\(T\\) iterations with subsampling of size q: (\\(\\tilde{q}T\\varepsilon, qT\\delta\\))-DP</li> </ul> <p>The latter is bad, because we lose a lot of privacy. In this case we would have to add more noise, which in turn reduces the accuracy of a model.</p> <p>PATE: In PATE, the data is split into \\(m\\) partitions. Each partition is given to a separate teacher model for training. These teacher models are then used in a noisy voting process on an aggregate teacher model. This model predicts the labels on some public unlabeled data. This new dataset is then used to create a student model, which has thus no more connection to the original data.</p> <p>The voting process works as follows. Let \\(n_j(x)\\) be the number of teachers predicting \\(j\\) on some input \\(x\\). The aggregating function \\(f\\) is defined as</p> \\[ f(x) = arg\\max_j\\{n_j(x) + Lap(0, 2/\\varepsilon)\\} \\] <p>One such query is (\\(\\varepsilon, 0\\))-DP. For \\(T\\) queries, this degrades to (\\(T\\varepsilon, 0\\))-DP.</p> <p>When compared with DP-SGD, PATE can be used on any algorithm, and achieves better results (\\(2.04, 10^{-5}\\)-DP for 98% accuracy on MNIST, compared to ($8,10^{-5})-DP with 97% accuracy). </p> <p>FedSGD: each client clips the gradient, and adds some gaussian noise to its computed gradient.</p> <p>FedAVG: each client clips its final weights, and then adds some gaussian noise before sending them to the server.</p>"},{"location":"data/rtai/privacy/#synthetic-data","title":"Synthetic data","text":"<p>Private sensitive data sets cannot be shared with the public due to privacy regulations. However, in some case this  might still be interesting: e.g. a hospital would like to share data to research groups. In such cases, a new data set can be generated that contains only synthetic data and has provable differential privacy guarantees. </p> <p>The key challenge here is to generate data having similar statistical properties to the original data but preserving  privacy. </p>"},{"location":"data/rtai/privacy/#select-measure-generate","title":"Select-Measure-Generate","text":"<p>We define a three-step procedure for generating synthetic data:</p> <ol> <li>Select: we define marginal queries we want to measure. The output data should have similar properties according    to these queries. They can be 1-way or 2-way.</li> <li>Measure: we measure the marginal queries using differential privacy by adding some noise (as seen in differential    privacy).</li> <li>Generate: we generate the data</li> </ol> <p>A Marginal is defined on a subset of attributes \\(C \\subseteq \\mathcal{A}\\). For each of these attributes, we compute how many entries have some specific value for this attribute. E.g. the 1-way marginal for an attribute nationality counts how many entries in the original dataset have a specific nationality. In SQL, this could be compared to a  <code>GROUP BY 'Nationality'</code> with the aggregation function <code>COUNT</code>. </p> <p>2-Way marginals are quite similar, but they also cover relationship between two marginals. This can be compared with a <code>GROUP BY</code> on two columns. </p> <p>Each such marginal has a sensitivity of \\(1\\), because adding one entry will only change a single entry in the output.</p> <p>The attribute selection can be done automatically by generating a graph based on the data. Each variable defines a  vertex, and the weight of the edges connecting these vertices is defined by the mutual dependency \\(I(X,Y)\\). The  Chow-Liu algorithm then computes the maximum spanning tree of this graph. </p> \\[ I(X,Y) = \\sum_x \\sum_y \\frac{p(X=x,Y=y)}{p(X=x)p(Y=y)} \\] <p>Let's say the following graph results from above step. </p> <p></p> <p>We can now generate data based on the following probabilities. This is called belief propagation.</p> \\[\\begin{align} &amp;p(\\text{Nat}=N, \\text{Smoke}=S, \\text{Kids}=K) \\\\ = &amp;p(\\text{Nat}=N) p(\\text{Smoke}=S | \\text{Nat}=N)p(\\text{Kids}=K|\\text{Nat}=N) \\end{align}\\] <p>Privacy</p> <p>Using the above approach, we have a generation process. However, the generated data is not yet private. The marginal  selection must be differential private, and the measurement require some level of noise.</p> <p>During the selection process, the MST must be estimated in a differentially private manner. This is done by using  exponential mechanism to estimate the maximum weight edge between two connected components. In the measure phase, we simply add some gaussian noise.</p>"},{"location":"data/rtai/robustness/","title":"Robustness","text":"<p>AIs have typically issues where they make false classifications due modified inputs. Such modifications can happen on data directly, or on the data that is being captured. All in all, it gets more and more important to have AIs that have a certain level of certified robustness giving some securities to the user. This is especially important for security-relevant applications.</p> <p>However, it is generally hard to certify models. And often, certification and improved robustness come with a certain cost regarding the model's performance, especially if those certifications are required to be scalable.</p>"},{"location":"data/rtai/robustness/#attacks","title":"Attacks","text":"<p>AI models have generally weaknesses and can be fooled by attackers. Adding a small amount of noise to an image can for example lead an image recognition model to wrong conclusions, or adding tape at certain spots on a stop sign can lead models to recognise it as a different sign.</p>"},{"location":"data/rtai/robustness/#adversarial-attacks","title":"Adversarial attacks","text":"<p>In adversarial attacks, we generally view two types of attacks:</p> <ul> <li>Targeted Attack where the attacker aims to classify the input as a specific label which differs from the   correct label.</li> <li>Untargeted Attack where the aim is to classify the input as some label that is not the correct one.</li> </ul> <p>The attacks can be further split into white box attacks where the attacker knows the complete model including parameters and the architecture, and black box attacks where the attacker only knows the architectures but has no information about the parameters.</p> <p>The following chapters only discuss white box attacks. Below table describes the three attacks in brief.</p> Attack type Region Optimization Outcome FGSM (targeted, untargeted) \\([-\\epsilon, +\\epsilon]\\) One step of size \\(\\epsilon\\) Output will be on region boundary PGD (mostly untargeted) Any region for which projections exist Many steps, uses projections to stay inside the region Inside region with maximised loss Carlini (targeted) Image and input + \\(\\eta\\) must be in range \\([0,1]\\) Produce change \\(\\eta\\) with small \\(l_\\infty\\), taking many steps Image inside \\([0,1]\\) with (hopefully) small \\(_\\infty\\) distance from original image"},{"location":"data/rtai/robustness/#fast-gradient-sign-method-fgsm","title":"Fast Gradient Sign Method (FGSM)","text":"<p>This attack uses the gradient descent of the classification model. The loss function of the gradient descent is computed, and the added/removed from the input to form a modified output that should be classified with some other label. The loss function is, however, modified before being added/removed: only the sign of the values is looked at, not the exact value. This lead to better results than taking the gradient itself.</p> <p>First, the perturbation is computed. This is slightly different for the targeted (T) and untargeted (U) mode. In T, the loss function is computed for the target label 3, whereas in U, the original label s is used.</p> \\[ \\eta_{t/s} = \\epsilon \\cdot sign(\\nabla_xloss_{t/s}(x)) \\] <p>where \\(\\epsilon\\) a small value indicating how large the perturbation should be, and \\(sign(g)\\) returning -1 if \\(g &lt; 0\\), 0 if \\(g = 0\\), or 1 if \\(g &gt; 0\\).</p> <p>As the output of the loss function is passed through the sign function, and then multiplied by \\(\\epsilon\\), the output is guaranteed to stay in the range \\(x \\pm \\epsilon\\). The original paper had a single iteration of this algorithm. If the perturbation did not change the output, the next input was looked at. The algorithm is designed to be fast and simple.</p> <ul> <li>Targeted: \\(x' = x-\\eta_t\\) modifies the input by minimising the loss for the label \\(t\\).</li> <li>Untargeted: \\(x' = x+\\eta_s\\) modifies the input by maximising the loss for the original label \\(s\\).</li> </ul>"},{"location":"data/rtai/robustness/#carlini-attack","title":"Carlini attack","text":"<p>In this attack, we are trying to find a perturbation \\(\\eta\\) classifies an input \\(x \\in X\\) to a target label \\(t \\in C\\): \\(f(x + \\eta) = t\\) where \\(||\\eta||_p\\) is minimized. We thus have an optimization problem. We also require that \\(x+\\eta\\) stays in the domain of the problem (\\([0,1]\\) for images).</p> <p>The optimization problem has currently a hard discrete constraint (\\(f(x + \\eta) = t\\)). However, it is hard to find the gradient to such problems. We thus require a relaxation. The Carlini attack uses a relaxation through an objective (proxy/soft) function \\(obj_t\\) such that</p> \\[ \\mathsf{if} \\; obj_t(x + \\eta) \\leq 0 \\; \\mathsf{then} (x + \\eta) = t \\] <p>Using this function, we are now trying to minimize \\(||\\eta||_p + c \\cdot obj_t(x + \\eta)\\). Notice that we are talking about an if relation and not an iff.</p> <p>The paper<sup>1</sup> cites a series of soft functions. One highlighted in the course is</p> \\[ obj_t(x) = loss_t(x) -1 = -log_2(p_f(x)_t)-1 \\] <p>where \\(p_f(x)_t\\) is the probability of a class \\(t\\) for some input \\(x\\) on network \\(f\\). The cross entropy loss is used as a loss function. We now have a problem that can be optimized.</p> <p>The model additionally has a hard box constraint to make sure that the output stays inside the domain of the input. This is often solved through PGD (projected gradient descent).</p> <p>Compare to the FGSM, this attack gets most often less perturbed attacks.</p>"},{"location":"data/rtai/robustness/#pgd","title":"PGD","text":"<p>The projected gradient descent (PGD) can be seen as a series of FGSM attacks.</p> <ol> <li>We start by picking some point \\(x_{orig}\\) from the dataset and put an \\(l_\\infty\\) ball around it, with some \\(\\epsilon\\)    that is typically bigger than the one used in an FGSM attack.</li> <li>Next, we select some random point \\(x\\) in the box.</li> <li>Now starts the PGD iteration. We compute \\(x' = x + \\epsilon' \\cdot sign(\\nabla_xLoss(x))\\). This is essentially an    FGSM attack on \\(x\\). \\(\\epsilon'\\) is smaller than \\(\\epsilon\\).</li> <li>\\(x'\\) might be outside the box around \\(x_{orig}\\). We thus must project it back on the box \\(x'' = project(x',x_{orig},    \\epsilon)\\). The projection uses clipping to get back into the box.</li> <li>If \\(x''\\) is not yet a labeled with a different class, we re-assign \\(x = x''\\) and repeat from step 3 until we find    another label.</li> </ol> <p>Above algorithm is often run with a constant number of iterations. After that, either an adversarial example has been found, or we simply look at the next sample \\(x\\).</p>"},{"location":"data/rtai/robustness/#adversarial-defenses","title":"Adversarial defenses","text":"<p>To defend somewhat against such attacks, we can use the following approach. For all samples \\(x\\) we search for the point in a region (eg. \\(l_\\infty\\)) around \\(x\\) that maximizes the loss. We then train the model on these points to minimize the loss.</p> <p>Although this might improve the adversarial accuracy, it typically reduces the standard accuracy.</p> <p>An approach shown in the lecture (PGD-defense) uses a PGD-attack on a mini-batch of the dataset. The output of this attack is then used in the training. The attack gives us samples with a maximized loss inside a region around the original samples.</p>"},{"location":"data/rtai/robustness/#adversarial-accuracy","title":"Adversarial accuracy","text":"<p>The adversarial accuracy measures how well a model is holding against attacks in the \\(l_p\\)-ball for a specific \\(\\epsilon\\). It is a metric for the robustness of a network.</p> <p>Typically, a PGD attack is used to measure this metric. It takes all samples that were classified correctly, and tries to break them. Let's say we have 100 samples out of which 95 are classified correctly (accuracy: 95%). Now, for 15 samples we found an adversarial example. The adversarial accuracy will thus be 80/100 = 80%.</p>"},{"location":"data/rtai/robustness/#certification","title":"Certification","text":"<p>Until now, we have looked at attacks and defenses that might or might not work well in practice. However, there are no formal guarantees. This is what we try to establish in this chapter: prove properties of realistic networks using automated verifiers. More formally we can state our fundamental problem, given a neural network \\(N\\), a property over inputs \\(\\phi\\) (pre-conditions), and a property over outputs \\(\\psi\\) (post conditions):</p> <p>Prove that \\(\\forall i \\in I. \\models \\phi \\Rightarrow N(i) \\models \\psi\\) holds or return a violation.</p> <p>We can now instantiate this problem definition for an image classification neural network in the following steps.</p> <ol> <li>Define \\(\\phi\\): to prove adversarial robustness, we define \\(\\phi\\) as the \\(l_\\infty\\)-ball around an input \\(x\\):    \\(ball(x)_\\epsilon = \\{x' \\in I \\mid ||x-x'||_\\infty &lt; \\epsilon \\}\\).</li> <li>Verify \\(\\psi\\) satisfies \\(\\phi\\). We define the property \\(\\phi\\) as: We want to prove that all inputs inside the    ball around \\(x\\) are classified identically to \\(x\\).</li> </ol> <p>The challenge of this approach is, that we cannot simply prove the property for all points in the \\(l_\\infty\\)-ball as there are too many of them.</p> <p>Before continuing, we must look at some properties of certification methods:</p> <ul> <li>Sound vs. Unsound: A method is called sound when it states \"property holds\" iff the property truly holds. It is   called unsound, if it states \"property holds\" even though this is not true.</li> <li>Complete vs. Incomplete: A method is called complete if it is able to prove all cases where a property holds. It   is called incomplete, if it misses some such cases.</li> </ul> <p>It is difficult to have such an algorithm. Actually, having a sound and complete algorithm is only possible in restricted types of computation, generally on small scaled networks.</p> <p>This chapter covers two kinds of sound methods:</p> <ul> <li>Scalable but incomplete: Box relaxation, DeepPoly relaxation</li> <li>Not scalable but complete: MILP, Branch and Bound with Lagrange Multipliers and DeepPoly</li> </ul>"},{"location":"data/rtai/robustness/#incomplete-certifications","title":"Incomplete certifications","text":"<p>The incomplete certification processes are generally faster, but are only able to approximate the results. They are sound but incomplete. We start with initial preconditions \\(\\phi\\) and pushes them through the network. This leads to over-approximations that different methods try to reduce to improve the certification. In essence, we have a certain input region (in the case of an image, this can be represented with the image itself and a delta on each pixel), and we try to prove for every point in this region, that the classification leads to the same result \\(\\psi\\). This is called bounds propagation.</p> <p>Every layer of the network to be certified produces a convex approximation, every layer loses some precision due to the over-approximation. To make those approximations, two questions are to be answered.</p> <ul> <li>What convex approximations are used (box, zonotope, polyhedra, ...) ?</li> <li>How does a layer modify the convex approximation, often called abstract transformer?</li> </ul> <p>In general, there is a trade-off to be made between approximation quality and speed.</p>"},{"location":"data/rtai/robustness/#box-relaxation","title":"Box relaxation","text":"<p>This first relaxation is very simple (thus fast), but loses quite a lot of precision. We use the convex approximation box.</p> <p>Abstract Transformers</p> <p>The following transformers are used to propagate the approximations through a network. \\(\\#\\) denotes the transformer operation. \\(a,b,c,d \\in \\mathbb{R}^n\\) are the approximation bounds where \\(\\forall i, a_i \\leq b_i\\). </p> <ul> <li>Addition: \\([a,b] +^{\\#} [c,d] = [a+c, b+d]\\) </li> <li>Negation: \\(-^{\\#} = [-b,-a]\\)</li> <li>ReLU:  \\(ReLU^{\\#}[a,b] = [ReLU(a), ReLU(b)]\\)</li> <li>Multiplication by positive constant: \\(\\lambda^{\\#}[a,b] = [\\lambda \\cdot a, \\lambda \\cdot b]\\)</li> </ul> <p>As an example, we define two inputs \\(x_1=[0,0.3]\\) and \\(x_2=[0.1,0.4]\\). Our neural net defines the following dependencies: \\(x_3 = x_1 + x_2\\) and \\(x_4=x_1-x_2\\). By applying above transformers, we obtain approximated intervals \\(x_3 = [0.1, 0.7]\\) and \\(x_4 = [-0.4, 0.2]\\). In this case, the two intervals are overlapping. The classification might therefore not be able to make the correct distinction on every input in the input range. However, the approximations made by the box relaxation include also many points that are not achievable by the input regions - the method is not precise.</p> <p>One possibility to improve the precision somewhat is merging the outputs, and no longer requiring that the intervals don't overlap, but that one's lower bound minus the other's upper bound is strictly greater than 0:</p> \\[\\begin{align} x_3 - x_4 &amp;&gt; 0\\\\ x_1 + x_2 - (x_1 - x_2) &amp;&gt; 0\\\\ 2x_2 &amp;&gt; 0 \\end{align}\\] <p>As we know that \\(x_2 &gt; 0\\), we are able to prove the property.</p>"},{"location":"data/rtai/robustness/#deeppoly-relaxation","title":"DeepPoly relaxation","text":"<p>The box relaxation seen in the previous chapter is lossy, it loses much precision both on ReLU and affine abstract transformers. DeepPoly improves on this by eliminating loss on affine transformers, and reducing loss on ReLU transformers.</p> <p>Using the box relaxation we defined intervals of possible values for each neuron. For each following neuron, the intervals are combined leading to imprecise results. DeepPoly also works with intervals, but keeps in mind the relation of the different neurons. Upon combining layers, we can apply back substitution of those relations which leads to simplifications in the relations and improve the respective precisions.</p> <p>Let's look for example at the following affine layers. For both \\(x_1\\) and \\(x_2\\), we have an input interval of \\([-1;1]\\). In addition of defining these intervals for each neuron of the first layer, we also compute the lower and upper bound \\(l_1, u_1\\). We do the same thing for the second layer but this time we define the intervals using the previous layer's neurons. The lower and upper bounds are computed through back propagation of above intervals.</p> <p></p> <p>For instance, nothing of interest has happened, our intervals are identical to the ones computed through the box relaxation. Let's look now at a DeepPoly relaxation for a ReLU function. We must consider three separate cases based on the lower and upper bounds observed at the neuron's input. We consider the ReLU \\(x_j = max(0, x_i)\\), where \\(x_j\\) is our ReLU neuron and \\(x_i\\) is the input.</p> <ul> <li>\\(l_i \\geq 0\\): strictly positive \\(a_j^\\leq = a_j^\\geq = x_i, l_j = l_i, u_j = u_i\\)</li> <li>\\(u_i \\leq 0\\): strictly negative \\(a_j^\\leq = a_j^\\geq = x_i, l_j = u_j = 0\\)</li> <li>\\(l_i &lt; 0\\) and \\(u_i &gt; 0\\): crossing ReLU, special relaxation applies</li> </ul> <p>As illustrated in above case distinction, the relaxation is trivial for strictly negative and strictly positive input intervals. However, the crossing ReLU, where the interval includes both negative and positive values is more complicated. We discuss three possible relaxations.</p> <p>Relaxation constraints</p> Relaxation IRelaxation II\\(\\alpha\\)-relaxation <p>For the first relaxation we limit the values to the inside of below triangle. The triangle's sides are defined as follows: </p> <ul> <li>Lower \\(y\\) bound: \\(y = 0\\)</li> <li>Upper \\(y\\) bound: \\(y = \\gamma * (x - x_l)\\) with a slope of \\(\\gamma = \\frac{u_x}{u_x - l_x}\\)</li> <li>Right \\(x\\) bound: \\(x = u_x\\). </li> </ul> <p>Note that the point \\(d\\) is at </p> <p> </p> <p>Above line definitions can be translated into the following constraints: </p> <ul> <li>\\(y \\geq 0\\)</li> <li>\\(y \\leq \\gamma * (x - x_l)\\)</li> <li>\\(x \\leq x_u\\)</li> </ul> <p>Let's get directly to the constraints. We keep the upper y limit identical to the previous relaxation. The lower bound is now defined as the slope of \\(x\\).</p> <ul> <li>Lower \\(y\\) bound: \\(y \\geq x\\)</li> <li>Upper \\(y\\) bound: \\(y \\leq \\gamma * (x - x_l)\\) with a slope of \\(\\gamma = \\frac{u_x}{u_x - l_x}\\)</li> <li>Lower \\(x\\) bound: \\(x \\geq l_x\\) </li> </ul> <p> </p> <p>The \\(\\alpha\\)-relaxation keeps some room for optimisation. The upper y limit is again identical. However, the  lower bound can be optimised through its slope to get the area of the shape as small as possible while staying inside the interval \\(\\alpha = [0,1]\\).</p> <ul> <li>Lower \\(y\\) bound: \\(y \\geq \\alpha x, \\alpha \\in [0,1]\\)</li> <li>Upper \\(y\\) bound: \\(y \\leq \\gamma * (x - x_l)\\) with a slope of \\(\\gamma = \\frac{u_x}{u_x - l_x}\\)</li> <li>Lower \\(x\\) bound: \\(x \\geq l_x\\) </li> <li>Upper \\(x\\) bound: \\(x \\leq l_x\\) </li> </ul> <p> </p> <p>We can now apply one of the relaxations to neurons. We extend the network above with two new neurons applying a ReLU on the outputs of \\(x_3\\) and \\(x_4\\).</p> <p></p> <p>Now, we can stitch those neurons together with the affine layer, and add an output layer to analyse the system. Without any further modification, this leads to the following network with output bounds \\(l_7 = -0.5\\) and \\(u_7 = 3.5\\).</p> <p></p> <p>We can further improve those bounds by using back substitution. This is where DeepPoly improves over other methods. The improved bound can, in this example, be observed with the upper bound \\(u_7\\).</p> \\[ \\begin{align*} x_7 &amp;\\leq x_5 + x_6 - 0.5\\\\ &amp;= 0.5 x_3 + 1 + 0.5 x_4 + 1\\\\ &amp;= 0.5(x_3 + x_4) + 1.5\\\\ &amp;= 0.5(x_1+x_2+x_1-x_2) + 1.5\\\\ &amp;= x_1 + 1.5\\\\ &amp;= 2.5\\\\ x_7 &amp;\\leq 2.5 \\end{align*} \\] <p>We observe that the upper bound has been improved from \\(3.5\\) to \\(2.5\\).</p>"},{"location":"data/rtai/robustness/#complete-certifications","title":"Complete Certifications","text":"<p>The following chapters discuss complete certification methods. Such methods are interesting in theory, but not widely in use due to their poor scalability.</p>"},{"location":"data/rtai/robustness/#milp-mixed-integer-linear-program","title":"MILP (Mixed Integer Linear Program)","text":"<p>The MILP solver is a complete certification method for ReLU networks. Unfortunately, the solver is at least NP-complete, and is thus slow. We will also see the use of box bounds to make the solver somewhat faster without losing the completeness.</p> <p>Essentially, we convert a decision problem into an optimization problem. We start with some minimization objective</p> \\[ \\text{min}c_1x_1 + c_2x_2 + ... + c_nx_n \\] <p>with \\(c_i \\in \\mathbb{R}\\), and \\(x_j\\) integer or real (hence \"mixed integer\"). The objective is subject to some linear constraints</p> \\[\\begin{align} a_{11}x_1 + ... + a_{1n}x_n \\leq $b_1\\\\ ...\\\\ a_{m1}x_1 + ... + a_{mn}x_n \\leq $b_1 \\end{align}\\] <p>with \\(a_{ij}, b_i \\in \\mathbb{R}\\). Lastly, bounds are defined on every neuron to improve MILP's performance.</p> \\[ l_i \\leq x_i \\leq u_i \\quad 1 \\leq i \\leq n \\] <p>With these definitions out of the way, the network must be encoded as a MILP instance in four steps:</p> <ol> <li>Encode Affine layer</li> <li>Encode ReLU layer</li> <li>Encode pre-condition \\(\\phi\\)</li> <li>Encode post-condition \\(\\psi\\)</li> </ol> <p>Encoding affine layers is trivial, as this is just a linear constraint. The same is valid for convolutions, as these are essentially affine transformations. \\(y = Wx + b\\), where \\(W\\) are the weights and \\(b\\) is the bias.</p> <p>The ReLU layer is the reason that MILP is slow. We assume that the lower and upper bounds are known for the previous layer. The encoding is defined as follows.</p> \\[\\begin{align} y &amp;\\leq x - l \\cdot (1-a)\\\\ y &amp;\\geq x\\\\ y &amp;\\leq u \\cdot a\\\\ y &amp;\\geq 0\\\\ a &amp;\\in \\{0,1\\} \\end{align}\\] <p>The encoding introduces the branching variable \\(a\\) for each crossing ReLU (that is, \\(l &lt; 0\\) and \\(u &gt; 0\\)). In the worst case, this branching must be done for every ReLU, leading to an exponential complexity. The box bounds computation is used here to check which ReLUs are crossing. This allows the reduction of branching.</p> Elaboration on the branching variable <p>For \\(a= 0\\) (notice that the last two inequalities result in \\(y=0\\)):</p> <ul> <li>\\(y \\leq x-l\\)</li> <li>\\(y \\geq x\\)</li> <li>\\(y \\leq 0\\)</li> <li>\\(y \\geq 0\\)</li> </ul> <p>For \\(a=1\\) (notice that the first two inequalities result in \\(y=x\\)):</p> <ul> <li>\\(y \\leq x\\)</li> <li>\\(y \\geq x\\)</li> <li>\\(y \\leq u\\)</li> <li>\\(y \\geq 0\\)</li> </ul> <p>As a pre-condition, we take \\(\\phi = L_{\\infty}\\) around \\(x\\) as an example. This is encoded as \\(x_i - \\epsilon \\leq x_i' \\leq x_i + \\epsilon\\), introducing bounds for each input neuron \\(x_i'\\).</p> <p>The post-condition \\(\\psi\\) defines that one label is always more probable than the other labels, no matter the input from \\(\\phi\\): for two inputs, we say: \\(\\psi = o_0 &gt; o_1\\) - this is what the MILP tries to prove, and we must thus form the objective around this post-condition. The encoding is defined as \\(\\text{min}(o_0 - o_1)\\).</p> <p>With the above encodings, we can define the MILP instance as follows:</p> <ul> <li>Minimization objective: \\(\\min(o_0 - o_1)\\)</li> <li>Linear constraints: Afine and ReLU encodings</li> <li>Bounds: Bounds per neuron \\(l_i \\leq x_i^p \\leq u_i\\), bounds on input \\(x_i - \\epsilon \\leq x_i' \\leq x_i +   \\epsilon\\)</li> <li>Mixed integer: \\(a_j \\in \\{0,1\\}\\)</li> </ul> Example <p>Let's consider the following network with bounds computed through the box relaxation.</p> <p> </p> <p>With this network, we can define the following instance. </p> <ul> <li>Affine:<ul> <li>\\(x_3 = x_1 + x_2\\)</li> <li>\\(x_4 = x_1 - x_2\\)</li> <li>\\(o_0 = x_5 + x_6 + 0.5\\)</li> <li>\\(o_1 = x_5 - x_6 - 0.5\\)</li> </ul> </li> <li>ReLU<ul> <li>\\(x_5: x_3 \\leq x_5 \\leq x_3 - 0.1 \\cdot (1-a_5)\\)</li> <li>\\(x_5: 0 \\leq x_5 \\leq 1.3 \\cdot a_5\\)</li> <li>\\(x_6: x_4 \\leq x_6 \\leq x_4 + 0.7 * (1-a_6)\\)</li> <li>\\(x_6: 0 \\leq x_6 \\leq 0.5 \\cdot a_6\\)</li> </ul> </li> <li>Input bounds: <ul> <li>\\(0\\leq x_1 \\leq 0.6\\)</li> <li>\\(0.1 \\leq x_2 \\leq 0.7\\)</li> </ul> </li> <li>Box bounds:<ul> <li>\\(0.1 \\leq x_3 \\leq 1.3\\)</li> <li>\\(-0.7 \\leq x_4 \\leq 0.5\\)</li> <li>\\(0.1 \\leq x_5 \\leq 1.3\\)</li> <li>\\(0 \\leq x_6 \\leq 0.5\\)</li> </ul> </li> <li>Binary integer variables: \\(a_5,a_6 \\in \\{0,1\\}\\)</li> </ul> <p>Using the box bounds, we can see directly that the input on \\(x_5\\) is strictly positive. This leads to the first  condition being infeasible for \\(a_5=0\\), as this would lead to \\(x_3 \\leq x_5 \\leq x_3 - 0.1\\), which is impossible.</p> <p>Now, the only branching variable remaining is \\(a_6\\). We must thus prove the property for both its possible values.</p> <ul> <li>\\(a_6 = 0:\\)<ul> <li>\\(x_6 = 0\\)</li> <li>\\(o_0 - o_1 = 2 \\cdot x_6 + 1 = 1\\)</li> </ul> </li> <li>\\(a_6 = 1:\\)<ul> <li>\\(x_6 = x_4, 0 \\leq x_6 \\leq 0.5\\)</li> <li>\\(o_0 - o_1 = 2 \\cdot x_6 + 1\\)</li> <li>\\(1 \\leq o_0 - o_1 \\leq 2\\)</li> </ul> </li> </ul>"},{"location":"data/rtai/robustness/#diffpoly","title":"DiffPoly","text":"<p>DiffPoly is an extension to DeepPoly and acts on the ReLU approximations. Instead of having an area, DiffPoly tries to not lose any precision by enforcing constraints on the input while staying differentiable. Our verification problem becomes an optimization problem.</p> <p>We are trying to get the split \\(x=0\\) and \\(x=x\\), but with the additional constraint \\(x=0 \\mid x \\leq 0\\), \\(x=x \\mid x &gt; 0\\). This constraint is enforced through a KTT condition.</p> KKT condition <p>We have our splitting constraint \\(g(x)\\). If this gets greater than 0, the function \\(f(x) - \\beta g(x)\\) gets to  negative infinity for a growing \\(\\beta\\), thus incentivising the choice of a different \\(x\\). Concretely, this computes an upper bound. To compute a lower bound, it is sufficient to swap \\(\\min\\) with \\(\\max\\) and vice versa. </p> \\[ \\max_{x\\in \\mathcal{X}} f(x) \\leq \\max_{x\\in \\mathcal{X}} \\min_{\\beta \\geq 0} f(x) - \\beta g(x) \\] \\[ s.t. \\quad g(x) \\leq 0 \\] <p>Applied on our splitting problem, this gets converted into: </p> \\[ \\max_{x \\in \\mathcal{X}} ax + c \\leq \\max_{x\\in \\mathcal{X}} \\min_{\\beta \\geq 0} ax + c + \\beta x_i \\] \\[ s.t. \\quad -x_i \\leq 0 \\] <p>As an example, we receive here a maximisation problem for an output variable (\\(ax = \\text{output}\\), \\(c=\\text{bias}\\)), making it dependent on some ReLU node (\\(x_i\\) is this ReLU node) via a lagrange multiplier.</p> <p>In the example, we will use the network shown below. To begin, the shown bounds and coefficients are computed using DeepPoly.</p> <p></p> <p>In the process of backsubstitution, we must always consider the value of \\(\\beta\\), because if the sign of \\(a\\beta + b\\) is negative, the lower bounds of the substituted values must be used (when computing the upper bounds of the output). The below case distinctions are more symbolic, they all happen in the optimization automatically.</p> \\(0.5 \\leq \\beta \\leq 1.5\\)\\(\\beta \\leq 0.5\\)\\(1.5 \\leq \\beta\\) \\[\\begin{align} &amp;\\max_xx_{11} (s.t. \\; x_7 &gt; 0)\\\\ &amp;\\leq \\max_x x_{10}-x_9+3 (s.t. \\; x_7 &gt; 0)\\\\ &amp;\\leq \\max_x 0.5x_8 -x_7 + 4 (s.t. \\; x_7 &gt; 0)\\\\ &amp;\\leq \\max_x \\min_{\\beta \\geq 0} 0.5x_8-x_7 + 4 + \\beta x_7\\\\ &amp;\\leq \\max_x \\min_{\\beta \\geq 0} (\\beta - 0.5)x_5 + (\\beta - 1.5) x_6 + 4.5 + 0.5\\beta \\\\ &amp;\\leq \\max_x \\min_{\\beta \\geq 0} (0.5\\beta - 0.25)x_3+ 4.5 + \\beta\\\\ &amp;\\leq \\max_x \\min_{\\beta \\geq 0} (0.5\\beta-0.25)(x_1+x_2) + 4 + 0.5 \\beta\\\\ &amp;= 4.25 \\end{align}\\] \\[\\begin{align} &amp;...\\\\ &amp;\\leq \\max_x \\min_{\\beta \\geq 0} (\\beta - 0.5)x_5 + (\\beta - 1.5) x_6 + 4.5 + 0.5\\beta \\\\ &amp;\\leq \\max_x \\min_{\\beta \\geq 0} 4.5 - 0.5 \\beta\\\\ &amp;= 4.25 \\end{align}\\] \\[\\begin{align} &amp;...\\\\ &amp;\\leq \\max_x \\min_{\\beta \\geq 0} (\\beta - 0.5)x_5 + (\\beta - 1.5) x_6 + 4.5 + 0.5\\beta \\\\ &amp;\\leq \\max_x \\min_{\\beta \\geq 0} (\\beta - 0.25)x_3 + (\\beta - 0.75) x_2 2.5 + 1.5\\beta \\\\ &amp;\\leq \\max_x \\min_{\\beta \\geq 0} (\\beta - 1)x_1 + 0.5x_2 2.5 + 1.5\\beta \\\\ &amp;\\leq \\max_x \\min_{\\beta \\geq 0} 2 + 2.5\\beta\\\\ &amp;= 5.75 \\end{align}\\] <p>We have now a system that can be optimised (with some modification, see below) on \\(\\beta\\).</p> \\[\\begin{align} &amp;\\max_x \\min_{\\beta \\geq 0} (0.5\\beta-0.25)(x_1+x_2) + 4 + 0.5 \\beta\\\\ \\leq &amp;\\min_{\\beta \\geq 0}\\max_x (0.5\\beta-0.25)(x_1+x_2) + 4 + 0.5 \\beta\\\\ \\leq &amp;\\min_{\\beta \\geq 0} \\beta-0.5 + 4 + 0.5 \\beta = \\min_{\\beta \\geq 0} 3.5 + 1.5\\beta \\end{align}\\] <p>From (1) to (2), we apply the \"weak duality\". From (2) to (3), we simply insert the lower/upper bounds.</p> <p>In above calculations, we set \\(l_7=0,u_7=2.5\\) to have the positive split. The same must now be done for the negative split with \\(l_7=-0.5, u_7=0\\). The maximum of the two optimization problems is the final solution.</p> <p>DiffPoly is generally implemented using a queue that is initialized with the full verification problem. The probelm is then tried to be verified. If not successful, some crossing ReLU is taken, and a split is created. Both new subproblems are then added to the queue. This continues until no more unverified problems are in the queue (or a timeout occurs, in which case the property is not verified).</p>"},{"location":"data/rtai/robustness/#certified-defense","title":"Certified defense","text":"<p>Until now, the relaxations and proving methods were only applied on a trained network. To obtain more provable networks, the relaxations can actually be incorporated during training. Even though, the accuracy is reduced, and the network is harder to optimize, we gain in verifiability. Actually, we try to bias the training process of a network for the properties we care about to be more provable.</p> <p>Incorporating provability into the training process is somewhat similar to PGD defense. We search for \\(\\theta\\) (network parameters) that minimizes \\(\\rho(\\theta)\\) where</p> \\[ \\rho(\\theta) = E_{(x,y)\\sim D} [\\max_{z \\in \\gamma(NN^{\\#}(S(x)))} \\quad L(\\Theta, z, y)] \\] <p>In other words, we pass our sample \\(x\\) and its region around it \\(S(x)\\) through some relaxation \\(NN^{\\#}\\) (e.g. DeepPoly), and find \\(z\\) in the relaxed output shape achieving the highest loss (contrary to the PGD attack where we searched for a point in the input region with the highest loss).</p> <p>The loss can be computed through some loss function \\(L(z, y) = \\max_{q \\neq y}(z_q - z_y)\\) where \\(z\\) is a vector of  logits. Now, every point in the output shape of \\(NN^{\\#}\\) might be the possible max. But as there are too many of them,  we must do approximations. This approximation can be done for example through an additional DeepPoly layer computing  \\(d_q = z_q - z_y\\) which is exact giving us lower and upper bounds for all of them. We can now compute the max over these bounds \\(d_q\\). </p> <p>For instance, this network does not prove anything, it just tries to make it more provable. For this reason, the  forward pass through \\(NN^{\\#}\\) does not need to be sound. We can use subregions of \\(S(x)\\), or remove some intermediate ReLU's to reduce the size of the relaxation shape. This allows for faster optimization.  </p> <p>Counter-intuitively, using more precise relaxations on the input mostly leads to worse outputs. This is due to the complexity of the abstractions, rendering the problem harder to optimize.  </p>"},{"location":"data/rtai/robustness/#randomized-smoothing","title":"Randomized smoothing","text":"<p>Contrary to the prior techniques that were deterministic, we now look at a randomized approach. We create a classifier that is robuts by construction.</p> <p>Given a classifier \\(f\\), we construct a smoothed classifier that finds the most probable class given some noise \\(\\epsilon\\) that follows an isotropic gaussian noise.</p> \\[ g(x) := \\text{argmax}_c\\in\\mathcal{y} \\quad \\mathbb{P}_{\\epsilon}(f(x+\\epsilon) = c) \\] <p>The classifier \\(g\\) can tell us thus the probability for each class given the perturbation, and most importantly the most probable class. Now, using above definition, we can compute a lower bound probability for the most probable class \\(\\underline{p_{A,x}}\\) and an upper bound for the next most probable class \\(B\\) (runner-up) \\(\\overline{p_{B,x}}\\). Very important: all those computations are for one very specific input \\(x\\).</p> <p>This allows as to get a certification</p> \\[ g(x + \\delta) = c_A \\quad \\forall || \\delta||_2 &lt; R_x \\] \\[ R_x := \\frac{\\sigma}{2}(\\Phi^{-1}(\\underline{p_{A,x}})- \\Phi{^-1}(\\overline{p_{B,x}})) \\] <p>with \\(\\Phi^{-1}\\) the inverse of the standard Gaussian CDF.</p> <p>To increase the radius, we try to maximize \\(\\sigma\\) - the noise added to the input. However, the value must not get too big as this will break the classification algorithm.</p> <p>The hard part is the computation of the probabilities \\(p_{A,x}\\) and \\(p_{B,x}\\) efficiently and soundly. In a first step, we change the formula for radius computation such that it is only depending on \\(p_{A,x}\\):</p> \\[\\begin{align} R_x := \\frac{\\sigma}{2}(\\Phi^{-1}(\\underline{p_{A,x}})- \\Phi{^-1}(\\underline{p_{B,x}}) &amp;\\geq \\frac{\\sigma}{2}(\\Phi^{-1}(\\underline{p_{A,x}})- \\Phi{^-1}(\\underline{1-p_{A,x}})\\\\ &amp;= \\frac{\\sigma}{2}(\\Phi^{-1}(\\underline{p_{A,x}}) + \\Phi{^-1}(\\underline{p_{A,x}})\\\\ &amp;= \\sigma \\Phi^{-1}(\\underline{p_{A,x}}) \\end{align}\\]"},{"location":"data/rtai/robustness/#certification-procedure","title":"Certification procedure","text":"<p>The following procedure roughly outlines how the certification is done.</p> <pre><code>function CERTIFY(f, sigma, x, n0, n, alpha):\n   ca = guess_top_class(f, sigma, x, n0)\n   pa = lower_bound_prob(ca, f, sigma, x, n, alpha)\n\n   if pa &gt; 0.5:\n      R = sigma * phi_inv(pa)\n      return ca, R\n   else:\n      return ABSTAIN // pa too low, lower bound of pa is too low,\n                     // or we estimated wrong pa\n</code></pre> <p>To compute the lower bound probability, we get help by the Monte Carlo Integration, as otherwise the integral would be too hard. The Monte Carlo Integration essentially samples many points and computes the final probability based on how often the sample was classified as \\(c_A\\).</p> \\[ p_A(x) \\approx \\frac{1}{n} \\Sigma^n_{i=1}[f(x + \\epsilon_i) = c_A] = \\widehat{p_A} \\] <p>Now, we need to get a statistical bound for this \\(\\widehat{p_A}\\), as we don't know if its value is bigger or smaller than the true \\(p_A\\). This can be done using a binomial confidence bound. Essentially, the above sum expects a binomial distribution. We can define probability bounds for an error rate \\(\\alpha\\) as \\(\\mathbb{P}(\\underline{p_{A,x}} \\leq p_{A,x} \\leq \\overline{p_{A,x}}) \\leq 1 - \\alpha\\). Increasing \\(\\alpha\\) means allowing more errors, and thus the lower bound will get closer to the true probability.</p> <p></p>"},{"location":"data/rtai/robustness/#inference-procedure","title":"Inference procedure","text":"<p>Using this model we can now compute the class that would be predicted by \\(g(x)\\).</p> <pre><code>function PREDICT(f, sigma, x, n, alpha):\n   // take n samples and compute monte carlo probability\n   ca, na, cb, nb = top_two_classes(f, sigma, x, n)\n\n   // compute the p-value, that na and nb are equally probable\n   if BinomPValue(na, na + nb, =, 0.5) &lt;= alpha:\n      return ca\n   else:\n      return ABSTAIN\n</code></pre>"},{"location":"data/rtai/robustness/#deterministic-vs-randomized","title":"Deterministic vs Randomized","text":"Robustness Certificate Adaption to new model class Adaption to new specification Suitable for NN scale Deterministic Verification Through sound analysis Requires new transformers Encode perturbation as convex region small to mid size Randomized Smoothing By construction Model Agnostic Requires new mathematical insights All sizes, but added latency might be prohibitive <ol> <li> <p>Carlini et al., Towards Evaluating the Robustness of Neural Networks \u21a9</p> </li> </ol>"},{"location":"general/placeholder/","title":"Placeholder","text":""},{"location":"security/","title":"Secure and reliable systems","text":"<p>The content of this section is treating courses that are attributed to the major secure and reliable systems.</p>"},{"location":"security/zkp/","title":"Zero-Knowledge Proof","text":"<p>Zero-knowledge proofs are a cryptographic concept and a set of protocols that allow one party, called the prover, to demonstrate to another party, called the verifier, that they possess certain knowledge or information without revealing what that knowledge or information is. In other words, zero-knowledge proofs enable a party to prove that they know a secret or have access to specific data without disclosing the actual content of that secret.</p> <p>The primary goals of zero-knowledge proofs are privacy, security, and trust. They are particularly valuable in situations where one party needs to authenticate themselves or prove their knowledge of something to another party without revealing any sensitive details. Zero-knowledge proofs are used in various applications, including cryptography, cyber-security, and privacy-preserving technologies.</p>"},{"location":"security/zkp/intro-definitions/","title":"Introduction and definitions","text":""},{"location":"security/zkp/intro-definitions/#proofs","title":"Proofs","text":"<p>In general, a proof is used to establish trust between two parties, where a statement is established to be valid. Such a statement is established between two parties:</p> <ul> <li>Prover P (proof writer): Wants to prove a statement</li> <li>Verifier V (proof checker): verifies that the proof is valid</li> </ul> <p>Those parties are interacting with each other in different ways. See the following proof types:</p> <ul> <li>Mathematical proof: One-directional proof, where the prover makes a sequence of logical assertions. All errors   made are detectable by the verifier.</li> <li>Interactive proof (IP): Bi-directional proof, where the messages are randomised and adaptive. Most errors are   detectable by V. Increase proving power (more complex problems can be proven), and increased efficiency.</li> </ul> <p>Now, a general (dirty) description of Zero-Knowledge Proofs could be: Mathematical proofs that were extended with interactions, randomness, and cryptographic assumptions.</p>"},{"location":"security/zkp/intro-definitions/#complexity-classes","title":"Complexity classes","text":"<p>Problems can be separated in different complexity classes. Each class determines how problems can be solved. This mostly concerns the runtime of solving the problem. A Complexity class is a set of languages (problem types with similar properties, e.g. time complexity). A language \\(L\\) is a collection of problems \\(L \\subseteq \\{0,1\\}^*\\), where each problem statement \\(x\\) is a binary encoding of YES/NO \\(x \\in \\{0,1\\}^*\\).</p> <ul> <li>P: Problems are solvable in polynomial time (efficient) and are thus easy to solve. There exists an algorithm \\(M\\)   that is able to say if \\(x \\in L\\) or \\(x \\notin L\\). This is obvious and needs no proof.</li> <li>NP: Problems where it is easy to say that \\(x \\in L\\) using a witness w: \\((x,w) \\in R_L\\) However, there are no   checks in polynomial time that can prove that \\(x \\notin L\\). \\(x \\in L\\) has proof which is easy to check. However, the   witness might be hard to find.</li> <li>IP (interactive proof): Problems are proven using a prover and a verifier. They exchange a certain amount of   messages and the verifier concludes if the proof is valid or not. The verifier must be running polynomial time.   The algorithms are able to verify the two following properties:<ul> <li>Completeness (usually accepts true statements): \\(\\forall x \\in L, Pr_{r,s}[\\langle P(r),V(s)\\rangle (x) = 1]   \\geq \\frac{3}{4}\\)</li> <li>Soundness (usually rejects false statements): \\(\\forall x \\notin L, \\forall P^*, Pr_   {r,s}[\\langle P^*(r),V(s)\\rangle (x) = 1] \\leq \\frac{1}{2}\\)</li> </ul> </li> </ul> <p>In above formulas, \\(Pr_{r,s}\\) denotes a proof system that uses the random values \\(r\\) and \\(s\\), and \\(P^*\\) is any malicious prover. The probability to accept/reject the statements can be changed, as long as acceptance is greater than rejection probability.</p> <p>Increased proving power (seen in the previous chapter) allows for proofs of larger complexity classes.</p>"},{"location":"security/zkp/intro-definitions/#interactive-algorithms-and-interactive-proof","title":"Interactive Algorithms and Interactive Proof","text":"<p>Interactive algorithms are used to perform interactive proofs. A series of \\(k\\) messages are exchanged between the prover and verifiers. Each message \\(a_i\\) contains all \\(i-1\\) previous messages, as well as the input \\(x \\in \\{0,1\\}^*\\) and a random value \\(r\\) or \\(s\\). The complete interaction is denoted as \\(\\langle P^*(r),V(s)\\rangle (x) = a_{k(x)}\\). All messages are stored in the transcript \\((x,a_1,...,a_{k(x)})\\) with \\(a_{k(x)}\\) being the verifiers conclusion if he accepts or rejects the proof.</p> \\[ \\begin{align} a_1 &amp;= P(x,r) \\\\ a_2 &amp;= V(x,a_1,r) \\\\ a_3 &amp;= P(x,a_1,a_2,r) \\\\ \\vdots \\\\ a_{k(x)} &amp;= V(x,a_1,...,a_{k(x)-1},s) \\end{align} \\]"},{"location":"security/zkp/intro-definitions/#graph-isomorphism","title":"Graph Isomorphism","text":"<p>A problem that was seen in the course as an example is the graph-isomorphism problem. To our knowledge, no algorithm exists that can proof if a graph is isomorphic. Isomorphic graphs are graphs that be mapped between each other using some permutation \\(\\pi\\).</p>"},{"location":"security/zkp/intro-definitions/#zero-knowledge-zk","title":"Zero-knowledge (ZK)","text":"<p>The following chapters can be summarised with the following points:</p> <ul> <li>Perfect soundness and perfect zero knowledge cannot be achieved at the same time.</li> <li>Knowledge-soundness also good for \"trivial\" languages</li> <li>Special soundness and SHVZK are those that are used the most.</li> </ul> Soundness Zero Knowledge Proof size Proofs   (short term secrecy) Perfect/statistical Computational Not compressing Arguments (short window for cheating) Computational (short window for cheating) Perfect/statistical &lt;&lt;|x|, |w|"},{"location":"security/zkp/intro-definitions/#perfect-zero-knowledge","title":"Perfect Zero-knowledge","text":"<p>Perfect zero-knowledge is a special case of zero-knowledge proofs, and only a few of those exist. The proof must make sure that the verifier gained no new knowledge - essentially, the verifier should be able to reproduce the proof by themselves. \\((P,V)\\) is a perfect zero-knowledge proof, in case an efficient simulator \\(S\\) exists that is able to reproduce the verifier's view \\((x,s,a_1,...,a_{k(x)})\\).</p> <p>The following example describes a perfect ZKP for graph isomorphism. We have two graphs \\(G_0, G_1\\) that are isomorphic ( there exists a permutation mapping \\(G_0\\) to \\(G_1\\)).</p> <ol> <li>Prover takes a random permutation \\(\\sigma\\), and permutes \\(G_0\\) using this permutation which produces the graph    \\(H\\). \\(H\\) is sent to the verifier.</li> <li>Verifier sends randomly either 0 or 1 to the prover.</li> <li>Prover: if a 0 was received, prover sends \\(\\sigma\\) from step 1 to the verifier. If 1 was received,    \\(\\sigma \\circ \\pi\\) is sent to the verifier (with \\(G_0 = \\pi(G_1)\\)).</li> <li> <p>Verifier now applies the permutation sent by the prover either to \\(G_0\\) or \\(G_1\\) (depending on the random value    sent in step 2.). If the graphs are isomorphic, both ways should result in the random permutation \\(H\\).</p> </li> <li> <p>Completeness is good, as V will always accept if the graphs are isomorphic and the prover knows the permutation.</p> </li> <li>Soundness: say there graphs are not isomorphic, there exists no \\(H\\) that is both isomorphic to \\(G_0\\) and \\(G_1\\) at   the same time. This means that the generated \\(H\\) is only isomorphic to one of the graphs, and in the conversation, V   will only accept the provers response with a probability of 50%.</li> </ol> <p>This perfect zero-knowledge can now be proven using a simulator. Such a simulator is capable of reproducing the verifier's view, which in this case is \\(View_{V^*}^P = (G_0,G_1,\\tau,H,b)\\), with \\(V^*\\) a malicious verifier. The simulator \\(S(V^*,G_0,G_1)\\) then goes through the following steps:</p> <ol> <li>\\(\\tau\\) a random distribution</li> <li>\\(B\\) a random sample of 0 or 1</li> <li>\\(H = \\tau(G_B)\\)</li> <li>Sample \\(b\\) (just as malicious verifier would)</li> <li>If \\(b \\neq B\\), start from begining</li> <li>Output the expected verifiers view.</li> </ol>"},{"location":"security/zkp/intro-definitions/#variations-of-zero-knowledge","title":"Variations of Zero-knowledge","text":"<p>As mentioned before, perfect zero-knowledge is only possible for some languages. Thus, some relaxations are designed.</p> <ul> <li>Black-box zero-knowledge: the simulator only gets black-box access to the malicious verifier, which means that   he has no in-depth access to V, and is only capable of requesting a next symbol. It is noted as \\(S^{V^*}\\).</li> <li>Semi-honest verifier (SHVZK): uses an honest verifier that follows the protocol, but the secret is chosen very   carefully. For this reason, the simulator requires access to said secret.</li> <li>Honest verifier: the simulator has access to an honest verifier, which makes the simulator's job easier. Verifier   is following the protocol.</li> <li>Statistical ZK: the simulator can simulate the malicious verifier if he gets lucky.</li> <li>Computational ZK: the simulator can simulate the malicious verifier if he gets lucky or is hardworking.</li> <li>ZK with auxiliary inputs: additional input is given to prover and verifier (e.g. hint, witness, conversations of   prior protocol). The simulator requires additional input as well.</li> </ul>"},{"location":"security/zkp/intro-definitions/#variations-of-soundness","title":"Variations of Soundness","text":"<ul> <li>Knowledge soundness: \\(\\kappa\\) is the error of how sure one is that the prover is sound. An extractor \\(E\\) extracts   a witness from the prover (somewhat similar to black-box ZK, but the extractor has oracle access to the malicious   prover, producing a witness). The extractor can get both transformations \\(\\tau\\) from the prover (by inputting 0 and   1). The extractor can then extract \\(\\pi = \\tau_1 \\circ \\tau_0^{-1}\\)</li> <li>Interactive arguments: a proof should be convincing. But in this case, arguments can be held between the two   parties, because the protocol only holds against efficient provers. This means that cryptographic assumptions can   prove the soundness.</li> <li>Special soundness: connected to the public coin protocol. A knowledge extractor is used, taking the tree of   transcripts as an input to extract a witness. If such an extractor exists, the protocol with (2k+1) moves is   \\((n_1,...,n_k)-special sound\\). This soundness is typically easier to compute.</li> <li>Perfect, statistical and computational soundness also exist.</li> </ul>"},{"location":"security/zkp/intro-definitions/#public-coin-protocols","title":"Public coin protocols","text":"<p>In general, the verifier publicly sends random \"coin flips\" to the prover. Those are the only messages that are sent by the verifier, and are often also called challenges.</p> <p>The public coin flips can then be arranged in a tree of transcripts. The number of challenges defines the depth of the tree.</p>"},{"location":"security/zkp/non-interactive-zk/","title":"Non-interactive zero-knowledge","text":""},{"location":"security/zkp/sigma/","title":"Sigma protocols","text":"<p>The sigma protocols are the shortest and nicest possible interactive proofs. It is a 3-move public-coin protocol with the following properties:</p> <ul> <li>V always accepts if \\((x,w)\\in R\\)</li> <li>k-special sound, which means that an extractor exists that can extract the witness.</li> <li>SHVZK</li> </ul>"},{"location":"security/zkp/sigma/#commitment-schemes","title":"Commitment schemes","text":"<p>Sigma protocols require commitment schemes. A real world example of a commitment scheme are envelopes: a message is put into a (cryptographic) envelope, that can then no longer be opened by some other entity. The sender committed to a certain message and nobody is able to change this without the others noticing it.</p> <p>The commitment scheme is a collection of three algorithms:</p> <ul> <li>\\(Setup(1^\\delta)\\): public parameters pp are generated. Message space \\(\\mathfrak{M}\\), randomness space   \\(\\mathfrak{R}\\), decommitment space \\(\\mathfrak{D}\\) and commitment space \\(\\mathfrak{C}\\).</li> <li>\\(Commit(pp,m\\in\\mathfrak{M}, r \\gets_\\$ \\mathfrak{R})\\): creates a commitment and a decommitment \\((c,d)\\).</li> <li>\\(Verify(pp,c\\in\\mathfrak{C},d\\in\\mathfrak{D},m\\in\\mathfrak{M})\\): asks question if message was in commitment, and   consequently outputs 0 or 1.</li> </ul> <p>The commitments must be correct and secure. From this, the following points follow.</p> <ul> <li>Correctness: \\(\\forall pp, Verify(pp,Commit(pp,m,r),m)=1\\)</li> <li>Perfect hiding: the commitment should not disclose anything about the message.</li> <li>perfect binding: it must not be possible to change the message.</li> </ul> <p>Hiding and binding also exist as computational hiding and binding. It is not possible to have perfect binding ** and perfect hiding** at the same time.</p>"},{"location":"security/zkp/sigma/#elgamal-encryption","title":"Elgamal encryption","text":"<p>The elgamal is a computationally hiding and perfectly binding example of a commitment scheme. We sample a random prime number h (prime \\(p\\) of order \\(2^\\lambda\\) from \\(\\mathbb{G}\\)) and a secret key \\(s\\), which can then be used to compute \\(g = s \\cdot h\\). \\(\\mathbb{Z}_p\\) is the collection of integers from 0 to p-1, but the operations inside this set are done with mod p.</p> <ul> <li>Setup outputs \\(pp := (\\mathbb{G}, g, h, p)\\)</li> <li>\\(Commit(pp,m\\in\\mathbb{G},r\\gets_\\$\\mathbb{Z}_p)\\): \\(((c_1,c_2),d):=((m+r\\cdot g,r \\cdot h),r)\\)</li> <li>\\(Verify(pp,c,d,m)\\): \\((Commit(pp,m,d)==c)\\)</li> </ul>"},{"location":"security/zkp/sigma/#pedersen-commitment","title":"Pedersen commitment","text":"<p>The pedersen commitment can be plugged into sigma protocols to have a perfect hiding and computationally binding proof, and has the following steps. The protocol is perfectly hiding because \\(r\\cdot h\\) is uniformly random in \\(\\mathbb{G}\\).</p> <ul> <li>Setup generatesagain the same output.</li> <li>\\(Commit(pp,m\\in\\mathbb{Z}_p,r\\gets_\\$\\mathbb{Z}_p)\\): \\(((c_1,c_2),d):=((m\\cdot g,r \\cdot h),r)\\)</li> <li>\\(Verify(pp,c,d,m)\\): \\((Commit(pp,m,d)==c)\\)</li> </ul>"},{"location":"security/zkp/sigma/#example-three-coloring-graph","title":"Example - three-coloring graph","text":"<p>In a three-coloring graph, all adjacent nodes must be of different colours. The IP is as follows (\\(E\\) is the set of edges):</p> <ul> <li>Prover creates a permutation of the graph (the colors change, but the three-coloring stays valid) \\(\\sigma\\).   Additionally, the set of colors \\(col\\) is extracted. A commitment is created: \\((c_u,d_u) \\gets_\\$ Commit(pp,col_u)\\).</li> <li>Prover only sends the commitment \\(c_u\\) to the verifier (\\(u\\) is a vertex).</li> <li>Verifier picks a random edge \\((a,b)\\) from the graph and sends that to the prover</li> <li>Prover sends colors and decommitments of the requested edge to the verifier</li> <li>The verifier checks the commitment and decommitment.</li> </ul> <p>Completeness: the three-coloring stays valid after the permutation. Additionally, the commitment scheme makes sure that the verifier is always capable of correctly verifying the commitments/decommitments.</p> <p>\\(|E|\\)-special soundness: the tree of transcript must contain all edges, and no adjacent nodes must be the same color.</p> <p>There exists a simulator for SHVZK which reproduces the verifier's view that is the following (for a single edge in this example):\\(((c_u)_{u\\in V}(a,b),col_a,d_a,col_b,d_b)\\), and \\(Verify()==1\\) for both nodes a and b, and \\(col_a \\neq col_b\\). The simulator \\(S(pp,G,(a,b))\\) does the following steps (note that the simulator does not know the graph). Note that the simulator is kind of going backwards in the protocol.</p> <ol> <li>Sample two random colors \\(col_a, col_b\\) with \\(col_a \\neq col_b\\)</li> <li>\\((c_a,d_a) \\gets_\\$ Commit(pp,col_a)\\)</li> <li>\\((c_b,d_b) \\gets_\\$ Commit(pp,col_b)\\)</li> <li>All other nodes can be committed to some color (does not matter what, as they stay hidden)</li> <li>Results in the verifier's view</li> </ol>"},{"location":"security/zkp/sigma/#composition","title":"Composition","text":"<p>Often, protocols are repeated to improve the completeness/soundness errors. This might happen in sequence repetition or parallel repetition. The \\(\\Sigma\\)-protocols are often used with parallel repetition. The protocol stays largely unchanged, but instead of sending a single message, multiple messages are sent at once from the prover to the verifier.</p> <p>A 2-sound \\(\\Sigma\\)-protocol for example sends two messages in parallel, which will reduce the soundness error from \\(\\frac{1}{|C|}\\) to \\(\\frac{1}{|C|}\\).</p>"},{"location":"security/zkp/sigma/#and-composition","title":"AND composition","text":"<p>The sigma protocol is capable of combining two relations \\(R\\) and \\(R'\\) into a single relation \\(R_\\land\\). The messages exchanged are similar to the parallel repetition.</p> <p>For this composition to work, both \\(R\\) and \\(R'\\) require that the verifier's challenge space $\\mathfrak{C} is identical.</p> <ol> <li>P then sends first messages using both sigma protocols for \\(R\\) and \\(R'\\)</li> <li>V sends a single challenge \\(c\\). This is valid because the relations must share the challenge space</li> <li>P sends back a message according to the challenge</li> <li>V must then accept both individual verifiers</li> </ol> <p>The AND composition of two sigma protocol is pretty straight forward. The simulator for \\(R_\\land\\) is the combination for the individual relations: \\(S^\\land(x,x',c) := (S(x,c),S'(x',c))\\).</p> <p>The protocol is complete, k-special-sound and SHVZK.</p>"},{"location":"security/zkp/sigma/#or-composition","title":"OR composition","text":"<p>The preconditions for this composition is the same as for the AND composition. There is, however, a difference in how the prover and verifier work together. To start, the prover has only a witness for one of the relations. The prover for the second relation is simulated using a simulator.</p> <ol> <li>P generates message \\(a\\) using prover \\(P_1\\)</li> <li>P generates a random \\(c'\\) from the challenge space</li> <li>P simulates the message \\(a'\\) and \\(z'\\) using \\(c'\\)</li> <li>P sends both \\(a\\) and \\(a'\\) to the verifier</li> <li>V responds with a new random \\(c''\\)</li> <li>P computes \\(c := c''-c'\\), which is then used to compute \\(z\\)</li> <li>P sends \\(z,z'\\) and \\(c,c'\\) to the verifier</li> <li>V checks that both challenges were correctly answered, and \\(c+c' == c''\\)</li> </ol> <p>The protocol is complete, k-special-sound and SHVZK.</p>"},{"location":"security/zkp/sigma/#multi-party-computation","title":"Multi-Party computation","text":"<p>In this protocol \\(\\Pi\\), multiple players \\(P_i\\) want to arrive at a common conclusion (joint function) without leaking any of their private information \\(w_i\\), which also function as the private inputs. The players interact with each other over multiple rounds, and in the end all players should get the output. Additional inputs are a public input \\(x\\), and private randomness \\(r_i\\).</p> <p>The protocol is then specified by a next message function, specifying what message \\(m\\) a player \\(i\\) will send in round \\(j\\) to some other player \\(k, k\\neq i\\). The output is the message that is going to be sent by player \\(P_i\\) in round \\(j+1\\). \\(M\\) are all messages that were received by a certain player. </p> \\[ \\Pi \\big(i,x,w_i,r_i,(M_1,...,M_j)\\big) \\to (m_{j+1,i\\to k}) \\] <p>The protocol is correct, if all players get the correct output. If one input is not in the relation, all players  will get 0. </p> <p>The protocol has also t-privacy. This means that up to \\(t\\) players can be corrupted until the protocol looses its privacy. </p>"},{"location":"security/zkp/sigma/#view","title":"View","text":"<p>A player's view is defined as \\(View_i =(x,w_i,r_i,M_1,...,M_k)\\) where \\(M_j\\) is the set of all messages player \\(P_i\\) received from all other players in a specific round \\(j\\).</p> <p>Two views \\(View_i, View_j\\) are called consistent, if the messages in \\(View_i\\) sent by \\(View_j\\) actually match the  messages that can be computed using \\(View_j\\) and \\(\\Pi\\). This is called local consistency</p> <p>To get global consistency, all combinations of views must be pairwise consistent. If this is the case, there exists a  protocol with input \\(x\\) that matches all views.  </p>"},{"location":"security/zkp/sigma/#sigma-protocol-with-mpc-in-the-head","title":"Sigma-Protocol with MPC in the head","text":"<p>This protocol is called 'in the head' because the prover imagines the graph of players and computes all their witness and their views by themselfs. We now have \\(P(pp,x,w)\\) and \\(V(pp,x\\)) with \\(pp\\) the parameters from the setup function.</p> <ol> <li>P computes all witness for all players \\(w_i\\), with the additional condition that \\(w = w_1 \\oplus ... \\oplus w_n\\)</li> <li>P uses all \\(w_i\\), input \\(x\\) and \\(\\Pi\\) to compute the views</li> <li>P commits to the views, and sends all commitments to the verifier</li> <li>V chooses random players \\(i,j\\)</li> <li>P sends the views and decommitments of \\(i,j\\) to V</li> <li>V runs the verifying function Verfy\\((pp,c_i,d_i,View_i)=1\\), makes sure the views are consistent, and that     \\(P_i = P_j = 1\\)</li> </ol>"},{"location":"security/zkp/sigma/#fiat-shamir-heuristic","title":"Fiat-Shamir Heuristic","text":"<p>The protocol gives full zero knowledge and reduces the number of messages exchanged to 1. Additionally, a hash function \\(H\\) is required, that is modelled as a random oracle. The hash function maps onto the challenge space \\(C\\). Additionally,  \\(H\\) remembers the outputs (uniform random hash) that it has given for previous inputs. Giving the same input again will result in the identical output. </p> <p>Unlike the sigma protocol seen until now, P is generating \\(c = H(x,a)\\). He then sends \\(a\\), \\(c\\), and \\(z\\) to the  verifier. V does the same checks as usual, but also makes sure that \\(c\\) was generated correctly using the common hash function.</p> <p>Some notes: </p> <ul> <li>Hash more than less. If a commitment scheme is involved for example, the public parameters pp should be hashed as well</li> <li>Unsecure for real hash functions (only certain hash-functions can be used for a secure protocol)</li> <li>Signature scheme can be implemented, where the prover signs, and the verifier verifies. This method was used in the   picnic signature scheme that was a candidate as a post-quantum signature scheme. </li> </ul>"},{"location":"security/zkp/sigma/#sigma-protocol-against-malicious-verifiers","title":"Sigma protocol against malicious verifiers","text":"<p>If the verifier generates random challenges, there is no way to gain knowledge. However, non-uniformly-random challenges might leak information.</p> <p>To counter this, a public coin flip protocol is used. The verifier is forced to be honest by generating challenges  together with the prover.</p> <p>The prover generates his challenge \\(c\\) and commits to it. The commitment \\(C\\) is then sent to the verifier. V also  generates a secret \\(c'\\) that he sends back to the prover. P then answers with \\(c\\) and the decommitment \\(d\\), allowing  the verifier to check that \\(c\\) was not changed in the meantime. This procedure can then be interleaved with a message:</p> <ol> <li>P computes \\(a\\), \\(c\\), and \\(C\\), sending \\(a\\) and \\(C\\) to V</li> <li>V generates \\(c'\\) and sends it to P</li> <li>P computes \\(z \\gets_\\$ P_2(x,w,a,c'';p)\\) with \\(c'' := c + c'\\), then sends \\(z,c,d\\) to V</li> <li>V verifies that \\(c\\) has not been changed, and computes the output \\(V(x,a,c'',z)\\)</li> </ol>"},{"location":"security/zkp/zk-arguments-and-proofs/","title":"Zero-knowledge arguments with short proofs","text":""}]}